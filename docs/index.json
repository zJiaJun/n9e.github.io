[
  {
    "content": " grafana-agent çš„ metricsé‡‡é›†ï¼Œå®Œå…¨å…¼å®¹ prometheus exporter ç”Ÿæ€ï¼Œä¸€äº›å¸¸è§çš„ exporterï¼Œä¼šåœ¨ grafana-agent ä¸­å†…åµŒå®ç°ï¼ˆåˆ—è¡¨å¦‚ä¸‹ï¼‰; å¯¹äºæœªåµŒå…¥åˆ° grafana-agentä¸­çš„ exporterï¼Œåˆ™å¯ä»¥åœ¨ grafana-agent ä¸­é…ç½® scrape_configs æ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œè¯·å‚è€ƒæŠ“å–ç¬¬ä¸‰æ–¹exporter;  grafana-agent å†…ç½®å®ç°çš„ exporter åˆ—è¡¨  node-exporter mysqld-exporter process-exporter cadvisor windows-exporter postgres-exporter mongodb-exporter redis-exporter memcached-exporter kafka-exporter elasticsearch-exporter consul-exporter dnsmasq-exporter  å†…ç½®exporterçš„é…ç½®é¡¹è¯´æ˜ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125  # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e # grafana-agent integration ç›¸å…³çš„é…ç½® integrations: ## grafana-agent self-integration ## grafana-agent æœ¬èº«çš„metrics é‡‡é›†ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå†…åµŒçš„ integrationï¼Œå¯ä»¥é€‰æ‹©å¯ç”¨æˆ–è€…å…³é—­ã€‚ agent: ### æ˜¯å¦å¼€å¯é’ˆå¯¹grafana-agent è‡ªèº«çš„integrationï¼Œå…è®¸grafana-agentè‡ªåŠ¨é‡‡é›†å’Œå‘é€å…¶è‡ªèº«çš„metrics [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the agent integration will be run but not scraped and thus not # remote_written. Metrics for the integration will be exposed at # /integrations/agent/metrics and can be scraped by an external process. ### è¿™ä¸ªé…ç½®é¡¹å¦‚æœè®¾ç½®ä¸ºfalseï¼Œé‚£ä¹ˆ /integrations/agent/metrics çš„æ•°æ®å¹¶ä¸ä¼šè¢«è‡ªåŠ¨æŠ“å–å’Œå‘é€ ### ä½†æ˜¯ï¼Œè¯¥æ¥å£ /integrations/agent/metrics çš„æ•°æ®ä»ç„¶æ”¯æŒè¢«å¤–éƒ¨çš„æŠ“å–è¿›ç¨‹æ‰€æŠ“å–  [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # Client TLS Configuration # Client Cert/Key Values need to be defined if the server is requesting a certificate # (Client Auth Type = RequireAndVerifyClientCert || RequireAnyClientCert). http_tls_config: \u003ctls_config\u003e ## æ§åˆ¶å†…åµŒçš„ node_exporter å·¥ä½œé€»è¾‘  node_exporter: \u003cnode_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ process_exporter å·¥ä½œé€»è¾‘ process_exporter: \u003cprocess_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ mysqld_exporter å·¥ä½œé€»è¾‘ mysqld_exporter: \u003cmysqld_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ redis_exporter å·¥ä½œé€»è¾‘ redis_exporter: \u003credis_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ dnsmasq_exporter å·¥ä½œé€»è¾‘ dnsmasq_exporter: \u003cdnsmasq_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ elasticsearch_exporter å·¥ä½œé€»è¾‘ elasticsearch_expoter: \u003celasticsearch_expoter_config\u003e # Controls the memcached_exporter integration memcached_exporter: \u003cmemcached_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ postgres_exporter å·¥ä½œé€»è¾‘ postgres_exporter: \u003cpostgres_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ statsd_exporter å·¥ä½œé€»è¾‘ statsd_exporter: \u003cstatsd_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ consul_exporter å·¥ä½œé€»è¾‘ consul_exporter: \u003cconsul_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ windows_exporter å·¥ä½œé€»è¾‘ windows_exporter: \u003cwindows_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ kafka_exporter å·¥ä½œé€»è¾‘ kafka_exporter: \u003ckafka_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ mongodb_exporter å·¥ä½œé€»è¾‘  mongodb_exporter: \u003cmongodb_exporter_config\u003e ## æ§åˆ¶å†…åµŒçš„ github_exporter å·¥ä½œé€»è¾‘ github_exporter: \u003cgithub_exporter_config\u003e # Automatically collect metrics from enabled integrations. If disabled, # integrations will be run but not scraped and thus not remote_written. Metrics # for integrations will be exposed at /integrations/\u003cintegration_key\u003e/metrics # and can be scraped by an external process. ## å¦‚æœè®¾ç½®ä¸ºfalseï¼Œç›¸å…³çš„exporter metricsæ¥å£ä»ä¼šè¢«æš´éœ²å‡ºæ¥ï¼Œä½†æ˜¯grafana-agentä¸ä¼šå»ä¸»åŠ¨æŠ“å–å’Œå‘é€ [scrape_integrations: \u003cboolean\u003e | default = true] # Extra labels to add to all samples coming from integrations. labels: { \u003cstring\u003e: \u003cstring\u003e } # The period to wait before restarting an integration that exits with an # error. [integration_restart_backoff: \u003cduration\u003e | default = \"5s\"] # A list of remote_write targets. Defaults to global_config.remote_write. # If provided, overrides the global defaults. prometheus_remote_write: - [\u003cremote_write\u003e]   é€šè¿‡grafana-agentæŠ“å–ç¬¬ä¸‰æ–¹exporterå¹¶æ”¶é›† å¦‚æ–‡ç« å¼€å¤´æ‰€è¿°ï¼Œå¯¹äºæœªåµŒå…¥åˆ°grafana-agentä¸­çš„exporterï¼Œåˆ™å¯ä»¥åœ¨grafana-agentä¸­é…ç½®scrape_configsæ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œå…¶é…ç½®å½¢å¼å®Œå…¨ç­‰åŒäº prometheus scrape_configsã€‚\ngrafana-agentä¸­å…³äºè‡ªå®šä¹‰é…ç½®scrape_configsçš„è¯¦ç»†è¯´æ˜å¦‚ä¸‹ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # scrape_configs like prometheus style configs: scrape_timeout: 10s # æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é…ç½®æŠ“å– grafana-agent æœ¬èº«çš„ metrics ï¼š http://127.0.0.1:12345/metrics - name: grafana-agent host_filter: false scrape_configs: - job_name: grafana-agent static_configs: - targets: ['127.0.0.1:12345'] remote_write: - url: http://localhost:9090/api/v1/write # å†æ¯”å¦‚,æˆ‘ä»¬ä¹Ÿå¯ä»¥é…ç½®æŠ“å–æ‚¨çš„åº”ç”¨ç¨‹åºæš´éœ²çš„metricsæ¥å£ï¼š http://helloworld.app:8088/metrics - name: outside-exporters host_filter: false scrape_configs: - job_name: prometheus static_configs: - targets: ['127.0.0.1:9090'] labels: cluster: 'fc-monitoring' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e   ",
    "description": "",
    "tags": null,
    "title": "grafana-agenté‡‡é›†å¸¸ç”¨exporter",
    "uri": "/grafana-agent/integrations/"
  },
  {
    "content": " é‡‡ç”¨Docker Composeåšç¼–æ’ï¼Œç”¨äºå•æœºå¿«é€Ÿå¯åŠ¨ç¯å¢ƒåšæµ‹è¯•ï¼ŒåŒ…å«äº†MySQLã€Redisã€Prometheusã€Ibexã€Nightingaleã€Telegraf\n ä»Githubä¸‹è½½å¤œèºçš„æºç ï¼Œè¿›å…¥dockerç›®å½•ï¼Œæ‰§è¡Œdocker-compose up -då³å¯ï¼Œdocker-composeä¼šè‡ªåŠ¨æ‹‰å–é•œåƒå¹¶å¯åŠ¨ï¼ŒæŸ¥çœ‹å„ä¸ªå®¹å™¨å¯åŠ¨çŠ¶æ€ï¼Œä½¿ç”¨å‘½ä»¤docker-compose psï¼Œéƒ½æ˜¯UpçŠ¶æ€åˆ™è¡¨ç¤ºå¯åŠ¨æˆåŠŸã€‚\nå¦‚æœibexã€nserverã€nwebapiç­‰æ¨¡å—ä¸€ç›´åœ¨Restartingï¼Œå¯èƒ½æ˜¯æ•°æ®åº“å®¹å™¨å¯åŠ¨å¤ªæ…¢äº†æ²¡æœ‰å‡†å¤‡å¥½ï¼Œå¯ä»¥æ‰§è¡Œdocker-compose downåœæ‰å†é‡æ–°å°è¯•å¯åŠ¨æµ‹è¯•ï¼Œè¿™ä¸ªé—®é¢˜å—é™äºä¸ªäººçŸ¥è¯†æ°´å¹³ä¸€ç›´ä¸çŸ¥é“å¦‚ä½•è§£å†³ï¼Œå¦‚æœæœ‰å¯¹ docker-compose æœºåˆ¶ç†Ÿæ‚‰çš„å°ä¼™ä¼´å¯ä»¥èµæ•™ä¸‹ï¼Œæ€ä¹ˆä¿è¯å„ä¸ªå®¹å™¨çš„å¯åŠ¨é¡ºåºï¼Œè¦æ±‚ MySQL è¿›ç¨‹å¯åŠ¨ä¹‹åï¼Œå…¶ä»–çš„è¿›ç¨‹æ‰å¯åŠ¨ã€‚\n$ git clone https://github.com/didi/nightingale.git $ cd nightingale/docker $ docker-compose up -d Creating network \"docker_nightingale\" with driver \"bridge\" Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done $ docker-compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u003e10090/tcp, 0.0.0.0:20090-\u003e20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u003e3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u003e19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u003e18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u003e9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u003e6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u003e8092/udp, 0.0.0.0:8094-\u003e8094/tcp, 0.0.0.0:8125-\u003e8125/udp æ›´å¤šdocker-composeç›¸å…³çŸ¥è¯†è¯·å‚è€ƒå®˜ç½‘\nWarningå¯åŠ¨æˆåŠŸä¹‹åï¼Œå»ºè®®æŠŠinitsqlç›®å½•ä¸‹çš„å†…å®¹æŒªèµ°ï¼Œè¿™æ ·ä¸‹æ¬¡é‡å¯çš„æ—¶å€™ï¼ŒDBå°±ä¸ä¼šé‡æ–°åˆå§‹åŒ–äº†ã€‚å¦åˆ™ä¸‹æ¬¡å¯åŠ¨mysqlè¿˜æ˜¯ä¼šè‡ªåŠ¨æ‰§è¡Œinitsqlä¸‹é¢çš„sqlæ–‡ä»¶å¯¼è‡´DBé‡æ–°åˆå§‹åŒ–ï¼Œé¡µé¢ä¸Šåˆ›å»ºçš„è§„åˆ™ã€ç”¨æˆ·ç­‰éƒ½ä¼šä¸¢å¤±ã€‚\ndocker-compose è¿™ç§éƒ¨ç½²æ–¹å¼ï¼Œåªæ˜¯ç”¨äºç®€å•æµ‹è¯•ï¼Œä¸æ¨èåœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼Œå½“ç„¶äº†ï¼Œå¦‚æœæ‚¨æ˜¯ docker-compose ä¸“å®¶ï¼Œå¦å½“åˆ«è®ºã€‚\n æœåŠ¡å¯åŠ¨ä¹‹åï¼Œæµè§ˆå™¨è®¿é—®nwebapiçš„ç«¯å£ï¼Œå³18000ï¼Œé»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020\n",
    "description": "",
    "tags": null,
    "title": "ä½¿ç”¨Dockerå¿«é€Ÿå¯åŠ¨æµ‹è¯•",
    "uri": "/quickstart/compose/"
  },
  {
    "content": "å¯¹äºæœªåµŒå…¥åˆ° grafana-agentä¸­çš„ exporterï¼Œåˆ™å¯ä»¥åœ¨ grafana-agent ä¸­é…ç½® scrape_configs æ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œè¯·å‚è€ƒæŠ“å–ç¬¬ä¸‰æ–¹exporterã€‚\n",
    "description": "",
    "tags": null,
    "title": "grafana-agentæ”¶é›†ä¸‰æ–¹exporter",
    "uri": "/grafana-agent/scrape_exporters/"
  },
  {
    "content": " æœ¬èŠ‚è®²è¿°å¦‚ä½•éƒ¨ç½²å•æœºç‰ˆï¼Œå•æœºç‰ˆå¯¹äºå¾ˆå¤šä¸­å°å…¬å¸è¶³å¤Ÿç”¨äº†ï¼Œç®€å•é«˜æ•ˆã€å¿«é€Ÿç›´æ¥ï¼Œå»ºè®®ä½¿ç”¨äº‘ä¸»æœºï¼Œæ€§èƒ½ä¸å¤Ÿäº†ç›´æ¥å‡é…ï¼Œå¯ä»¥åº”å¯¹æ¯ç§’ä¸ŠæŠ¥çš„æ•°æ®ç‚¹å°äº100ä¸‡çš„æƒ…å½¢ï¼Œå¦‚æœåªæ˜¯ç›‘æ§æœºå™¨ï¼ˆæ¯å°æœºå™¨æ¯ä¸ªå‘¨æœŸå¤§æ¦‚é‡‡é›†200ä¸ªæ•°æ®ç‚¹ï¼‰é‡‡é›†å‘¨æœŸé¢‘ç‡è®¾ç½®10ç§’çš„è¯ï¼Œæ”¯æ’‘ä¸Šé™æ˜¯5ä¸‡å°\n å¦‚æœä»…ä»…æ˜¯ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼ŒDocker éƒ¨ç½²æ–¹å¼æ˜¯æœ€å¿«çš„ï¼Œä¸è¿‡å¾ˆå¤šæœ‹å‹æœªå¿…æœ‰ Docker ç¯å¢ƒï¼Œå¦å¤–ä¸ºäº†å‡å°‘å¼•å…¥æ›´å¤šæŠ€æœ¯æ ˆï¼Œå¢å¼ºç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§ï¼Œæœ‰äº›æœ‹å‹å¯èƒ½ä¹Ÿä¸æ„¿æ„ç”¨ Dockerï¼Œé‚£æœ¬ç¯‡å°±æ¥è®²è§£å¦‚ä½•å¿«é€Ÿéƒ¨ç½²å•æœºç‰ˆï¼Œå•æœºç‰ˆçš„é…å¥—æ—¶åºåº“æ˜¯ä½¿ç”¨ Prometheusã€‚å¦‚æœè¦ç›‘æ§çš„æœºå™¨æœ‰å‡ åƒå°ï¼ŒæœåŠ¡æœ‰å‡ ç™¾ä¸ªï¼Œå•æœºç‰ˆçš„å®¹é‡æ— æ³•æ»¡è¶³ï¼Œå¯ä»¥ä¸Šé›†ç¾¤ç‰ˆï¼Œé›†ç¾¤ç‰ˆçš„æ—¶åºåº“å»ºè®®ä½¿ç”¨ VictoriaMetricsï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ M3DBï¼Œä¸è¿‡ M3DB çš„æ¶æ„æ›´å¤æ‚ï¼Œå¾ˆå¤šæœ‹å‹æ— æ³•æå®šï¼Œé€‰æ‹©ç®€å•çš„ VictoriaMetricsï¼Œå¯¹å¤§éƒ¨åˆ†å…¬å¸æ¥è®²ï¼Œè¶³å¤Ÿç”¨äº†ã€‚æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹æœåŠ¡ç«¯æ¶æ„ï¼š\næŒ‰ç…§å•æœºç‰ˆæœ¬çš„è¿™ä¸ªæ¶æ„å›¾å¯ä»¥çœ‹å‡ºï¼ŒæœåŠ¡ç«¯éœ€è¦å®‰è£…çš„ç»„ä»¶æœ‰ï¼šMySQLã€Redisã€Prometheusã€n9e-serverã€n9e-webapiï¼ŒAgent æœ‰å¤šç§é€‰å‹ï¼Œå¯ä»¥æ˜¯ Telegrafã€Datadog-Agentã€Grafana-Agent ç­‰ï¼ŒAgent åº”è¯¥éƒ¨ç½²åœ¨æ‰€æœ‰çš„ç›®æ ‡æœºå™¨ä¸Šï¼ŒåŒ…æ‹¬æœåŠ¡ç«¯çš„è¿™å°æœºå™¨ï¼ŒExporters æ˜¯æŒ‡ Prometheus ç”Ÿæ€çš„å„ç±» Exporter é‡‡é›†å™¨ï¼Œæ¯”å¦‚ mysqld_exporterã€redis_exporterã€blackbox_exporter ç­‰ï¼Œè¿™äº› Exporter æ˜¯éå¿…é¡»çš„ï¼Œçœ‹å„è‡ªå…¬å¸çš„æƒ…å†µã€‚\nç¯å¢ƒå‡†å¤‡ ä¾èµ–çš„ç»„ä»¶æœ‰ï¼šmysqlã€redisã€prometheusï¼Œè¿™ä¸‰ä¸ªç»„ä»¶éƒ½æ˜¯å¼€æºè½¯ä»¶ï¼Œè¯·å¤§å®¶è‡ªè¡Œå®‰è£…ï¼Œå…¶ä¸­prometheusåœ¨å¯åŠ¨çš„æ—¶å€™è¦æ³¨æ„å¼€å¯ --enable-feature=remote-write-receiver è¿™é‡Œä¹Ÿæä¾›ä¸€ä¸ªå°è„šæœ¬æ¥å®‰è£…è¿™3ä¸ªç»„ä»¶ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒï¼š\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service  cat \u003c\u003cEOF \u003e/etc/systemd/system/prometheus.service [Unit] Description=\"prometheus\" Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \"SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\" # install redis yum install -y redis systemctl enable redis systemctl restart redis ä¸Šä¾‹ä¸­mysqlçš„rootå¯†ç è®¾ç½®ä¸ºäº†1234ï¼Œå»ºè®®ç»´æŒè¿™ä¸ªä¸å˜ï¼Œåç»­å°±çœå»äº†ä¿®æ”¹é…ç½®æ–‡ä»¶çš„éº»çƒ¦ã€‚\nå®‰è£…å¤œèºç»„ä»¶ mkdir -p /opt/n9e \u0026\u0026 cd /opt/n9e # å» https://github.com/didi/nightingale/releases æ‰¾æœ€æ–°ç‰ˆæœ¬çš„åŒ…ï¼Œæ–‡æ¡£é‡Œçš„åŒ…åœ°å€å¯èƒ½å·²ç»ä¸æ˜¯æœ€æ–°çš„äº† tarball=n9e-5.5.0.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.5.0/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u003c docker/initsql/a-n9e.sql nohup ./n9e server \u0026\u003e server.log \u0026 nohup ./n9e webapi \u0026\u003e webapi.log \u0026 # check logs # check port å¦‚æœå¯åŠ¨æˆåŠŸï¼Œserver é»˜è®¤ä¼šç›‘å¬åœ¨ 19000 ç«¯å£ï¼Œwebapi ä¼šç›‘å¬åœ¨ 18000 ç«¯å£ï¼Œä¸”æ—¥å¿—æ²¡æœ‰æŠ¥é”™ã€‚ä¸Šé¢ä½¿ç”¨ nohup ç®€å•æ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ç”¨ systemd æ‰˜ç®¡ï¼Œç›¸å…³ service æ–‡ä»¶å¯ä»¥åœ¨ etc/service ç›®å½•ä¸‹ï¼Œä¾›å‚è€ƒã€‚\né…ç½®æ–‡ä»¶etc/server.confå’Œetc/webapi.confä¸­éƒ½å«æœ‰ mysql çš„è¿æ¥åœ°å€é…ç½®ï¼Œæ£€æŸ¥ä¸€ä¸‹ç”¨æˆ·åå’Œå¯†ç ï¼Œprometheus å¦‚æœä½¿ç”¨ä¸Šé¢çš„è„šæœ¬å®‰è£…ï¼Œé»˜è®¤ä¼šç›‘å¬æœ¬æœº 9090 ç«¯å£ï¼Œserver.conf å’Œ webapi.conf ä¸­çš„ prometheus ç›¸å…³åœ°å€éƒ½ä¸ç”¨ä¿®æ”¹å°±æ˜¯å¯¹çš„ã€‚\nå¥½äº†ï¼Œæµè§ˆå™¨è®¿é—® webapi çš„ç«¯å£ï¼ˆé»˜è®¤æ˜¯18000ï¼‰å°±å¯ä»¥ä½“éªŒç›¸å…³åŠŸèƒ½äº†ï¼Œé»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020ã€‚å¦‚æœå®‰è£…è¿‡ç¨‹å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å‚è€ƒå…¬ä¼—å·ï¼ˆäº‘åŸç”Ÿç›‘æ§ï¼‰çš„è§†é¢‘æ•™ç¨‹ã€‚\nå¤œèºæœåŠ¡ç«¯éƒ¨ç½²å¥½äº†ï¼Œæ¥ä¸‹æ¥è¦è€ƒè™‘ç›‘æ§æ•°æ®é‡‡é›†çš„é—®é¢˜ï¼Œå¦‚æœæ˜¯ Prometheus é‡åº¦ç”¨æˆ·ï¼Œå¯ä»¥ç»§ç»­ä½¿ç”¨å„ç±» Exporter æ¥é‡‡é›†ï¼Œåªè¦æ•°æ®è¿›äº†æ—¶åºåº“äº†ï¼Œå¤œèºå°±èƒ½å¤Ÿæ¶ˆè´¹ï¼ˆåˆ¤æ–­å‘Šè­¦ã€å±•ç¤ºå›¾è¡¨ç­‰ï¼‰ï¼›å¦‚æœæƒ³å¿«é€Ÿçœ‹åˆ°æ•ˆæœï¼Œå¯ä»¥ä½¿ç”¨ Telegraf æ¥é‡‡é›†ç›‘æ§æ•°æ®ï¼Œè¯·å‚è€ƒåç»­æ–‡æ¡£ç« èŠ‚ã€‚\n",
    "description": "",
    "tags": null,
    "title": "ä½¿ç”¨äºŒè¿›åˆ¶éƒ¨ç½²å•æœºç‰ˆæœåŠ¡ç«¯",
    "uri": "/quickstart/standalone/"
  },
  {
    "content": "å¦‚æœæ‚¨å¯¹Dockerçš„ä½¿ç”¨éå¸¸ç†Ÿæ‚‰ï¼Œå»ºè®®åˆ©ç”¨Docker composeçš„æ–¹å¼å¿«é€Ÿå¯åŠ¨æµ‹è¯•ï¼Œè¯·å‚è€ƒä½¿ç”¨Docker Composeå¿«é€Ÿéƒ¨ç½²ï¼Œå¦‚æœå¯¹Dockerä¸ç†Ÿæ‚‰ï¼Œé‚£å°±ç”¨äºŒè¿›åˆ¶æ–¹å¼éƒ¨ç½²ï¼Œä¹Ÿéå¸¸ç®€å•ï¼Œæœ€å°çš„å¯è¿è¡Œç¯å¢ƒæ˜¯Prometheus+MySQL+Redis+Nightingaleï¼Œè¯·å‚è€ƒå¿«é€Ÿåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å¯åŠ¨å•æœºç‰ˆã€‚è¿™ä¸ªæœ€å°çš„ç¯å¢ƒåªæœ‰Prometheusé‡‡é›†åˆ°çš„è‡ªèº«çš„ä¸€äº›ç›‘æ§æŒ‡æ ‡ï¼Œç•¥æ˜¾å•è–„ï¼Œæ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥Telegrafï¼Œé‡‡é›†æœºå™¨ã€ç½‘ç»œè®¾å¤‡ã€å„ç±»ä¸­é—´ä»¶çš„æŒ‡æ ‡ï¼Œè¯·å‚è€ƒä½¿ç”¨Telegrafé‡‡é›†ç›‘æ§æ•°æ®ã€‚\nå¦‚æœå…¬å¸ä½“é‡å¾ˆå¤§ï¼Œå»ºè®®æŠŠå•æœºç‰ˆæœ¬çš„Prometheusæ›¿æ¢ä¸ºVictoriaMetricsï¼Œè¯·å‚è€ƒä½¿ç”¨VictoriaMetricsä½œä¸ºæ—¶åºåº“ã€‚æˆ–è€…ç›´æ¥éƒ¨ç½²å¤šä¸ªPrometheusï¼ŒæŒ‰ç…§ä¸šåŠ¡çº¿æˆ–è€…æŒ‰ç…§åœ°åŸŸæ¥åˆ’åˆ†é›†ç¾¤ï¼Œæ­¤æ—¶ä½ å¯èƒ½éœ€è¦æ¥å…¥å¤šä¸ªProm/VM/M3DBé›†ç¾¤ï¼Œåœ¨å¼•å…¥å¤šä¸ªTSDBçš„è¿‡ç¨‹ä¸­ï¼Œå°±è¦åŒæ­¥ä½¿ç”¨å¤œèºçš„å¤šServeréƒ¨ç½²æ¨¡å‹äº†ï¼Œè¯·å‚è€ƒç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é«˜å¯ç”¨é›†ç¾¤ç‰ˆ\n",
    "description": "",
    "tags": null,
    "title": "å®‰è£…éƒ¨ç½²",
    "uri": "/quickstart/"
  },
  {
    "content": " Telegraf æ˜¯ InfluxData å¼€æºçš„ä¸€æ¬¾é‡‡é›†å™¨ï¼Œå¯ä»¥é‡‡é›†æ“ä½œç³»ç»Ÿã€å„ç§ä¸­é—´ä»¶çš„ç›‘æ§æŒ‡æ ‡ï¼Œé‡‡é›†ç›®æ ‡åˆ—è¡¨ï¼Œçœ‹èµ·æ¥æ˜¯éå¸¸ä¸°å¯Œï¼ŒTelegrafæ˜¯ä¸€ä¸ªå¤§ä¸€ç»Ÿçš„è®¾è®¡ï¼Œå³ä¸€ä¸ªäºŒè¿›åˆ¶å¯ä»¥é‡‡é›†CPUã€å†…å­˜ã€mysqlã€mongodbã€redisã€snmpç­‰ï¼Œä¸åƒPrometheusçš„exporterï¼Œæ¯ä¸ªç›‘æ§å¯¹è±¡ä¸€ä¸ªexporterï¼Œç®¡ç†èµ·æ¥ç•¥éº»çƒ¦ã€‚ä¸€ä¸ªäºŒè¿›åˆ¶åˆ†å‘èµ·æ¥ç¡®å®æ¯”è¾ƒæ–¹ä¾¿ã€‚\n è¿™é‡Œæä¾›å¿«é€Ÿå®‰è£…çš„æ•™ç¨‹ï¼ŒTelegrafçš„æ›´å¤šçŸ¥è¯†ï¼Œè¯·å‚è€ƒTelegrafå®˜ç½‘ï¼Œç¬”è€…ä¹‹å‰ä¹Ÿå†™äº†ä¸€ä¸ªTelegrafè°ƒç ”ç¬”è®°ï¼Œè®²è§£äº†Telegrafçš„åŸºæœ¬ç”¨æ³•ï¼Œä¸€å®šè¦çœ‹ï¼ï¼ï¼ï¼Œå¤§å®¶äº¦å¯å‚è€ƒã€‚\nTelegrafä¸‹è½½åœ°å€åœ¨è¿™é‡Œï¼Œæ ¹æ®è‡ªå·±çš„å¹³å°é€‰æ‹©å¯¹åº”çš„äºŒè¿›åˆ¶ä¸‹è½½å³å¯ã€‚ç¬”è€…çš„ç¯å¢ƒæ˜¯CentOSï¼Œä¸‹é¢æ˜¯å®‰è£…è„šæœ¬ï¼Œ/opt/telegraf/telegraf.conf æ˜¯ä¸€ä¸ªç»è¿‡åˆ å‡çš„å¹²å‡€çš„é…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®šäº†opentsdb output pluginï¼Œè¿™ä¸ªpluginçš„å†™å…¥åœ°å€é…ç½®çš„æ˜¯n9e-serverï¼Œæ‰€ä»¥ï¼ŒTelegrafé‡‡é›†çš„æ•°æ®ä¼šè¢«æ¨é€ç»™n9e-serverï¼ŒäºŒè€…è´¯é€šï¼š\n#!/bin/sh  version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u003c\u003cEOF \u003e /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false [[outputs.opentsdb]] host = \"http://127.0.0.1\" port = 19000 http_batch_size = 50 http_path = \"/opentsdb/put\" debug = false separator = \"_\" [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\", \"iso9660\", \"overlay\", \"aufs\", \"squashfs\"] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\"uptime_format\"] [[inputs.net]] ignore_protocol_stats = true EOF cat \u003c\u003cEOF \u003e /etc/systemd/system/telegraf.service [Unit] Description=\"telegraf\" After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  Warning/opt/telegraf/telegraf.confçš„å†…å®¹æ˜¯ä¸ªåˆ å‡ç‰ˆï¼Œåªæ˜¯ä¸ºäº†è®©å¤§å®¶å¿«é€Ÿè·‘èµ·æ¥ï¼Œå¦‚æœè¦é‡‡é›†æ›´å¤šç›‘æ§å¯¹è±¡ï¼Œæ¯”å¦‚mysqlã€redisã€tomcatç­‰ï¼Œè¿˜æ˜¯è¦ä»”ç»†å»é˜…è¯»ä»tarballé‡Œè§£å‹å‡ºæ¥çš„é‚£ä¸ªé…ç½®æ–‡ä»¶ï¼Œé‚£é‡Œæœ‰å¾ˆè¯¦ç»†çš„æ³¨é‡Šï¼Œä¹Ÿå¯ä»¥å‚è€ƒå®˜æ–¹æä¾›çš„å„ä¸ªé‡‡é›†æ’ä»¶ä¸‹çš„README\n ğŸ’¡ Telegrafå‘Šè­¦ç­–ç•¥ | Telegrafç›‘æ§å¤§ç›˜\n",
    "description": "",
    "tags": null,
    "title": "ä½¿ç”¨Telegrafé‡‡é›†ç›‘æ§æ•°æ®",
    "uri": "/quickstart/telegraf/"
  },
  {
    "content": "åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Deploymentæˆ–è€…Daemonsetçš„æ–¹å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼ŒæŠ“å–å®¿ä¸»æœºä¸Škubeletå’ŒcAdvisorçš„metricsæŒ‡æ ‡ï¼Œå¹¶æŠŠæŠ“å–åˆ°çš„æ•°æ®ï¼Œä»¥remote_writeçš„æ–¹å¼æ¨é€åˆ°Nightingale.\né€šè¿‡æœ¬æ–‡æ¡£ï¼Œæˆ‘ä»¬é¢„æœŸè¾¾æˆä»¥ä¸‹ç›®æ ‡ï¼š\n éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼› é…ç½®grafana-agentæŠ“å–kubeletå’ŒcAdvisorçš„metricsï¼›  K8sæ˜¯å¼€æºçš„å®¹å™¨ç¼–æ’ç³»ç»Ÿï¼Œè‡ªåŠ¨åŒ–ç®¡ç†å®¹å™¨çš„éƒ¨ç½²ã€æ‰©ç¼©å®¹ç­‰å·¥ä½œã€‚K8sé»˜è®¤ä¼šæš´éœ²Nodeå’Œæ§åˆ¶é¢çš„è‹¥å¹²metricsæ¥å£ï¼Œè¿™äº›æ¥å£å…¼å®¹Prometheusçš„metricsè§„èŒƒã€‚æˆ‘ä»¬å¯ä»¥éƒ¨ç½²grafana-agentæ¥æ”¶é›†Nodeçš„cAdvisorå’Œkubelet metricsï¼Œå¹¶ä»¥remote_writeçš„æ–¹å¼å‘é€åˆ°Nightingale.\nå‰ç½®ä¾èµ–  ä¸€ä¸ªå¼€å¯RBACï¼ˆrole-based access controlï¼‰çš„Kubernetesé›†ç¾¤ï¼› å®‰è£…å¹¶é…ç½®å¥½äº†kubectlå‘½ä»¤è¡Œå·¥å…·ï¼›  æ­¥éª¤ä¸€ï¼šåˆ›å»º ServiceAcountã€ClusterRoleã€ClusterRoleBinding export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-bare.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f - æ­¥éª¤äºŒï¼šåˆ›å»ºConfigMapï¼Œé…ç½®grafana-agent export NAMESPACE=default export CLUSTER_NAME=kubernetes export FC_REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write #export FC_REMOTE_WRITE_URL=https://n9e-server:19000/prometheus/v1/write #export FC_REMOTE_WRITE_USERNAME=fc_laiwei #export FC_REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u003c\u003cEOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: integrations remote_write: - url: ${FC_REMOTE_WRITE_URL} basic_auth: username: ${FC_REMOTE_WRITE_USERNAME} password: ${FC_REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/cadvisor bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node metric_relabel_configs: - action: drop regex: container_([a-z_]+); source_labels: - __name__ - image - action: drop regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s) source_labels: - __name__ relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics/cadvisor source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes - job_name: integrations/kubernetes/kubelet bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes EOF envsubst | kubectl apply -n $NAMESPACE -f - æ­¥éª¤ä¸‰ï¼šåœ¨K8sä¸­åˆ›å»ºgrafana-agentå®ä¾‹  Daemonset\n å¯¹äºé‡‡é›† node_exporter/ kubelet/ cAdvisorç­‰æŒ‡æ ‡ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šåªè¿è¡Œä¸€ä¸ªgrafana-agentå®ä¾‹çš„æƒ…å†µï¼Œæ¨èä»¥daemonsetè¿è¡Œ export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-daemonset.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  Deployment\n å¯¹äºé‡‡é›†MySQLd_Exporterç­‰éœ€è¦è¿è¡Œå¤šä¸ªgrafana-agentå®ä¾‹çš„æƒ…å†µï¼Œæ¨èä»¥deploymentè¿è¡Œã€‚ export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-deployment.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f - å¦‚ä½•é‡å»ºgrafana-agent  Daemonset\n kubectl rollout restart daemonset/grafana-agent  Deployment\n kubectl rollout restart deployment/grafana-agent è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†åœ¨K8sä¸­éƒ¨ç½²grafana-agentå¹¶æ”¶é›†metricsï¼Œè¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é…ç½®grafana-agentæ¥å»ºç«‹èµ·å®Œæ•´çš„kubernetesæŒ‡æ ‡ç›‘æ§ä½“ç³»ã€‚\n",
    "description": "",
    "tags": null,
    "title": "åœ¨K8sä¸­è¿è¡Œgrafana-agentæ”¶é›†metrics",
    "uri": "/grafana-agent/k8s_metrics/"
  },
  {
    "content": " VictoriaMetrics æ¶æ„ç®€å•ï¼Œå¯é æ€§é«˜ï¼Œåœ¨æ€§èƒ½ï¼Œæˆæœ¬ï¼Œå¯æ‰©å±•æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç¤¾åŒºæ´»è·ƒï¼Œä¸”å’Œ Prometheus ç”Ÿæ€ç»‘å®šç´§å¯†ã€‚å¤œèºæ¨èæ‚¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ VictoriaMetrics ä½œä¸ºæ—¶åºæ•°æ®åº“ã€‚\n VictoriaMetrics æä¾›å•æœºç‰ˆå’Œé›†ç¾¤ç‰ˆã€‚å¦‚æœæ‚¨çš„æ¯ç§’å†™å…¥æ•°æ®ç‚¹æ•°å°äº100ä¸‡ï¼ŒVictoriaMetrics å®˜æ–¹é»˜è®¤æ¨èæ‚¨ä½¿ç”¨å•æœºç‰ˆï¼Œå•æœºç‰ˆå¯ä»¥é€šè¿‡å¢åŠ æœåŠ¡å™¨çš„CPUæ ¸å¿ƒæ•°ï¼Œå¢åŠ å†…å­˜ï¼Œå¢åŠ IOPSæ¥è·å¾—çº¿æ€§çš„æ€§èƒ½æå‡ã€‚ä¸”å•æœºç‰ˆæ˜“äºé…ç½®å’Œè¿ç»´ã€‚\næ¥ä¸‹æ¥çš„æ–‡ç« ï¼Œä»‹ç»åœ¨å¤œèºä¸­ï¼Œä»¥ VictoriaMetrics é›†ç¾¤ç‰ˆæœ¬ä½œä¸ºæ—¶åºæ•°æ®åº“ä¸ºä¾‹ï¼Œå®Œæ•´çš„å®‰è£…å’Œé…ç½®è¿‡ç¨‹ã€‚\nvmstorageã€vminsertã€vmselect ä¸‰è€…ç»„åˆæ„æˆ VictoriaMetrics çš„é›†ç¾¤åŠŸèƒ½ï¼Œä¸‰è€…éƒ½å¯ä»¥é€šè¿‡å¯åŠ¨å¤šä¸ªå®ä¾‹æ¥åˆ†æ‹…æ‰¿è½½æµé‡ã€‚\n vmstorage æ˜¯æ•°æ®å­˜å‚¨æ¨¡å—ï¼š\n  å…¶æ•°æ®ä¿å­˜åœ¨-storageDataPathæŒ‡å®šçš„ç›®å½•ä¸­ï¼Œé»˜è®¤ä¸º./vmstorage-data/ï¼Œvmstorage æ˜¯æœ‰çŠ¶æ€æ¨¡å—ï¼Œåˆ é™¤ storage node ä¼šä¸¢å¤±çº¦ 1/Nçš„å†å²æ•°æ®ï¼ˆN ä¸ºé›†ç¾¤ä¸­ vmstorage node çš„èŠ‚ç‚¹æ•°é‡ï¼‰ã€‚å¢åŠ  storage nodeï¼Œåˆ™éœ€è¦åŒæ­¥ä¿®æ”¹ vminsert å’Œ vmselect çš„å¯åŠ¨å‚æ•°ï¼Œå°†æ–°åŠ å…¥çš„storage nodeèŠ‚ç‚¹åœ°å€é€šè¿‡å‘½ä»¤è¡Œå‚æ•° -storageNodeä¼ å…¥ç»™vminsertå’Œvmselectã€‚ vmstorage å¯åŠ¨åï¼Œä¼šç›‘å¬ä¸‰ä¸ªç«¯å£ï¼Œåˆ†åˆ«æ˜¯ -httpListenAddr :8482ã€-vminsertAddr :8400ã€-vmselectAddr :8401ã€‚ç«¯å£8400è´Ÿè´£æ¥æ”¶æ¥è‡ª vminsert çš„å†™å…¥è¯·æ±‚ï¼Œç«¯å£8401è´Ÿè´£æ¥æ”¶æ¥è‡ª vmselect çš„æ•°æ®æŸ¥è¯¢è¯·æ±‚ï¼Œç«¯å£8482åˆ™æ˜¯ vmstorage è‡ªèº«æä¾›çš„ http api æ¥å£ã€‚   vminsert æ¥æ”¶æ¥è‡ªå®¢æˆ·ç«¯çš„æ•°æ®å†™å…¥è¯·æ±‚ï¼Œå¹¶è´Ÿè´£è½¬å‘åˆ°é€‰å®šçš„vmstorageï¼š\n  vminsert æ¥æ”¶åˆ°æ•°æ®å†™å…¥è¯·æ±‚åï¼ŒæŒ‰ç…§ jump consistent hash ç®—æ³•ï¼Œå°†æ•°æ®è½¬å‘åˆ°é€‰å®šçš„æŸä¸ªvmstorage node ä¸Šã€‚vminsert æœ¬èº«æ˜¯æ— çŠ¶æ€æ¨¡å—ï¼Œå¯ä»¥å¢åŠ æˆ–è€…åˆ é™¤ä¸€ä¸ªæˆ–å¤šä¸ªå®ä¾‹ï¼Œè€Œä¸ä¼šé€ æˆæ•°æ®çš„æŸå¤±ã€‚vminsert æ¨¡å—é€šè¿‡å¯åŠ¨æ—¶çš„å‚æ•° -storageNode xxx,yyy,zzz æ¥æ„ŸçŸ¥åˆ°æ•´ä¸ª vmstorage é›†ç¾¤çš„å®Œæ•´ node åœ°å€åˆ—è¡¨ã€‚ vminsert å¯åŠ¨åï¼Œä¼šç›‘å¬ä¸€ä¸ªç«¯å£-httpListenAddr :8480ã€‚è¯¥ç«¯å£å®ç°äº† prometheus remote_writeåè®®ï¼Œå› æ­¤å¯ä»¥æ¥æ”¶å’Œè§£æé€šè¿‡ remote_write åè®®å†™å…¥çš„æ•°æ®ã€‚ä¸è¿‡è¦æ³¨æ„ï¼ŒVictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å…·æœ‰å¤šç§Ÿæˆ·åŠŸèƒ½ï¼Œå› æ­¤ç§Ÿæˆ·IDä¼šä»¥å¦‚ä¸‹å½¢å¼å‡ºç°åœ¨ API URL ä¸­: http://vminsert:8480/insert/\u003caccount_id\u003e/prometheus/api/v1/writeã€‚ æ›´å¤š URL Format å¯ä»¥å‚è€ƒ VictoriaMetricså®˜ç½‘ã€‚   vmselect æ¥æ”¶æ¥è‡ªå®¢æˆ·ç«¯çš„æ•°æ®æŸ¥è¯¢è¯·æ±‚ï¼Œå¹¶è´Ÿè´£è½¬å‘åˆ°æ‰€æœ‰çš„ vmstorage æŸ¥è¯¢ç»“æœå¹¶åˆå¹¶ï¼š\n  vmselect å¯åŠ¨åï¼Œä¼šç›‘å¬ä¸€ä¸ªç«¯å£-httpListenAddr :8481ã€‚è¯¥ç«¯å£å®ç°äº† prometheus remote_queryç­‰åè®®ï¼Œå› æ­¤å¯ä»¥æ¥æ”¶å’Œè§£æ remote_query åè®®çš„æŸ¥è¯¢ã€‚ä¸è¿‡è¦æ³¨æ„ï¼ŒVictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å…·æœ‰å¤šç§Ÿæˆ·åŠŸèƒ½ï¼Œå› æ­¤ç§Ÿæˆ·IDä¼šä»¥å¦‚ä¸‹å½¢å¼å‡ºç°åœ¨ API URL ä¸­: http://vminsert:8481/select/\u003caccount_id\u003e/prometheus/api/v1/queryã€‚ æ›´å¤š URL Format å¯ä»¥å‚è€ƒ VictoriaMetricså®˜ç½‘ã€‚  ä¸‹è½½å’Œå®‰è£… VictoriaMetrics é›†ç¾¤ç‰ˆ  å» vm release ä¸‹è½½ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶ç‰ˆæœ¬ï¼Œæ¯”å¦‚æˆ‘ä»¬é€‰æ‹©ä¸‹è½½ v1.69.0 amd64ã€‚ è§£å‹ç¼©åå¾—åˆ°ï¼š  $ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  å¯åŠ¨ä¸‰ä¸ª vmstorage å®ä¾‹(å¯ä»¥ç”¨ä¸‹é¢çš„è„šæœ¬å¿«é€Ÿç”Ÿæˆä¸åŒå®ä¾‹çš„å¯åŠ¨å‘½ä»¤)ï¼š  #!/bin/bash  for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\"\" fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\"nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath\\ -httpListenAddr :$httpListenAddr\\ -vminsertAddr :$vminsertAddr\\ -vmselectAddr :$vmselectAddr\\ \u0026\u003e ${pp}vmstor.log \u0026\" echo $prog (exec \"$prog\") done ä¹Ÿå¯ä»¥è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¡Œå¯åŠ¨ä¸‰ä¸ªå®ä¾‹ï¼š\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026\u003e vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026\u003e 1vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026\u003e 2vmstor.log \u0026  å¯åŠ¨ä¸€ä¸ª vminsert å®ä¾‹ï¼š  nohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026\u003evminsert.log \u0026  å¯åŠ¨ä¸€ä¸ª vmselect å®ä¾‹ï¼š  nohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026\u003evmselect.log \u0026  æŸ¥çœ‹ vmstorageï¼Œvminsertï¼Œvmselect çš„ /metrics æ¥å£:  curl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  n9e-serveré€šè¿‡remote writeæ¥å£å†™å…¥æ—¶åºåº“ï¼Œvmä½œä¸ºæ—¶åºåº“çš„ä¸€ä¸ªé€‰æ‹©ï¼Œå…¶remote writeæ¥å£åœ°å€ä¸ºï¼šhttp://127.0.0.1:8480/insert/0/prometheus/api/v1/write æŠŠè¿™ä¸ªåœ°å€é…ç½®åˆ°server.confå½“ä¸­å³å¯ï¼Œé…ç½®å®Œäº†é‡å¯n9e-server  # Readeréƒ¨åˆ†ä¿®æ”¹Url [Reader] Url = \"http://172.21.0.8:8481/select/0/prometheus\" # Writerséƒ¨åˆ†ä¿®æ”¹Url [[Writers]] Url = \"http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\"  ä¿®æ”¹æ‚¨çš„ n9e-webapi çš„é…ç½®æ–‡ä»¶ ./etc/webapi.conf å¦‚ä¸‹ï¼š  [[Clusters]] # Prometheus cluster name Name = \"Default\" # Prometheus APIs base url Prom = \"http://127.0.0.1:8481/select/0/prometheus\" ç„¶åï¼Œé‡æ–°å¯åŠ¨n9e-webapiï¼Œè¿™æ ·å¤œèºå°±å¯ä»¥é€šè¿‡ remote query æŸ¥è¯¢åˆ° victoriametrics é›†ç¾¤çš„æ•°æ®äº†ã€‚\nInfon9e-webapi çš„å®‰è£…ã€é…ç½®å’Œå¯åŠ¨ï¼Œè¯·å‚è€ƒ è¿™é‡Œã€‚\n FAQ  VictoriaMetrics å•æœºç‰ˆæœ¬å¦‚ä½•ä¿éšœæ•°æ®çš„å¯é æ€§ï¼Ÿ  vm é’ˆå¯¹ç£ç›˜IOæœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ï¼Œå•æœºç‰ˆå¯ä»¥è€ƒè™‘å°†æ•°æ®çš„å¯é æ€§ä¿éšœäº¤ç»™ EBS ç­‰äº‘ç›˜æ¥ä¿è¯ã€‚\n  VictoriaMetrics å¦‚ä½•è¯„ä¼°å®¹é‡ï¼Ÿ  å‚è€ƒvmçš„å®˜æ–¹æ–‡æ¡£ã€‚\n  VictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å¢åŠ æˆ–è€…åˆ é™¤vmstorage Nodeçš„æ—¶å€™ï¼Œæ•°æ®å¦‚ä½•å†å¹³è¡¡ï¼Ÿ  vm ä¸æ”¯æŒæ‰©ç¼©å®¹èŠ‚ç‚¹æ—¶ï¼Œå¯¹æ•°æ®è¿›è¡Œè‡ªåŠ¨çš„å†å¹³è¡¡ã€‚\n  VictoriaMetrics çš„æ•°æ®å¤§å°å¦‚ä½•æŸ¥çœ‹ï¼Ÿ  å¯ä»¥é€šè¿‡ vmstorage å®ä¾‹æš´éœ²çš„ /metrics æ¥å£æ¥è·å–åˆ°ç›¸åº”çš„ç»Ÿè®¡æ•°æ®ï¼Œè­¬å¦‚ï¼š\n $ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\"indexdb\"} 609291 vm_data_size_bytes{type=\"storage/big\"} 0 vm_data_size_bytes{type=\"storage/small\"} 8749893  vminsert åœ¨å°†æ•°æ®å†™å…¥å¤šä¸ª vmstorage Nodeçš„æ—¶å€™ï¼Œæ˜¯æŒ‰ç…§ä»€ä¹ˆè§„åˆ™å°†æ•°æ®å†™å…¥åˆ°ä¸åŒçš„ node ä¸Šçš„ï¼Ÿ  é‡‡ç”¨jump consistent hash å¯¹æ•°æ®è¿›è¡Œåˆ†ç‰‡ï¼Œå†™å…¥åˆ°ç›¸åº”çš„storage nodeä¸Šã€‚\n  vmselect åœ¨æ¥åˆ°æŸ¥è¯¢è¯·æ±‚çš„æ—¶å€™ï¼Œå¦‚ä½•å®šä½åˆ°è¯·æ±‚çš„æ•°æ®æ˜¯åœ¨å“ªä¸ª storage nodeä¸Šçš„ï¼Ÿ  vmselect å¹¶ä¸çŸ¥é“æ¯ä¸ªmetricså¯¹åº”çš„æ•°æ®åˆ†å¸ƒçš„storage nodeï¼Œvmselectä¼šå¯¹æ‰€æœ‰çš„storage nodeå‘èµ·æŸ¥è¯¢è¯·æ±‚ï¼Œæœ€åè¿›è¡Œæ•°æ®åˆå¹¶ï¼Œå¹¶è¿”å›ã€‚\n  VictoriaMetrics å’Œ M3db çš„å¯¹æ¯”å’Œé€‰æ‹©ï¼Ÿ  m3dbæ¶æ„è®¾è®¡ä¸Šæ›´é«˜çº§ï¼Œå®ç°éš¾åº¦é«˜ï¼Œm3dbåœ¨æ—¶åºæ•°æ®åŠŸèƒ½ä¹‹åï¼Œé‡ç‚¹è§£å†³äº†è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œæ•°æ®è‡ªåŠ¨å¹³è¡¡ç­‰è¿ç»´éš¾é¢˜ã€‚ä½†æ˜¯å› æ­¤ä¹Ÿæ›´å¤æ‚ï¼Œå¯é æ€§ç›®å‰ä¹Ÿæ›´éš¾ä¿è¯ã€‚VictoriaMetricsæ¶æ„è®¾è®¡ä¸Šçš„tradeoff æ›´å€¾å‘äºç®€å•å¯é ï¼Œé‡ç‚¹ä¼˜åŒ–äº†å•æœºç‰ˆçš„æ€§èƒ½ï¼Œå¼ºè°ƒå‚ç›´æ‰©å±•ï¼ŒåŒæ—¶å’Œprometheus ç”Ÿæ€åšåˆ°å…¼å®¹ï¼Œç”šè‡³äºåœ¨å¾ˆå¤šçš„ç‚¹ä¸Šåšåˆ°äº†åŠ å¼ºã€‚ä½†æ˜¯ VictoriaMetrics å¯¹äºæ—¶åºæ•°æ®downsampleï¼ŒèŠ‚ç‚¹çš„è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œæ•°æ®è‡ªåŠ¨å†å¹³è¡¡ç­‰é«˜çº§åŠŸèƒ½å’Œåˆ†å¸ƒå¼èƒ½åŠ›ï¼Œæ˜¯æœ‰ç¼ºå¤±çš„ã€‚\n   Infoå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯VictoriaMetricså•æœºç‰ˆï¼Œnightingale çš„é…ç½®æ–‡ä»¶éœ€è¦åšå¦‚ä¸‹è°ƒæ•´ï¼š\n # Readeréƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [Reader] Url = \"http://127.0.0.1:8428\" # Writerséƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [[Writers]] Url = \"http://127.0.0.1:8428/api/v1/write\" # Clusterséƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [[Clusters]] # Prometheus cluster name Name = \"Default\" # Prometheus APIs base url Prom = \"http://127.0.0.1:8428\" ç›¸å…³èµ„æ–™  ä½¿ç”¨ Docker Compose å¿«é€Ÿéƒ¨ç½² VictoriaMetricsã€‚ ä½¿ç”¨ Helm Chart å¿«é€Ÿåœ¨ Kubernetesä¸­éƒ¨ç½² VictoriaMetricsã€‚ ä½¿ç”¨ VictoriaMetrics Operator åœ¨ Kubernetesä¸­éƒ¨ç½² VictoriaMetricsã€‚ VictoriaMetrics é›†ç¾¤ç‰ˆæ¶æ„ï¼š   ",
    "description": "",
    "tags": null,
    "title": "ä½¿ç”¨VictoriaMetricsä½œä¸ºæ—¶åºåº“",
    "uri": "/quickstart/victoriametrics/"
  },
  {
    "content": "åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Daemonsetçš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„æ—¥å¿—ï¼Œå¹¶å°†å…¶æ¨é€åˆ°Nightingale.\n",
    "description": "",
    "tags": null,
    "title": "åœ¨K8sä¸­è¿è¡Œgrafana-agentæ”¶é›†log",
    "uri": "/grafana-agent/k8s_logs/"
  },
  {
    "content": "åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥ Deployment çš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„traceæ•°æ®ï¼Œå¹¶å°†å…¶æ¨é€åˆ°Nightingale.\n",
    "description": "",
    "tags": null,
    "title": "åœ¨K8sä¸­è¿è¡Œgrafana-agentæ”¶é›†trace",
    "uri": "/grafana-agent/k8s_traces/"
  },
  {
    "content": "ç”±äºPrometheusæ²¡æœ‰é›†ç¾¤ç‰ˆæœ¬ï¼Œå—é™äºå®¹é‡é—®é¢˜ï¼Œå¾ˆå¤šå…¬å¸ä¼šæ­å»ºå¤šå¥—Prometheusï¼Œæ¯”å¦‚æŒ‰ç…§ä¸šåŠ¡æ‹†åˆ†ï¼Œä¸åŒçš„ä¸šåŠ¡ä½¿ç”¨ä¸åŒçš„Prometheusé›†ç¾¤ï¼Œæˆ–è€…æŒ‰ç…§åœ°åŸŸæ‹†åˆ†ï¼Œä¸åŒçš„åœ°åŸŸä½¿ç”¨ä¸åŒçš„Prometheusé›†ç¾¤ã€‚è¿™é‡Œæ˜¯ä»¥Prometheusæ¥ä¸¾ä¾‹ï¼ŒVictoriaMetricsã€M3DBéƒ½æœ‰é›†ç¾¤ç‰ˆæœ¬ï¼Œä¸è¿‡æœ‰æ—¶ä¸ºäº†ä¸ç›¸äº’å¹²æ‰°å’Œåœ°åŸŸç½‘ç»œé—®é¢˜ï¼Œä¹Ÿä¼šæ‹†æˆå¤šä¸ªé›†ç¾¤ã€‚å¯¹äºå¤šé›†ç¾¤çš„ååŒï¼Œéœ€è¦åœ¨å¤œèºé‡Œåšä¸€äº›é…ç½®ï¼Œå›é¡¾ä¸€ä¸‹å¤œèºçš„æ¶æ„å›¾ï¼š\nå›¾ä¸Šåˆ†äº† 3 ä¸ª regionï¼Œæ¯ä¸ª region ä¸€å¥—æ—¶åºåº“ï¼Œæ¯ä¸ª region ä¸€å¥— n9e-serverï¼Œn9e-server ä¾èµ– redisï¼Œæ‰€ä»¥æ¯ä¸ª region ä¸€ä¸ª redisï¼Œn9e-webapi å’Œ mysql æ”¾åˆ°ä¸­å¿ƒï¼Œn9e-webapi ä¹Ÿä¾èµ–ä¸€ä¸ª redisï¼Œæ‰€ä»¥ä¸­å¿ƒç«¯æ”¾ç½®çš„æ˜¯ n9e-webapiã€redisã€mysqlï¼Œå¦‚æœæƒ³å›¾çœäº‹ï¼Œredis ä¹Ÿæ˜¯å¯ä»¥å¤ç”¨çš„ï¼Œå„ä¸ª region çš„ n9e-server éƒ½è¿æ¥ä¸­å¿ƒçš„ redis ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚\nä¸ºäº†é«˜å¯ç”¨ï¼Œå„ä¸ª region çš„ n9e-server å¯ä»¥å¤šéƒ¨ç½²å‡ ä¸ªå®ä¾‹ç»„æˆä¸€ä¸ªé›†ç¾¤ï¼Œé›†ç¾¤ä¸­çš„æ‰€æœ‰ n9e-server çš„é…ç½®æ–‡ä»¶ server.conf ä¸­çš„ ClusterName è¦è®¾ç½®æˆä¸€æ ·çš„å­—ç¬¦ä¸²ã€‚\nå‡è®¾ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªæ—¶åºåº“ï¼Œåœ¨åŒ—äº¬æ­å»ºäº†ä¸€ä¸ª Prometheusï¼Œåœ¨å¹¿å·æ­å»ºäº†ä¸€ä¸ª VictoriaMetricsï¼Œn9e-webapi ä¼šæŠŠè¿™ä¸¤ä¸ªæ—¶åºåº“ä½œä¸º DataSourceï¼Œæ‰€ä»¥åœ¨ n9e-webapi çš„é…ç½®æ–‡ä»¶ä¸­ï¼Œè¦é…ç½®ä¸Šè¿™ä¿©å­˜å‚¨çš„åœ°å€ï¼Œä¸¾ä¾‹ï¼š\n[[Clusters]] # cluster name Name = \"Prom-Beijing\" # Prometheus APIs base url Prom = \"http://10.2.3.4:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 [[Clusters]] # cluster name Name = \"VM-Guangzhou\" # Prometheus APIs base url Prom = \"http://172.21.0.8:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 å¦å¤–å›¾ä¸Šä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œä¸€ä¸ª n9e-server å¯¹åº”ä¸€ä¸ªæ—¶åºåº“ï¼Œæ‰€ä»¥åœ¨ n9e-server çš„é…ç½®æ–‡ä»¶ä¸­ï¼Œä¹Ÿéœ€è¦é…ç½®å¯¹åº”çš„æ—¶åºåº“çš„åœ°å€ï¼Œæ¯”å¦‚åŒ—äº¬çš„ serverï¼Œé…ç½®å¦‚ä¸‹ï¼ŒWriters ä¸‹é¢çš„ Url é…ç½®çš„æ˜¯ remote write çš„åœ°å€ï¼Œè€Œ Reader ä¸‹é¢é…ç½®çš„ Url æ˜¯å®ç°Prometheus åŸç”ŸæŸ¥è¯¢æ¥å£çš„ BaseUrlã€‚\n[Reader] # prometheus base url Url = \"http://127.0.0.1:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Url = \"http://127.0.0.1:9090/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 å‡è®¾ä¸Šæµ·åŒºåŸŸç”¨çš„æ˜¯ VictoriaMetricsï¼Œæ‰€ä»¥ Url ç•¥æœ‰ä¸åŒï¼Œé…ç½®å¦‚ä¸‹ï¼š\n[Reader] # prometheus base url Url = \"http://127.0.0.1:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Url = \"http://127.0.0.1:8480/insert/0/prometheus/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 n9e-webapi æ˜¯è¦å“åº”å‰ç«¯ ajax è¯·æ±‚çš„ï¼Œå‰ç«¯ä¼šä» n9e-webapi æŸ¥è¯¢ç›‘æ§æ•°æ®ï¼Œn9e-webapi è‡ªèº«ä¸å­˜å‚¨ç›‘æ§æ•°æ®ï¼Œè€Œæ˜¯ä»…ä»…åšäº†ä¸€ä¸ªä»£ç†ï¼ŒæŠŠè¯·æ±‚ä»£ç†ç»™åç«¯çš„æ—¶åºåº“ï¼Œå‰ç«¯è¯»å–æ•°æ®æ—¶ä¼šè°ƒç”¨ Prometheus çš„é‚£äº›åŸç”Ÿæ¥å£ï¼Œå³ï¼š/api/v1/query /api/v1/query_range /api/v1/labels è¿™ç§æ¥å£ï¼Œæ‰€ä»¥æ³¨æ„å•¦ï¼Œn9e-webapi ä¸­é…ç½®çš„ Clusters ä¸‹é¢çš„Urlï¼Œéƒ½æ˜¯è¦æ”¯æŒPrometheus åŸç”Ÿæ¥å£çš„ BaseUrlã€‚\nå¯¹äº n9e-serverï¼Œæœ‰ä¸¤ä¸ªé‡è¦ä½œç”¨ï¼Œä¸€ä¸ªæ˜¯æ¥æ”¶ç›‘æ§æ•°æ®ï¼Œç„¶åè½¬å‘ç»™åç«¯å¤šä¸ª Writerï¼Œæ‰€ä»¥ï¼ŒWriter å¯ä»¥é…ç½®å¤šä¸ªï¼Œé…ç½®æ–‡ä»¶æ˜¯ toml æ ¼å¼ï¼Œ[[Writers]]åŒä¸­æ‹¬å·è¿™ç§å°±è¡¨ç¤ºæ•°ç»„ï¼Œæ•°æ®å†™ç»™åç«¯å­˜å‚¨ï¼Œèµ°çš„åè®®æ˜¯ Prometheus çš„ Remote Writeï¼Œæ‰€ä»¥ï¼Œæ‰€æœ‰æ”¯æŒ Remote Write çš„å­˜å‚¨ï¼Œéƒ½å¯ä»¥ä½¿ç”¨ã€‚n9e-server çš„å¦ä¸€ä¸ªé‡è¦ä½œç”¨ï¼Œæ˜¯åšå‘Šè­¦åˆ¤æ–­ï¼Œä¼šå‘¨æœŸæ€§ä» mysql åŒæ­¥å‘Šè­¦è§„åˆ™ï¼Œç„¶åæ ¹æ®ç”¨æˆ·é…ç½®çš„ PromQL è°ƒç”¨æ—¶åºåº“çš„ query æ¥å£ï¼Œæ‰€ä»¥ n9e-server çš„ Reader ä¸‹é¢çš„ Urlï¼Œä¹Ÿæ˜¯è¦é…ç½®æ”¯æŒ Prometheus åŸç”Ÿæ¥å£çš„ BaseUrlã€‚å¦å¤–æ³¨æ„ï¼ŒWriter å¯ä»¥é…ç½®å¤šä¸ªï¼Œä½†æ˜¯ Reader åªèƒ½é…ç½®ä¸€ä¸ªã€‚æ¯”å¦‚ç›‘æ§æ•°æ®å¯ä»¥å†™ä¸€ä»½åˆ°Prometheus å­˜å‚¨è¿‘æœŸæ•°æ®ç”¨äºå‘Šè­¦åˆ¤æ–­ï¼Œå†å†™ä¸€ä»½åˆ° OpenTSDB å­˜å‚¨é•¿æœŸæ•°æ®ï¼ŒWriter å°±å¯ä»¥é…ç½®ä¸º Prometheus å’Œ OpenTSDB è¿™ä¸¤ä¸ªï¼Œè€Œ Reader åªé…ç½® Prometheus å³å¯ã€‚\n",
    "description": "",
    "tags": null,
    "title": "æ¥å…¥å¤šä¸ªProm/VM/M3DBé›†ç¾¤",
    "uri": "/quickstart/multitsdb/"
  },
  {
    "content": "å¯¹äºè§„æ¨¡ç›¸å¯¹è¾ƒå°çš„å…¬å¸ï¼Œæ¯”å¦‚å‡ ç™¾å°æœºå™¨è¿™ä¸ªä½“é‡ï¼Œä¸ªäººè®¤ä¸ºå•æœºç‰ˆè¶³å¤Ÿç”¨äº†ï¼Œä½¿ç”¨äº‘ä¸»æœºéƒ¨ç½²ï¼Œæ€§èƒ½ä¸è¶³å¯ä»¥ç›´æ¥å‡é…ï¼Œå­˜å‚¨ä½¿ç”¨äº‘å­˜å‚¨ä¿è¯ï¼Œç¡¬ä»¶æ•…éšœäº‘å¹³å°ä¹Ÿä¼šè‡ªåŠ¨æŠŠè™šæ‹Ÿæœºçƒ­è¿ç§»èµ°ï¼Œéå¸¸çœå¿ƒã€‚é‚£å¦‚æœå’±ä»¬ä½“é‡ç¡®å®æ¯”è¾ƒå¤§ï¼Œæˆ–è€…æ²¡æœ‰äº‘ä¸»æœºè¿™ç§åŸºç¡€è®¾æ–½ï¼Œè¿™é‡Œä¼šè®²è§£é›†ç¾¤ç‰ˆçš„éƒ¨ç½²æ–¹å¼ã€‚\næ—¶åºåº“ æ—¶åºåº“çš„é›†ç¾¤éƒ¨ç½²ï¼Œå°±çœ‹æ—¶åºåº“è‡ªèº«çš„æœºåˆ¶äº†ï¼Œè¿™é‡Œä¸å±•å¼€ï¼Œå¦‚æœæ˜¯ä½¿ç”¨ Prometheusï¼ŒPrometheus æ²¡æœ‰é›†ç¾¤ç‰ˆï¼ŒVictoriaMetricsã€M3DBã€Thanos ç­‰éƒ½æ˜¯æœ‰é›†ç¾¤ç‰ˆçš„ï¼Œè¯·å‚è€ƒä»–ä»¬çš„æ–‡æ¡£\nMySQL MySQL ä¸€èˆ¬éƒ¨ç½²æˆä¸»ä»ï¼Œè¿™ä¸ªè¯·ä½ ä»¬çš„ DBA æ¥æå§ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨äº‘ä¸Š RDSï¼Œè¿™é‡Œå°±ä¸å±•å¼€äº†\nRedis å¤œèºå½“å‰ n9e-webapi å’Œ n9e-server éƒ½ä¾èµ– redisï¼Œredis ä¸€èˆ¬æœ‰ä¸‰ç§æ¨¡å¼ï¼Œå•æœºæ¨¡å¼ã€é›†ç¾¤æ¨¡å¼ã€å“¨å…µæ¨¡å¼ï¼Œå¤œèºå½“å‰åªæ”¯æŒå•æœºæ¨¡å¼ã€‚å…·ä½“ä½¿ç”¨å‡ ä¸ª redisï¼Œè¦çœ‹å¤§å®¶çš„ç¯å¢ƒæƒ…å†µï¼Œå¦‚æœå›¾çœäº‹ï¼Œå…¨å±€å°±ä½¿ç”¨ä¸€ä¸ª redis ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ä¹Ÿå¯ä»¥æŠŠ n9e-webapi ç”¨çš„ redis å’Œ n9e-server ç”¨çš„ redis åˆ†å¼€ï¼Œå¯ä»¥å‚è€ƒæ–‡æ¡£ï¼šæ¥å…¥å¤šä¸ª Prom/VM/M3DB é›†ç¾¤\nn9e-webapi è¿™ä¸ªæ¨¡å—æ˜¯æ”¾ä¸­å¿ƒçš„ï¼Œå¯ä»¥éƒ¨ç½²å¤šä¸ªå®ä¾‹ï¼Œå‰é¢ç»Ÿä¸€æ”¾ç½® nginx æˆ–è€… lvsï¼ŒæŸä¸ª n9e-webapi å®ä¾‹å¦‚æœæŒ‚äº†ï¼Œnginxã€lvs éƒ½å¯ä»¥è‡ªåŠ¨æ‘˜é™¤ï¼Œä¿è¯äº†é«˜å¯ç”¨ã€‚\nn9e-server n9e-server æ˜¯éšç€æ—¶åºåº“èµ°çš„ï¼Œæ¯ä¸ªæ—¶åºåº“å¯¹åº”ä¸€å¥— n9e-serverï¼Œä¸€å¥— n9e-server å¯ä»¥åªæœ‰ä¸€ä¸ª n9e-server å®ä¾‹ï¼Œä¹Ÿå¯ä»¥éƒ¨ç½²å¤šä¸ªä¿è¯é«˜å¯ç”¨å’Œæ€§èƒ½ã€‚åŒä¸€å¥— n9e-server å†…éƒ¨çš„å¤šä¸ªå®ä¾‹ï¼Œå…¶é…ç½®æ–‡ä»¶ server.conf ä¸­çš„ ClusterName å­—æ®µï¼Œè¦é…ç½®æˆä¸€æ ·çš„å­—ç¬¦ä¸²ã€‚\n",
    "description": "",
    "tags": null,
    "title": "ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é«˜å¯ç”¨é›†ç¾¤ç‰ˆ",
    "uri": "/quickstart/clusters/"
  },
  {
    "content": "é¦–é¡µæœ‰ä¸ªæ¶æ„å›¾ï¼Œå¤§å®¶å¯ä»¥çœ‹åˆ°ï¼Œå¤œèºæŠŠæ¥æ”¶åˆ°çš„ç›‘æ§æ•°æ®éƒ½ç›´æ¥å†™å…¥äº†åç«¯æ—¶åºæ•°æ®åº“ï¼Œæ‰€ä»¥ï¼Œè¯»å–ç›‘æ§æ•°æ®ï¼Œæ— éœ€ç»ç”±å¤œèºçš„æ¥å£ï¼Œç›´æ¥è¯»å–åç«¯çš„æ—¶åºåº“çš„æ¥å£å°±å¯ä»¥äº†ã€‚å³ï¼šå¦‚æœä½¿ç”¨äº† Prometheusï¼Œå°±é€šè¿‡ Prometheus çš„æ¥å£è¯»å–ç›‘æ§æ•°æ®ï¼Œå¦‚æœç”¨äº† VictoriaMetricsï¼Œå°±é€šè¿‡ VictoriaMetrics çš„æ¥å£è¯»å–ç›‘æ§æ•°æ®ã€‚\næ¯”å¦‚ Prometheusï¼Œå°±æ˜¯é‚£äº›/api/v1/query /api/v1/query_rangeä¹‹ç±»çš„æ¥å£ã€‚ç›¸å…³æ¥å£æ–‡æ¡£è¯·å‚è€ƒï¼šPrometheuså®˜ç½‘\n",
    "description": "",
    "tags": null,
    "title": "è¯»å–ç›‘æ§æ•°æ®",
    "uri": "/api/read/"
  },
  {
    "content": "æ¦‚è¿° æ‰€è°“çš„å‘Šè­¦è‡ªæ„ˆï¼Œå…¸å‹æ‰‹æ®µæ˜¯åœ¨å‘Šè­¦è§¦å‘æ—¶è‡ªåŠ¨å›è°ƒæŸä¸ªwebhookåœ°å€ï¼Œåœ¨è¿™ä¸ªwebhooké‡Œå†™å‘Šè­¦è‡ªæ„ˆçš„é€»è¾‘ï¼Œå¤œèºé»˜è®¤æ”¯æŒè¿™ç§æ–¹å¼ã€‚å¦å¤–ï¼Œå¤œèºè¿˜å¯ä»¥æ›´è¿›ä¸€æ­¥ï¼Œé…åˆibexè¿™ä¸ªæ¨¡å—ï¼Œåœ¨å‘Šè­¦è§¦å‘çš„æ—¶å€™ï¼Œè‡ªåŠ¨å»å‘Šè­¦çš„æœºå™¨æ‰§è¡ŒæŸä¸ªè„šæœ¬ï¼Œè¿™ç§æœºåˆ¶å¯ä»¥å¤§å¹…ç®€åŒ–æ„å»ºè¿ç»´è‡ªæ„ˆé“¾è·¯çš„å·¥ä½œé‡ï¼Œæ¯•ç«Ÿï¼Œä¸æ˜¯æ‰€æœ‰çš„è¿ç»´äººå‘˜éƒ½æ“…é•¿å†™http serverï¼Œä½†æ‰€æœ‰çš„è¿ç»´äººå‘˜ï¼Œéƒ½æ“…é•¿å†™è„šæœ¬ã€‚è¿™ç§æ–¹å¼æ˜¯å…¸å‹çš„ç‰©ç†æœºæ—¶ä»£çš„äº§ç‰©ï¼Œå¸Œæœ›å„ä½æœ‹å‹ç”¨ä¸åˆ°è¿™ä¸ªå·¥å…·ï¼ˆè¯´æ˜è´µå¸çš„ITæŠ€æœ¯å·²ç»èµ°å¾—éå¸¸é å‰äº†ï¼‰ã€‚\næ¶æ„ ibexæ¨¡å—ï¼Œç±»ä¼¼ä¹‹å‰å¤œèºv3ç‰ˆæœ¬ä¸­çš„jobæ¨¡å—ï¼Œå¯ä»¥æ‰¹é‡æ‰§è¡Œè„šæœ¬ï¼Œå…¶æ¶æ„éå¸¸ç®€å•ï¼ŒåŒ…æ‹¬serverå’Œagentdä¸¤ä¸ªæ¨¡å—ï¼Œagentdå‘¨æœŸæ€§è°ƒç”¨serverçš„rpcæ¥å£ï¼Œè¯¢é—®æœ‰å“ªäº›ä»»åŠ¡è¦æ‰§è¡Œï¼Œå¦‚æœæœ‰åˆ†é…ç»™è‡ªå·±çš„ä»»åŠ¡ï¼Œå°±ä»serveræ‹¿åˆ°ä»»åŠ¡è„šæœ¬ä¿¡æ¯ï¼Œåœ¨æœ¬åœ°forkä¸€ä¸ªè¿›ç¨‹è¿è¡Œï¼Œç„¶åå°†ç»“æœä¸ŠæŠ¥ç»™æœåŠ¡ç«¯ã€‚ä¸ºäº†ç®€åŒ–éƒ¨ç½²ï¼Œserverå’Œagentdèåˆæˆäº†ä¸€ä¸ªäºŒè¿›åˆ¶ï¼Œå°±æ˜¯ibexï¼Œé€šè¿‡ä¼ å…¥ä¸åŒçš„å‚æ•°æ¥å¯åŠ¨ä¸åŒçš„è§’è‰²ã€‚ibexæ¶æ„å›¾å¦‚ä¸‹ï¼š\né¡¹ç›®åœ°å€  Gitä»“åº“ï¼šhttps://gitee.com/cnperl/ibex ç¼–è¯‘æ–¹æ³•çœ‹è¿™é‡Œ Linux ä¸‹ç¼–è¯‘å¥½çš„åŒ… åœ¨è¿™é‡Œ  å®‰è£…å¯åŠ¨ ä¸‹è½½å®‰è£…åŒ…ä¹‹åï¼Œè§£å‹ç¼©ï¼Œåœ¨etcä¸‹å¯ä»¥æ‰¾åˆ°æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯çš„é…ç½®æ–‡ä»¶ï¼Œåœ¨sqlç›®å½•ä¸‹å¯ä»¥æ‰¾åˆ°åˆå§‹åŒ–sqlè„šæœ¬ã€‚\nåˆå§‹åŒ–sql mysql \u003c sql/ibex.sql å¯åŠ¨server serverçš„é…ç½®æ–‡ä»¶æ˜¯etc/server.confï¼Œæ³¨æ„ä¿®æ”¹é‡Œè¾¹çš„mysqlè¿æ¥åœ°å€ï¼Œé…ç½®æ­£ç¡®çš„mysqlç”¨æˆ·åå’Œå¯†ç ã€‚ç„¶åå°±å¯ä»¥ç›´æ¥å¯åŠ¨äº†ï¼š\nnohup ./ibex server \u0026\u003e server.log \u0026 ibexæ²¡æœ‰webé¡µé¢ï¼Œåªæä¾›apiæ¥å£ï¼Œé‰´æƒæ–¹å¼æ˜¯http basic authï¼Œbasic authçš„ç”¨æˆ·åå’Œå¯†ç é»˜è®¤éƒ½æ˜¯ibexï¼Œåœ¨etc/server.confä¸­å¯ä»¥æ‰¾åˆ°ï¼Œå¦‚æœibexéƒ¨ç½²åœ¨äº’è”ç½‘ï¼Œä¸€å®šè¦ä¿®æ”¹é»˜è®¤ç”¨æˆ·åå’Œå¯†ç ï¼Œå½“ç„¶ï¼Œå› ä¸ºn9eè¦è°ƒç”¨ibexï¼Œæ‰€ä»¥n9eçš„server.confå’Œwebapi.confä¸­ä¹Ÿé…ç½®äº†ibexçš„basic authè´¦å·ä¿¡æ¯ï¼Œè¦æ”¹å°±è¦ä¸€èµ·æ”¹å•¦ã€‚\nå¯åŠ¨agentd å®¢æˆ·ç«¯çš„é…ç½®éå¸¸éå¸¸ç®€å•ï¼Œagentd.confå†…å®¹å¦‚ä¸‹ï¼š\n# debug, release RunMode = \"release\" # task meta storage dir MetaDir = \"./meta\" [HTTP] Enable = true # http listening address Host = \"0.0.0.0\" # http listening port Port = 2090 # https cert file path CertFile = \"\" # https key file path KeyFile = \"\" # whether print access log PrintAccessLog = true # whether enable pprof PProf = false # http graceful shutdown timeout, unit: s ShutdownTimeout = 30 # max content length: 64M MaxContentLength = 67108864 # http server read timeout, unit: s ReadTimeout = 20 # http server write timeout, unit: s WriteTimeout = 40 # http server idle timeout, unit: s IdleTimeout = 120 [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\"10.2.3.4:20090\"] # $ip or $hostname or specified string Host = \"telegraf01\" å®¢æˆ·ç«¯çš„HTTPæ¥å£ç”¨å¤„ä¸å¤§ï¼Œå¯ä»¥æŠŠEnableè®¾ç½®ä¸ºfalseï¼Œå…³é—­ç›‘å¬ï¼Œé‡ç‚¹å…³æ³¨Heartbeatè¿™ä¸ªéƒ¨åˆ†ï¼ŒIntervalæ˜¯å¿ƒè·³é¢‘ç‡ï¼Œé»˜è®¤æ˜¯1000æ¯«ç§’ï¼Œå¦‚æœæœºå™¨é‡æ¯”è¾ƒå°ï¼Œæ¯”å¦‚å°äº1000å°ï¼Œç»´æŒ1000æ²¡é—®é¢˜ï¼Œå¦‚æœæœºå™¨é‡æ¯”è¾ƒå¤§ï¼Œå¯ä»¥é€‚å½“è°ƒå¤§è¿™ä¸ªé¢‘ç‡ï¼Œæ¯”å¦‚2000æˆ–è€…3000ï¼Œå¯ä»¥å‡è½»æœåŠ¡ç«¯çš„å‹åŠ›ã€‚Serversæ˜¯ä¸ªæ•°ç»„ï¼Œé…ç½®çš„æ˜¯ibex-serverçš„åœ°å€ï¼Œibex-serverå¯ä»¥å¯åŠ¨å¤šä¸ªï¼Œå¤šä¸ªåœ°å€éƒ½é…ç½®åˆ°è¿™é‡Œå³å¯ï¼ŒHostè¿™ä¸ªå­—æ®µï¼Œæ˜¯æœ¬æœºçš„å”¯ä¸€æ ‡è¯†ï¼Œæœ‰ä¸‰ç§é…ç½®æ–¹å¼ï¼Œå¦‚æœé…ç½®ä¸º$ipï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ¢æµ‹æœ¬æœºçš„IPï¼Œå¦‚æœæ˜¯$hostnameï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ¢æµ‹æœ¬æœºçš„hostnameï¼Œå¦‚æœæ˜¯å…¶ä»–å­—ç¬¦ä¸²ï¼Œé‚£å°±ç›´æ¥æŠŠè¯¥å­—ç¬¦ä¸²ä½œä¸ºæœ¬æœºçš„å”¯ä¸€æ ‡è¯†ã€‚æ¯ä¸ªæœºå™¨ä¸Šéƒ½è¦éƒ¨ç½²ibex-agentdï¼Œä¸åŒçš„æœºå™¨è¦ä¿è¯Hostå­—æ®µè·å–çš„å†…å®¹ä¸èƒ½é‡å¤ã€‚\nå¦å¤–ï¼ŒTelegrafçš„é…ç½®æ–‡ä»¶ä¸­ï¼Œæœ‰ä¸‹é¢è¿™ä¹ˆä¸€æ®µï¼š\n[agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false å…¶ä¸­hostnameé»˜è®¤ç•™ç©ºï¼Œè¡¨ç¤ºè‡ªåŠ¨æ¢æµ‹æœ¬æœºçš„hostnameï¼Œå¦‚æœå†™äº†å…·ä½“çš„æŸä¸ªå­—ç¬¦ä¸²ï¼Œé‚£å°±æŠŠå†™çš„é‚£ä¸ªå­—ç¬¦ä¸²ä½œä¸ºç›‘æ§æ•°æ®çš„hostå­—æ®µçš„å†…å®¹ï¼Œè¿™ä¸ªhostnameå­—æ®µè¦å’Œibexçš„agentd.confä¸­çš„Hostå­—æ®µä¿æŒä¸€è‡´ï¼Œå…¸å‹çš„åšæ³•æœ‰ï¼š\n Telegrafä¸­æŠŠhostnameé…ç½®ä¸ºç©ºï¼ŒTelegrafè‡ªåŠ¨è·å–æœ¬æœºhostnameï¼Œibexçš„Hosté…ç½®ä¸º$hostnameï¼Œibexä¹Ÿä¼šè‡ªåŠ¨è·å–æœ¬æœºhostnameï¼Œè¿™æ ·Telegrafå’Œibexå¯ä»¥è·å–åˆ°ç›¸åŒçš„æ ‡è¯†å†…å®¹ Telegrafä¸­æ‰‹å·¥æŠŠhostnameé…ç½®ä¸ºæœ¬æœºçš„ipï¼Œibexåˆ™æŠŠHosté…ç½®ä¸º$ipï¼Œè¿™æ ·äºŒè€…ä¹Ÿå¯ä»¥è·å–åˆ°ç›¸åŒçš„æ ‡è¯†å†…å®¹ Telegrafå’Œibexéƒ½ä½¿ç”¨æŸä¸ªç‰¹å®šå†™æ­»çš„å­—ç¬¦ä¸²æ¥ä½œä¸ºæ ‡è¯†ä¿¡æ¯ï¼Œè¿™æ ·ä¹ŸOKï¼Œä½†æ˜¯è¦ä¿è¯ä¸åŒçš„æœºå™¨ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²ä¸èƒ½é‡å¤  ä¸‹é¢æ˜¯å¯åŠ¨ibex-agentdçš„å‘½ä»¤ï¼š\nnohup ./ibex agentd \u0026\u003e agentd.log \u0026 å¦å¤–ï¼Œç»†å¿ƒçš„è¯»è€…åº”è¯¥ä¼šå‘ç°ibexçš„å‹ç¼©åŒ…é‡Œçš„etcç›®å½•ä¸‹æœ‰ä¸ªserviceç›®å½•ï¼Œé‡Œè¾¹å‡†å¤‡å¥½äº†ä¸¤ä¸ªserviceæ ·ä¾‹æ–‡ä»¶ï¼Œä¾¿äºå¤§å®¶ä½¿ç”¨systemdæ¥ç®¡ç†ibexè¿›ç¨‹ï¼Œç”Ÿäº§ç¯å¢ƒï¼Œå»ºè®®ä½¿ç”¨systemdæ¥ç®¡ç†ã€‚\n",
    "description": "",
    "tags": null,
    "title": "å‘Šè­¦è‡ªæ„ˆä¾èµ–çš„è„šæœ¬ä¸‹å‘æ‰§è¡Œæ¨¡å—",
    "uri": "/quickstart/ibex/"
  },
  {
    "content": "è°ƒç”¨ n9e-server çš„ /opentsdb/put æ¥å£ï¼ŒPOST æ–¹æ³•ï¼Œè¯¥æ¥å£å®ç°äº† OpenTSDB çš„æ•°æ®åè®®ï¼Œç›‘æ§æ•°æ®åšæˆ JSON æ”¾åˆ° HTTP Request Body ä¸­ï¼Œä¸¾ä¾‹ï¼š\n[ { \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 }, { \"metric\": \"cpu_usage_util\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 69.5 } ] æ˜¾ç„¶ï¼ŒJSON æœ€å¤–å±‚æ˜¯ä¸ªæ•°ç»„ï¼Œå¦‚æœåªä¸ŠæŠ¥ä¸€æ¡ç›‘æ§æ•°æ®ï¼Œä¹Ÿå¯ä»¥ä¸è¦å¤–é¢çš„ä¸­æ‹¬å·ï¼Œç›´æ¥æŠŠå¯¹è±¡ç»“æ„ä¸ŠæŠ¥ï¼š\n{ \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 } æœåŠ¡ç«¯ä¼šçœ‹ç¬¬ä¸€ä¸ªå­—ç¬¦æ˜¯å¦æ˜¯[ï¼Œæ¥åˆ¤æ–­ä¸ŠæŠ¥çš„æ˜¯æ•°ç»„ï¼Œè¿˜æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè‡ªåŠ¨åšç›¸åº”çš„ Decodeã€‚å¦‚æœè§‰å¾—ä¸ŠæŠ¥çš„å†…å®¹å¤ªè¿‡å ç”¨å¸¦å®½ï¼Œä¹Ÿå¯ä»¥åš gzip å‹ç¼©ï¼Œæ­¤æ—¶ä¸ŠæŠ¥çš„æ•°æ®ï¼Œè¦å¸¦æœ‰Content-Encoding: gzipçš„ Headerã€‚\nInfoæ³¨æ„ ident è¿™ä¸ªæ ‡ç­¾ï¼Œident æ˜¯ identity çš„ç¼©å†™ï¼Œè¡¨ç¤ºè®¾å¤‡çš„å”¯ä¸€æ ‡è¯†ï¼Œå¦‚æœæ ‡ç­¾ä¸­æœ‰ ident æ ‡ç­¾ï¼Œn9e-server å°±è®¤ä¸ºè¿™ä¸ªç›‘æ§æ•°æ®æ˜¯æ¥è‡ªæŸä¸ªæœºå™¨çš„ï¼Œä¼šè‡ªåŠ¨è·å– ident çš„ valueï¼Œæ³¨å†Œåˆ°ç›‘æ§å¯¹è±¡çš„åˆ—è¡¨é‡Œ\n ",
    "description": "",
    "tags": null,
    "title": "æ¨é€ç›‘æ§æ•°æ®ï¼ˆOpenTSDBåè®®ï¼‰",
    "uri": "/api/opentsdb/"
  },
  {
    "content": " æœ¬èŠ‚è®²è¿° Nightingale çš„æºç ç¼–è¯‘æ–¹å¼ï¼Œåˆ†å‰åç«¯ä¸¤éƒ¨åˆ†ã€‚å¦å¤–ï¼Œå¦‚æœç”¨åˆ°å‘Šè­¦è‡ªæ„ˆæ¨¡å—ï¼Œä¼šç”¨åˆ° ibex è¿™ä¸ªæ¨¡å—ï¼Œæœ¬èŠ‚ä¹Ÿä¼šä¸€å¹¶è®²è§£ ibex æ¨¡å—çš„ç¼–è¯‘æ–¹æ³•ã€‚å¯¹äº ARM çš„å¤„ç†å™¨ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶ï¼Œå¤§å®¶å°±è¦ç”¨ä¸‹é¢çš„æ–¹æ³•è‡ªè¡Œç¼–è¯‘äº†ã€‚\n å‰ç«¯ git clone https://github.com/n9e/fe-v5.git cd fe-v5 npm install npm run build åç«¯ Nightingale åç«¯é‡‡ç”¨ Go è¯­è¨€ç¼–å†™ï¼Œç¼–è¯‘çš„å‰ç½®æ¡ä»¶å°±æ˜¯é…ç½® Go çš„å¼€å‘ç¯å¢ƒã€‚\né…ç½®Goç¯å¢ƒ åˆ°Goå®˜ç½‘é€‰æ‹©å¯¹åº”çš„ç‰ˆæœ¬ä¸‹è½½ï¼Œæˆ‘çš„ç¯å¢ƒæ˜¯Linuxï¼Œé€‰æ‹©çš„go1.17.3.linux-amd64.tar.gzï¼Œç›´æ¥ä¸‹è½½åˆ°/rootç›®å½•ä¸‹äº†ï¼Œç„¶åè§£å‹ç¼©ï¼Œå³Goçš„å†…å®¹éƒ½æ”¾åˆ°äº†/root/goç›®å½•ä¸‹äº†ã€‚åŒæ—¶å‡†å¤‡gopathç›®å½•ï¼Œå¦‚ä¸‹ï¼š\ncd /root \u0026\u0026 mkdir -p gopath/src echo \"GOROOT=/root/go\" \u003e\u003e .bash_profile echo \"GOPATH=/root/gopath\" \u003e\u003e .bash_profile echo 'export PATH=$GOROOT/bin:$GOPATH/bin:$PATH' \u003e\u003e .bash_profile source .bash_profile ç¼–è¯‘n9e git clone https://github.com/didi/nightingale.git # å›½å†…é…ç½®ä¸€ä¸‹ä»£ç†ï¼Œå¯ä»¥åŠ é€Ÿç¼–è¯‘ export GOPROXY=https://goproxy.cn # æ‰§è¡Œç¼–è¯‘ cd nightingale \u0026\u0026 make ç¼–è¯‘å®Œæˆä¹‹åå¦‚æœç”ŸæˆäºŒè¿›åˆ¶ï¼šn9eï¼Œå°±è¡¨ç¤ºç¼–è¯‘æˆåŠŸï¼æƒ³è¦å¿«é€Ÿå…¥é—¨Goè¯­è¨€ï¼Ÿå¯ä»¥å‚è€ƒGOCNçš„èµ„æ–™ï¼\nç¼–è¯‘ibex å¦‚æœéœ€è¦å‘Šè­¦è‡ªæ„ˆèƒ½åŠ›ï¼Œå¤œèºä¾èµ–ibexåšå‘½ä»¤ä¸‹å‘æ‰§è¡Œï¼Œibexçš„ç¼–è¯‘å’Œn9eå‡ ä¹ä¸€æ¨¡ä¸€æ ·ï¼Œå¦‚ä¸‹ï¼š\ngit clone https://gitee.com/cnperl/ibex.git # å›½å†…é…ç½®ä¸€ä¸‹ä»£ç†ï¼Œå¯ä»¥åŠ é€Ÿç¼–è¯‘ export GOPROXY=https://goproxy.cn # æ‰§è¡Œç¼–è¯‘ cd ibex \u0026\u0026 make ç¼–è¯‘å®Œæˆä¹‹åå¦‚æœç”ŸæˆäºŒè¿›åˆ¶ï¼šibexï¼Œå°±è¡¨ç¤ºç¼–è¯‘æˆåŠŸï¼\n",
    "description": "",
    "tags": null,
    "title": "æºç ç¼–è¯‘å¤œèºå‰åç«¯åŠå‘Šè­¦è‡ªæ„ˆæ¨¡å—",
    "uri": "/quickstart/compile/"
  },
  {
    "content": "ç®€ä»‹ n9e-webapi æ¨¡å—æä¾›äº†ä¸¤ç±»æ¥å£ï¼Œä¸€ä¸ªæ˜¯ /api/n9e æ‰“å¤´çš„ï¼Œç»™å‰ç«¯è°ƒç”¨ï¼Œå¦ä¸€ç±»æ˜¯ /v1/n9e æ‰“å¤´çš„ï¼Œç»™ç¬¬ä¸‰æ–¹ç³»ç»Ÿè°ƒç”¨ã€‚å¦‚æœæƒ³ä»¥ä¸ªäººèº«ä»½æ¨¡ä»¿WEBæ“ä½œï¼Œä¹Ÿæ˜¯è°ƒç”¨ /api/n9e ç›¸å…³æ¥å£ã€‚\nä»¥ä¸ªäººèº«ä»½æ¨¡ä»¿WEBæ“ä½œ è¿™ç§æ–¹å¼ï¼Œé¡µé¢ä¸Š JavaScript å¯ä»¥è°ƒç”¨çš„æ‰€æœ‰æ¥å£ï¼Œä½ éƒ½å¯ä»¥ç”¨ç¨‹åºè°ƒç”¨ï¼Œæ‰“å¼€ chrome çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰’æ‹‰è¿™äº›æ¥å£ï¼Œè¿˜æ˜¯éå¸¸å®¹æ˜“çš„ã€‚å½“ç„¶ï¼Œè¦å…ˆç™»å½•ï¼Œç™»å½•è°ƒç”¨ webapi æ¨¡å—çš„ /api/n9e/auth/login æ¥å£ï¼Œç³»ç»Ÿä½¿ç”¨ jwt è®¤è¯ï¼Œå¦‚æœç™»å½•æˆåŠŸï¼Œä¼šè¿”å› access_token å’Œ refresh_tokenï¼Œæ¯æ¬¡è°ƒç”¨çš„æ—¶å€™éƒ½è¦æŠŠ access_token æ”¾åˆ° Header é‡Œï¼Œaccess_token å·®ä¸å¤š15åˆ†é’Ÿè¿‡æœŸï¼Œä¹‹åå¯ä»¥é‡æ–°è°ƒç”¨ç™»å½•æ¥å£æ¢ tokenï¼Œä¹Ÿå¯ä»¥è°ƒç”¨ /api/n9e/auth/refresh æ¥å£ç”¨ refresh_token æ¢ä¸€ä¸ªæ–°çš„ access_tokenï¼Œå½“ç„¶ï¼Œä¹Ÿä¼šé¡ºé“è¿”å›ä¸€ä¸ªæ–°çš„ refresh_tokenï¼Œä¸¾ä¾‹ï¼š\n# è°ƒç”¨ç™»å½•æ¥å£æ‹¿åˆ°access_tokenå’Œrefresh_tokenè®°å½•ä¸‹æ¥ï¼Œåé¢è°ƒç”¨å…¶ä»–æ¥å£çš„æ—¶å€™ä¼šç”¨åˆ° [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\"username\": \"root\", \"password\": \"root.2020\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\",\"user\":{\"id\":1,\"username\":\"root\",\"nickname\":\"è¶…ç®¡\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true}},\"err\":\"\"} # access_tokenæ”¾åˆ°Authorizationè¿™ä¸ªHeaderé‡Œï¼ŒBearerçš„éªŒè¯æ–¹å¼ [root@10-255-0-34 ~]# curl -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\" 'http://localhost:18000/api/n9e/self/profile' {\"dat\":{\"id\":1,\"username\":\"root\",\"nickname\":\"è¶…ç®¡\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true},\"err\":\"\"} # å¦‚æœtokenè¿‡æœŸäº†ï¼Œåç«¯ä¼šè¿”å›å¼‚å¸¸HTTPçŠ¶æ€ç ï¼Œæ­¤æ—¶è¦è°ƒç”¨refreshæ¥å£æ¢å–æ–°çš„token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\"},\"err\":\"\"} ç¬¬ä¸‰æ–¹ç³»ç»Ÿè°ƒç”¨å¤œèº æ¯”å¦‚ç¬¬ä¸‰æ–¹ç³»ç»Ÿæƒ³è·å–å¤œèºä¸­çš„æ‰€æœ‰æœªæ¢å¤å‘Šè­¦ï¼Œæˆ–è€…è·å–å¤œèºä¸­çš„å…¨é‡ç”¨æˆ·åˆ—è¡¨ï¼Œè¿™äº›éœ€æ±‚ï¼Œå»ºè®®èµ° /v1/n9e æ‰“å¤´çš„æ¥å£ï¼Œè¿™äº›æ¥å£èµ° BasicAuth è®¤è¯ï¼ŒBasicAuth çš„ç”¨æˆ·åå’Œå¯†ç åœ¨ webapi.conf ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œå°±æ˜¯ BasicAuth é‚£ä¸ª section çš„é…ç½®ã€‚å½“å‰è¿™ä¸ªé˜¶æ®µï¼Œ/v1/n9e å‰ç¼€çš„æ¥å£è¿˜æ¯”è¾ƒå°‘ï¼Œä¸è¿‡ä»£ç æ¡†æ¶å·²ç»æ­èµ·æ¥äº†ï¼Œä»£ç åœ¨ src/webapi/router/router.go æ–‡ä»¶ä¸­ï¼Œå¦‚æœè´µå¸è¦å°è£…å¤œèºçš„æ¥å£ï¼Œå¯èƒ½è¦åœ¨è¿™ä¸ªè·¯ç”±åˆ†ç»„ä¸‹åŠ ä¸€äº›è·¯ç”±é…ç½®äº†ã€‚ä½œä¸ºå¼€æºè½¯ä»¶ï¼Œè¯´æ¸…æ¥šåŸç†å°±å¥½äº†ï¼Œå¦‚æœè´µå¸ä»ç„¶æä¸æ˜ç™½å¯ä»¥è”ç³»æˆ‘ä»¬ï¼Œæˆ‘ä»¬æä¾›å•†ä¸šæŠ€æœ¯æ”¯æŒæœåŠ¡ :-)\n",
    "description": "",
    "tags": null,
    "title": "è°ƒç”¨webapiçš„æ¥å£",
    "uri": "/api/webapi/"
  },
  {
    "content": "å¤œèºæ— éœ€å¯¹æ¥ Grafanaï¼Œå¤œèºä¼šæŠŠç›‘æ§æ•°æ®è½¬å­˜åˆ°åç«¯æ—¶åºåº“ï¼Œæ¯”å¦‚ Prometheusã€VictoriaMetricsã€M3DB ç­‰ï¼ŒæŠŠè¿™äº›æ—¶åºåº“é…ç½®ä¸º Grafana çš„æ•°æ®æºå³å¯ã€‚\n",
    "description": "",
    "tags": null,
    "title": "å¯¹æ¥Grafana",
    "uri": "/usage/grafana/"
  },
  {
    "content": "ç›‘æ§ Linux å¸¸ç”¨çš„æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ä¸ªæ˜¯é€šè¿‡éƒ¨ç½² Telegrafï¼Œä¸€ä¸ªæ˜¯é€šè¿‡ node_exporterï¼Œå…³æ³¨ä¸‰ä¸ªå±‚é¢çš„é—®é¢˜ï¼šæ€ä¹ˆéƒ¨ç½²ï¼Ÿé…ç½®å“ªäº›å‘Šè­¦è§„åˆ™ï¼Ÿç›‘æ§å¤§ç›˜å¦‚ä½•é…ç½®ï¼Ÿ\nTelegraf  éƒ¨ç½²æ–¹å¼ï¼šä½¿ç”¨Telegrafé‡‡é›†ç›‘æ§æ•°æ® å‘Šè­¦è§„åˆ™ï¼šhttps://github.com/didi/nightingale/blob/main/etc/alerts/linux_by_telegraf.json ç›‘æ§å¤§ç›˜ï¼šhttps://github.com/didi/nightingale/blob/main/etc/dashboards/linux_by_telegraf.json  node_exporter  éƒ¨ç½²æ–¹å¼ï¼šhttps://github.com/prometheus/node_exporter å‘Šè­¦è§„åˆ™ï¼šhttps://github.com/didi/nightingale/blob/main/etc/alerts/node_by_exporter.json ç›‘æ§å¤§ç›˜ï¼šhttps://github.com/didi/nightingale/blob/main/etc/dashboards/node_by_exporter.json  ",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§Linux",
    "uri": "/usage/linux/"
  },
  {
    "content": "æ¨èä½¿ç”¨ windows_exporter ç›‘æ§ windows\n éƒ¨ç½²æ–¹å¼ï¼šhttps://github.com/prometheus-community/windows_exporter å‘Šè­¦è§„åˆ™ï¼šhttps://github.com/didi/nightingale/blob/main/etc/alerts/windows_by_exporter.json ç›‘æ§å¤§ç›˜ï¼šhttps://github.com/didi/nightingale/blob/main/etc/dashboards/windows_by_exporter.json  ",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§Windows",
    "uri": "/usage/windows/"
  },
  {
    "content": "Telegrafå†…ç½®æ”¯æŒsnmpçš„é‡‡é›†ï¼Œæœ¬èŠ‚ç»™ä¸€ä¸ªå…¥é—¨ä¾‹å­ï¼Œè®©å¤§å®¶å¿«é€Ÿä¸Šæ‰‹ï¼Œæ›´å¤šå…·ä½“çŸ¥è¯†å¯ä»¥å‚è€ƒè¿™é‡Œã€‚åœ¨telegraf.confä¸­æœç´¢inputs.snmpï¼Œå³å¯æ‰¾åˆ°å¯¹åº”çš„é…ç½®ï¼Œä¾‹å­å¦‚ä¸‹ï¼š\n[[inputs.snmp]] agents = [\"udp://172.25.79.194:161\"] timeout = \"5s\" version = 3 agent_host_tag = \"ident\" retries = 1 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysUpTime.0\" name = \"uptime\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysName.0\" name = \"source\" is_tag = true [[inputs.snmp.table]] oid = \"IF-MIB::ifTable\" name = \"interface\" inherit_tags = [\"source\"] [[inputs.snmp.table.field]] oid = \"IF-MIB::ifDescr\" name = \"ifDescr\" is_tag = true ä¸Šé¢éå¸¸å…³é”®çš„éƒ¨åˆ†æ˜¯ï¼šagent_host_tag = \"ident\"ï¼Œå› ä¸ºå¤œèºå¯¹identè¿™ä¸ªæ ‡ç­¾ä¼šç‰¹æ®Šå¯¹å¾…å¤„ç†ï¼ŒæŠŠæºæœ‰è¿™ä¸ªæ ‡ç­¾çš„æ•°æ®å½“åšéš¶å±æŸä¸ªç›‘æ§å¯¹è±¡çš„æ•°æ®ï¼Œæœºå™¨å’Œç½‘ç»œè®¾å¤‡éƒ½æ˜¯å…¸å‹çš„æœŸæœ›ä½œä¸ºç›‘æ§å¯¹è±¡æ¥ç®¡ç†çš„ï¼Œæ‰€ä»¥snmpçš„é‡‡é›†ä¸­ï¼Œæˆ‘ä»¬æŠŠç½‘ç»œè®¾å¤‡çš„ipæ”¾åˆ°identè¿™ä¸ªæ ‡ç­¾é‡Œå¸¦ä¸Šå»ã€‚\nå¦å¤–è¿™ä¸ªé‡‡é›†è§„åˆ™æ˜¯v3çš„æ ¡éªŒæ–¹æ³•ï¼Œä¸åŒçš„å…¬å¸å¯èƒ½é…ç½®çš„æ ¡éªŒæ–¹å¼ä¸åŒï¼Œè¯·å„ä½å‚ç…§telegraf.confä¸­é‚£äº›snmpç›¸å…³çš„æ³¨é‡Šä»”ç»†æ ¸å¯¹ï¼Œå¦‚æœæ˜¯v2ä¼šç®€å•å¾ˆå¤šï¼ŒæŠŠä¸Šä¾‹ä¸­çš„å¦‚ä¸‹éƒ¨åˆ†ï¼š\nversion = 3 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" æ¢æˆï¼š\nversion = 2 community = \"public\" å³å¯ï¼Œå½“ç„¶äº†ï¼Œcommunityè¦æ”¹æˆä½ ä»¬è‡ªå·±çš„ï¼Œè¿™é‡Œå†™çš„publicåªæ˜¯ä¸¾ä¸ªä¾‹å­ã€‚\ninputs.snmp.fieldç›¸å…³çš„é‚£äº›é…ç½®ï¼Œå¯ä»¥é‡‡é›†åˆ°å„ä¸ªç½‘å£çš„ç›‘æ§æŒ‡æ ‡ï¼Œæ›´å¤šçš„ä½¿ç”¨æ–¹å¼è¯·å‚è€ƒå®˜ç½‘\n å¦å¤–ï¼Œsnmpçš„é‡‡é›†ï¼Œå»ºè®®å¤§å®¶ä½¿ç”¨ä¸“é—¨çš„Telegrafæ¥åšï¼Œå› ä¸ºå’Œæœºå™¨ã€ä¸­é—´ä»¶ç­‰çš„é‡‡é›†é¢‘ç‡å¯èƒ½ä¸åŒï¼Œæ¯”å¦‚è¾¹ç¼˜äº¤æ¢æœºï¼Œæˆ‘ä»¬5miné‡‡é›†ä¸€æ¬¡å°±å¤Ÿäº†ï¼Œå¦‚æœæŒ‰ç…§é»˜è®¤çš„é…ç½®å¯æ˜¯10sé‡‡é›†ä¸€æ¬¡ï¼Œå®åœ¨æ˜¯å¤ªé¢‘ç¹äº†ï¼Œå¯èƒ½ä¼šç»™ä¸€äº›è€å¼äº¤æ¢æœºé€ æˆæ¯”è¾ƒå¤§çš„å‹åŠ›ï¼Œé‡‡é›†é¢‘ç‡åœ¨telegraf.confçš„æœ€ä¸Šé¢[agent]éƒ¨åˆ†ï¼Œè¾¹ç¼˜äº¤æ¢æœºå»ºè®®é…ç½®ä¸ºï¼š\n[agent] interval = \"300s\" flush_interval = \"300s\" æ ¸å¿ƒäº¤æ¢æœºå¯ä»¥é…ç½®çš„é¢‘ç¹ä¸€äº›ï¼Œæ¯”å¦‚60sæˆ–è€…120sï¼Œè¯·å„ä½ç½‘ç»œå·¥ç¨‹å¸ˆæœ‹å‹è‡ªè¡Œæ–Ÿé…Œã€‚\n",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§ç½‘ç»œè®¾å¤‡",
    "uri": "/usage/snmp/"
  },
  {
    "content": "Googleæå‡ºäº†åº”ç”¨ç›‘æ§çš„4ä¸ªé»„é‡‘æŒ‡æ ‡ï¼Œåˆ†åˆ«æ˜¯ï¼šæµé‡ã€å»¶è¿Ÿã€é”™è¯¯ã€é¥±å’Œåº¦ï¼Œå…¶ä¸­å‰é¢3ä¸ªæŒ‡æ ‡éƒ½å¯ä»¥é€šè¿‡å†…åµŒSDKçš„æ–¹å¼åŸ‹ç‚¹é‡‡é›†ã€‚å¤œèºæ ¸å¿ƒæ¨¡å—æœ‰ä¸¤ä¸ªï¼Œwebapiä¸»è¦æ˜¯æä¾›httpæ¥å£ç»™JavaScriptè°ƒç”¨ï¼Œserverä¸»è¦æ˜¯è´Ÿè´£æ¥æ”¶ç›‘æ§æ•°æ®ï¼Œå¤„ç†å‘Šè­¦è§„åˆ™ï¼Œè¿™ä¸¤ä¸ªæ¨¡å—éƒ½å¼•å…¥äº†Prometheusçš„Goçš„SDKï¼Œç”¨æ­¤æ–¹å¼åšApp Performanceç›‘æ§ï¼Œæœ¬èŠ‚ä»¥å¤œèºçš„ä»£ç ä¸ºä¾‹ï¼Œè®²è§£å¦‚ä½•ä½¿ç”¨Prometheusçš„SDKã€‚\nwebapiç›‘æ§ webapiæ¨¡å—ä¸»è¦ç»Ÿè®¡ä¸¤ä¸ªå†…å®¹ï¼Œä¸€ä¸ªæ˜¯è¯·æ±‚çš„æ•°é‡ç»Ÿè®¡ï¼Œä¸€ä¸ªæ˜¯è¯·æ±‚çš„å»¶è¿Ÿç»Ÿè®¡ï¼Œç»Ÿè®¡æ—¶ï¼Œè¦ç”¨ä¸åŒçš„Labelåšç»´åº¦åŒºåˆ†ï¼Œåé¢å°±å¯ä»¥é€šè¿‡ä¸åŒçš„ç»´åº¦åšå¤šç§å¤šæ ·çš„ç»Ÿè®¡åˆ†æï¼Œå¯¹äºHTTPè¯·æ±‚ï¼Œè§„åˆ’4ä¸ªæ ¸å¿ƒLabelï¼Œåˆ†åˆ«æ˜¯ï¼šserviceã€codeã€pathã€methodã€‚serviceæ ‡è¯†æœåŠ¡åç§°ï¼Œè¦æ±‚å…¨å±€å”¯ä¸€ï¼Œä¾¿äºå’Œå…¶ä»–æœåŠ¡åç§°åŒºåˆ†å¼€ï¼Œæ¯”å¦‚webapiæ¨¡å—ï¼Œå°±å®šä¹‰ä¸ºn9e-webapiï¼Œcodeæ˜¯httpè¿”å›çš„çŠ¶æ€ç ï¼Œ200å°±è¡¨ç¤ºæˆåŠŸæ•°é‡ï¼Œå…¶ä»–codeå°±æ˜¯å¤±è´¥çš„ï¼Œåé¢æˆ‘ä»¬å¯ä»¥æ®æ­¤ç»Ÿè®¡æˆåŠŸç‡ï¼Œmethodæ˜¯HTTPæ–¹æ³•ï¼ŒGETã€POSTã€PUTã€DELETEç­‰ï¼Œæ¯”å¦‚æ–°å¢ç”¨æˆ·å’Œè·å–ç”¨æˆ·åˆ—è¡¨å¯èƒ½éƒ½æ˜¯/api/n9e/usersï¼Œä»è·¯å¾„ä¸Šæ— æ³•åŒºåˆ†ï¼Œåªèƒ½å†åŠ ä¸Šmethodæ‰èƒ½åŒºåˆ†å¼€ã€‚\npathç€é‡è¯´ä¸€ä¸‹ï¼Œè¡¨ç¤ºè¯·æ±‚è·¯å¾„ï¼Œæ¯”å¦‚ä¸Šé¢æåˆ°çš„/api/n9e/usersï¼Œä½†æ˜¯ï¼Œåœ¨restfulå®è·µä¸­ï¼Œurlä¸­ç»å¸¸ä¼šæœ‰å‚æ•°ï¼Œæ¯”å¦‚è·å–ç¼–å·ä¸º1çš„ç”¨æˆ·çš„ä¿¡æ¯ï¼Œæ¥å£æ˜¯/api/n9e/user/1ï¼Œè·å–ç¼–å·ä¸º2çš„ç”¨æˆ·ä¿¡æ¯ï¼Œæ¥å£æ˜¯/api/n9e/user/2ï¼Œå¦‚æœè¿™ä¿©å¸¦æœ‰ç”¨æˆ·ç¼–å·çš„urléƒ½ä½œä¸ºLabelï¼Œä¼šé€ æˆæ—¶åºåº“ç´¢å¼•çˆ†ç‚¸ï¼Œè€Œä¸”ä»ä¸šåŠ¡æ–¹ä½¿ç”¨è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬ä¹Ÿä¸å…³æ³¨ç¼–å·ä¸º1çš„ç”¨æˆ·è·å–è¯·æ±‚è¿˜æ˜¯ç¼–å·ä¸º2çš„ç”¨æˆ·è·å–è¯·æ±‚ï¼Œè€Œæ˜¯å…³æ³¨æ•´ä½“çš„GET /api/n9e/user/:idè¿™ä¸ªæ¥å£çš„ç›‘æ§æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è®¾ç½®Labelçš„æ—¶å€™ï¼Œè¦æŠŠpathè®¾ç½®ä¸º/api/n9e/user/:idï¼Œè€Œä¸æ˜¯é‚£å…·ä½“çš„å¸¦æœ‰ç”¨æˆ·ç¼–å·çš„urlè·¯å¾„ã€‚å¤œèºç”¨çš„ginæ¡†æ¶ï¼Œginæ¡†æ¶æœ‰ä¸ªFullPathæ–¹æ³•å°±æ˜¯è·å–è¿™ä¸ªä¿¡æ¯çš„ï¼Œæ¯”è¾ƒæ–¹ä¾¿ã€‚\né¦–å…ˆï¼Œæˆ‘ä»¬åœ¨webapiä¸‹é¢åˆ›å»ºä¸€ä¸ªstatåŒ…ï¼Œæ”¾ç½®ç›¸å…³ç»Ÿè®¡å˜é‡ï¼š\npackage stat import ( \"time\" \"github.com/prometheus/client_golang/prometheus\" ) const Service = \"n9e-webapi\" var ( labels = []string{\"service\", \"code\", \"path\", \"method\"} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"uptime\", Help: \"HTTP service uptime.\", }, []string{\"service\"}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"http_request_count_total\", Help: \"Total number of HTTP requests made.\", }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \"http_request_duration_seconds\", Help: \"HTTP request latencies in seconds.\", }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } } uptimeå˜é‡æ˜¯é¡ºæ‰‹ä¸ºä¹‹ï¼Œç»Ÿè®¡è¿›ç¨‹å¯åŠ¨äº†å¤šä¹…æ—¶é—´ï¼Œä¸ç”¨å¤ªå…³æ³¨ï¼ŒRequestCounterå’ŒRequestDurationï¼Œåˆ†åˆ«ç»Ÿè®¡è¯·æ±‚æµé‡å’Œè¯·æ±‚å»¶è¿Ÿã€‚Initæ–¹æ³•æ˜¯åœ¨webapiæ¨¡å—è¿›ç¨‹åˆå§‹åŒ–çš„æ—¶å€™è°ƒç”¨ï¼Œæ‰€ä»¥è¿›ç¨‹ä¸€èµ·ï¼Œå°±ä¼šè‡ªåŠ¨æ³¨å†Œå¥½ã€‚\nç„¶åæˆ‘ä»¬å†™ä¸€ä¸ªmiddlewareï¼Œåœ¨è¯·æ±‚è¿›æ¥çš„æ—¶å€™æ‹¦æˆªä¸€ä¸‹ï¼Œçœçš„æ¯ä¸ªè¯·æ±‚éƒ½è¦å»ç»Ÿè®¡ï¼Œmiddlewareæ–¹æ³•çš„ä»£ç å¦‚ä¸‹ï¼š\nimport ( ... promstat \"github.com/didi/nightingale/v5/src/webapi/stat\" ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\"%d\", c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } } æœ‰äº†è¿™ä¸ªmiddlewareä¹‹åï¼Œnewå‡ºginçš„engineçš„æ—¶å€™ï¼Œå°±ç«‹é©¬Useä¸€ä¸‹ï¼Œä»£ç å¦‚ä¸‹ï¼š\n... r := gin.New() r.Use(stat()) ... æœ€åï¼Œç›‘æ§æ•°æ®è¦é€šè¿‡/metricsæ¥å£æš´éœ²å‡ºå»ï¼Œæˆ‘ä»¬è¦æš´éœ²è¿™ä¸ªè¯·æ±‚ç«¯ç‚¹ï¼Œä»£ç å¦‚ä¸‹ï¼š\nimport ( ... \"github.com/prometheus/client_golang/prometheus/promhttp\" ) func configRoute(r *gin.Engine, version string) { ... r.GET(\"/metrics\", gin.WrapH(promhttp.Handler())) } å¦‚ä¸Šï¼Œæ¯ä¸ªwebapiçš„æ¥å£çš„æµé‡å’ŒæˆåŠŸç‡éƒ½å¯ä»¥ç›‘æ§åˆ°äº†ã€‚å¦‚æœä½ ä¹Ÿéƒ¨ç½²äº†å¤œèºï¼Œè¯·æ±‚webapiçš„ç«¯å£(é»˜è®¤æ˜¯18000)çš„/metricsæ¥å£çœ‹çœ‹å§ã€‚\nInfoå¦‚æœæœåŠ¡éƒ¨ç½²å¤šä¸ªå®ä¾‹ï¼Œç”šè‡³å¤šä¸ªregionï¼Œå¤šä¸ªç¯å¢ƒï¼Œä¸Šé¢çš„4ä¸ªLabelå°±ä¸å¤Ÿç”¨äº†ï¼Œå› ä¸ºåªæœ‰è¿™4ä¸ªLabelä¸è¶³ä»¥å”¯ä¸€æ ‡è¯†ä¸€ä¸ªå…·ä½“çš„å®ä¾‹ï¼Œæ­¤æ—¶éœ€è¦envã€regionã€instanceè¿™ç§Labelï¼Œè¿™äº›Labelä¸éœ€è¦åœ¨ä»£ç é‡ŒåŸ‹ç‚¹ï¼Œåœ¨é‡‡é›†çš„æ—¶å€™ä¸€èˆ¬å¯ä»¥é™„åŠ é¢å¤–çš„æ ‡ç­¾ï¼Œé€šè¿‡é™„åŠ æ ‡ç­¾çš„æ–¹å¼æ¥å¤„ç†å³å¯\n serverç›‘æ§ serveræ¨¡å—çš„ç›‘æ§ï¼Œå’Œwebapiæ¨¡å—çš„ç›‘æ§å·®å¼‚è¾ƒå¤§ï¼Œå› ä¸ºå…³æ³¨ç‚¹ä¸åŒï¼Œwebapiå…³æ³¨çš„æ˜¯HTTPæ¥å£çš„è¯·æ±‚é‡å’Œå»¶è¿Ÿï¼Œè€Œserveræ¨¡å—å…³æ³¨çš„æ˜¯æ¥æ”¶äº†å¤šå°‘ç›‘æ§æŒ‡æ ‡ï¼Œå†…éƒ¨äº‹ä»¶é˜Ÿåˆ—çš„é•¿åº¦ï¼Œä»æ•°æ®åº“åŒæ­¥å‘Šè­¦è§„åˆ™èŠ±è´¹å¤šä¹…ï¼ŒåŒæ­¥äº†å¤šå°‘æ¡æ•°æ®ç­‰ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦åœ¨serverçš„packageä¸‹åˆ›å»ºä¸€ä¸ªstatåŒ…ï¼ŒstatåŒ…ä¸‹æ”¾ç½®stat.goï¼Œå†…å®¹å¦‚ä¸‹ï¼š\npackage stat import ( \"github.com/prometheus/client_golang/prometheus\" ) const ( namespace = \"n9e\" subsystem = \"server\" ) var ( // å„ä¸ªå‘¨æœŸæ€§ä»»åŠ¡çš„æ‰§è¡Œè€—æ—¶ \tGaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_duration\", Help: \"Cron method use duration, unit: ms.\", }, []string{\"cluster\", \"name\"}) // ä»æ•°æ®åº“åŒæ­¥æ•°æ®çš„æ—¶å€™ï¼ŒåŒæ­¥çš„æ¡æ•° \tGaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_sync_number\", Help: \"Cron sync number.\", }, []string{\"cluster\", \"name\"}) // ä»å„ä¸ªæ¥æ”¶æ¥å£æ¥æ”¶åˆ°çš„ç›‘æ§æ•°æ®æ€»é‡ \tCounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"samples_received_total\", Help: \"Total number samples received.\", }, []string{\"cluster\", \"channel\"}) // äº§ç”Ÿçš„å‘Šè­¦æ€»é‡ \tCounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alerts_total\", Help: \"Total number alert events.\", }, []string{\"cluster\"}) // å†…å­˜ä¸­çš„å‘Šè­¦äº‹ä»¶é˜Ÿåˆ—çš„é•¿åº¦ \tGaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alert_queue_size\", Help: \"The size of alert queue.\", }, []string{\"cluster\"}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) } å®šä¹‰ä¸€ä¸ªç›‘æ§æŒ‡æ ‡ï¼Œé™¤äº†nameä¹‹å¤–ï¼Œè¿˜å¯ä»¥è®¾ç½®namespaceã€subsystemï¼Œæœ€ç»ˆé€šè¿‡/metricsæ¥å£æš´éœ²çš„æ—¶å€™ï¼Œå¯ä»¥å‘ç°ï¼šç›‘æ§æŒ‡æ ‡çš„æœ€ç»ˆåå­—ï¼Œå°±æ˜¯$namespace_$subsystem_$nameï¼Œä¸‰è€…æ‹¼æ¥åœ¨ä¸€èµ·ã€‚webapiæ¨¡å—çš„ç›‘æ§ä»£ç ä¸­æˆ‘ä»¬çœ‹åˆ°äº†counterç±»å‹å’Œhistogramç±»å‹çš„å¤„ç†ï¼Œè¿™æ¬¡æˆ‘ä»¬æ‹¿GaugeAlertQueueSizeä¸¾ä¾‹ï¼Œè¿™æ˜¯ä¸ªGAUGEç±»å‹çš„ç»Ÿè®¡æ•°æ®ï¼Œèµ·ä¸€ä¸ªgoroutineå‘¨æœŸæ€§è·å–é˜Ÿåˆ—é•¿åº¦ï¼Œç„¶åSetåˆ°GaugeAlertQueueSizeä¸­ï¼š\npackage engine import ( \"context\" \"time\" \"github.com/didi/nightingale/v5/src/server/config\" promstat \"github.com/didi/nightingale/v5/src/server/stat\" ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } } å¦å¤–ï¼ŒInitæ–¹æ³•è¦åœ¨serveræ¨¡å—åˆå§‹åŒ–çš„æ—¶å€™è°ƒç”¨ï¼Œserverçš„router.goä¸­è¦æš´éœ²/metricsç«¯ç‚¹è·¯å¾„ï¼Œè¿™äº›å°±ä¸å†è¯¦è¿°äº†ï¼Œå¤§å®¶å¯ä»¥æ‰’æ‹‰ä¸€ä¸‹å¤œèºçš„ä»£ç çœ‹ä¸€ä¸‹ã€‚\næ•°æ®æŠ“å– åº”ç”¨è‡ªèº«çš„ç›‘æ§æ•°æ®å·²ç»é€šè¿‡/metricsæ¥å£æš´éœ²äº†ï¼Œåç»­é‡‡é›†è§„åˆ™å¯ä»¥åœ¨prometheus.ymlä¸­é…ç½®ï¼Œprometheus.ymlä¸­æœ‰ä¸ªsectionå«ï¼šscrape_configså¯ä»¥é…ç½®æŠ“å–ç›®æ ‡ï¼Œè¿™æ˜¯PrometheusèŒƒç•´çš„çŸ¥è¯†äº†ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒPrometheuså®˜ç½‘ã€‚\nå‚è€ƒèµ„æ–™  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  ",
    "description": "",
    "tags": null,
    "title": "åŸ‹ç‚¹ç›‘æ§ä¹‹PromSDK",
    "uri": "/usage/promapm/"
  },
  {
    "content": "StatsDç®€ä»‹ åœ¨å†…åµŒPrometheus SDKåšAPMä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸šåŠ¡è¿›ç¨‹å†…åµŒPrometheusçš„SDKåšåŸ‹ç‚¹ï¼Œè¿™ç§æ–¹å¼ï¼Œä¼šæŠŠç›‘æ§æ•°æ®èšåˆè®¡ç®—çš„é€»è¾‘æ”¾åœ¨ä¸šåŠ¡è¿›ç¨‹ä¸­ï¼Œæ¯”å¦‚ä¸€äº›å¹³å‡å€¼ã€åˆ†ä½å€¼çš„è®¡ç®—ï¼Œå¯èƒ½ä¼šå¯¹ä¸šåŠ¡è¿›ç¨‹é€ æˆå½±å“ï¼Œæœ¬èŠ‚è¦ä»‹ç»çš„StatsDçš„æ–¹å¼ï¼Œç†å¿µæ˜¯æŠŠæŒ‡æ ‡èšåˆè®¡ç®—çš„é€»è¾‘æŒªåˆ°ä¸šåŠ¡è¿›ç¨‹ä¹‹å¤–ï¼Œä¸šåŠ¡è¿›ç¨‹è°ƒç”¨åŸ‹ç‚¹å‡½æ•°çš„æ—¶å€™ï¼Œé€šè¿‡UDPæ¨é€ç»™StatsDï¼Œå³ä½¿StatsDæŒ‚äº†ï¼Œä¹Ÿä¸ä¼šå¯¹ä¸šåŠ¡è¿›ç¨‹é€ æˆå½±å“ã€‚\nStatsDçš„ç®€ä»‹ï¼Œç½‘ä¸Šä¸€æœä¸€å¤§æŠŠï¼Œè¯·å¤§å®¶è‡ªè¡ŒGoogleï¼Œè¿™é‡Œå°±ä¸é‡å¤æè¿°äº†ã€‚æ ¸å¿ƒè¦ç†è§£ä¸€ä¸‹StatsDçš„è®¾è®¡ç†å¿µã€åè®®ã€æ”¯æŒçš„å„ä¸ªè¯­è¨€çš„SDKï¼ˆåœ¨é™„å½•é‡Œæœ‰ï¼‰å³å¯ï¼Œä¸‹é¢ç›´æ¥æ‹¿ä¸€ä¸ªå°ä¾‹å­è®²è§£å¦‚ä½•åˆ©ç”¨Telegrafæ”¯æŒStatsDåè®®çš„æ•°æ®ï¼Œæ•°æ®åªè¦è¿›äº†Telegrafäº†ï¼Œå°±æ„å‘³ç€å¯ä»¥æ¨åˆ°å¤œèºäº†ï¼Œå¤œèºå°±ç›¸å½“äºæ”¯æŒäº†StatsDçš„åŸ‹ç‚¹ç›‘æ§é‡‡é›†èƒ½åŠ›ã€‚\nTelegrafå¯ç”¨StatsD åœ¨Telegrafçš„é…ç½®æ–‡ä»¶ä¸­æœç´¢inputs.statsdå°±èƒ½çœ‹åˆ°å¯¹åº”çš„sectionï¼š\n[[inputs.statsd]] protocol = \"udp\" service_address = \":8125\" percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0] metric_separator = \"_\" å¯ç”¨å¦‚ä¸Šé…ç½®ï¼Œpercentilesç•¥å¾®æœ‰ç‚¹å¤šï¼Œå¯ä»¥é…ç½®çš„å°‘ä¸€ç‚¹ï¼Œæ¯”å¦‚percentiles = [50.0, 90.0, 99.0, 100.0]ï¼Œè¿™æ ·æ•´ä½“è®¡ç®—å­˜å‚¨å‹åŠ›ä¹Ÿä¼šå°ä¸€äº›ã€‚é‡å¯Telegrafï¼ŒTelegrafå°±ä¼šåœ¨8125ç«¯å£ç›‘å¬udpåè®®ï¼Œæ¥æ”¶ä¸šåŠ¡åŸ‹ç‚¹æ•°æ®çš„ä¸ŠæŠ¥ã€‚å³ï¼ŒTelegrafå®ç°äº†StatsDçš„åè®®ï¼Œå¯ä»¥ä½œä¸ºStatsDçš„Serverä½¿ç”¨ã€‚\nåœ¨ä¸šåŠ¡ç¨‹åºä¸­åŸ‹ç‚¹ é™„å½•é‡Œç½—åˆ—äº†ä¸€äº›å®¢æˆ·ç«¯SDKï¼Œè¿™é‡Œç¬”è€…ä½¿ç”¨Goè¯­è¨€çš„ä¸€ä¸ªSDKæ¥æµ‹è¯•ï¼Œå®ç°äº†ä¸€ä¸ªå¾ˆå°çš„webç¨‹åºï¼Œä»£ç å¦‚ä¸‹ï¼š\npackage main import ( \"fmt\" \"math/rand\" \"net/http\" \"time\" \"github.com/smira/go-statsd\" ) var client *statsd.Client func homeHandler(w http.ResponseWriter, r *http.Request) { start := time.Now() // random sleep \tnum := rand.Int31n(100) time.Sleep(time.Duration(num) * time.Millisecond) fmt.Fprintf(w, \"duration: %d\", num) client.Incr(\"requests.counter,page=home\", 1) client.PrecisionTiming(\"requests.latency,page=home\", time.Since(start)) } func main() { // init client \tclient = statsd.NewClient(\"localhost:8125\", statsd.TagStyle(statsd.TagFormatInfluxDB), statsd.MaxPacketSize(1400), statsd.MetricPrefix(\"http.\"), statsd.DefaultTags(statsd.StringTag(\"service\", \"n9e-webapi\"), statsd.StringTag(\"region\", \"bj\")), ) defer client.Close() http.HandleFunc(\"/\", homeHandler) http.ListenAndServe(\":8000\", nil) } è¿™ä¸ªwebæœåŠ¡åªæœ‰ä¸€ä¸ªæ ¹è·¯å¾„ï¼Œé€»è¾‘ä¹Ÿå¾ˆç®€å•ï¼Œå°±æ˜¯éšæœºsleepå‡ åä¸ªæ¯«ç§’å½“åšä¸šåŠ¡å¤„ç†æ—¶é—´ã€‚æ•´ä½“é€»è¾‘æ˜¯è¿™æ ·çš„ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬è¦é€šè¿‡statsd.NewClientåˆå§‹åŒ–ä¸€ä¸ªstatsdçš„å®¢æˆ·ç«¯ï¼Œå‚æ•°ä¸­æŒ‡å®šäº†StatsDçš„Serveråœ°å€ï¼ˆåœ¨æœ¬ä¾‹ä¸­å°±æ˜¯Telegrafçš„8125ï¼‰ï¼ŒæŒ‡å®šäº†æ‰€æœ‰ç›‘æ§æŒ‡æ ‡çš„å‰ç¼€æ˜¯http.ï¼Œè¿˜æŒ‡å®šäº†ä¸¤ä¸ªå…¨å±€Tagï¼Œä¸€ä¸ªæ˜¯service=n9e-webapiï¼Œå¦ä¸€ä¸ªæ˜¯region=bjï¼Œé€šè¿‡TagStyleæŒ‡å®šäº†è¦å‘é€çš„æ˜¯InfluxDBæ ·å¼ï¼ˆå› ä¸ºæ•°æ®æ˜¯å‘ç»™Telegrafçš„ï¼ŒTelegrafæ˜¯InfluxDBç”Ÿæ€çš„ï¼‰çš„æ ‡ç­¾ã€‚ç„¶åï¼Œåœ¨è¯·æ±‚çš„å…·ä½“å¤„ç†é€»è¾‘é‡Œä¸ŠæŠ¥äº†ä¸¤ä¸ªç›‘æ§æŒ‡æ ‡ï¼Œä¸€ä¸ªæ˜¯requests.counterï¼Œå¦ä¸€ä¸ªæ˜¯requests.latencyï¼Œå¹¶ä¸”ï¼Œä¸ºè¿™ä¿©æŒ‡æ ‡æŒ‡å®šäº†ä¸€ä¸ªæŒ‡æ ‡çº§åˆ«çš„æ ‡ç­¾page=homeï¼Œæ•´ä½“çœ‹èµ·æ¥è¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ã€‚\næµ‹è¯•æ–¹æ³• ä¸Šé¢çš„Goç¨‹åºç¼–è¯‘ä¸€ä¸‹ï¼Œå¯åŠ¨ï¼Œä¼šä½œä¸ºä¸€ä¸ªweb serverç›‘å¬åœ¨8000ç«¯å£ï¼Œç„¶åå‘¨æœŸæ€§è¯·æ±‚è¿™ä¸ªweb serverçš„åœ°å€åšæµ‹è¯•ï¼Œè¿™ä¸ªweb serveræ¥æ”¶åˆ°è¯·æ±‚ä¹‹åï¼Œå°±è°ƒç”¨statsdçš„sdkï¼Œstatsdçš„sdkçš„æ ¸å¿ƒé€»è¾‘å°±æ˜¯æŠŠæ•°æ®å‘ç»™Telegrafçš„8125ï¼Œç„¶åå°±æ˜¯Telegrafå¤„ç†èšåˆé€»è¾‘ï¼Œèšåˆä¹‹åçš„æ•°æ®æ¯10sï¼ˆé»˜è®¤flushé¢‘ç‡ï¼‰å‘ç»™å¤œèºã€‚\nåœ¨é¡µé¢ä¸Šï¼Œåº”è¯¥å¯ä»¥çœ‹åˆ°http_requests_latencyå’Œhttp_requests_counteræ‰“å¤´çš„ç›¸å…³æŒ‡æ ‡ï¼Œæ¯”å¦‚http_requests_latency_meanè¿™ä¸ªæŒ‡æ ‡ï¼Œä¼šçœ‹åˆ°è¿™ä¸ªæŒ‡æ ‡æœ‰å¦‚ä¸‹å‡ ä¸ªæ ‡ç­¾ï¼š\n ident: VM-0-4-centos è¿™ä¸ªæ ‡ç­¾å…¶å®æ˜¯TelegrafåŸå§‹çš„hostæ ‡ç­¾ï¼Œå¤œèºçš„è§„èŒƒé‡Œå«identï¼Œæ‰€ä»¥åšäº†ä¸€ä¸‹rename metric_type: timing è¿™ä¸ªæ˜¾ç„¶æ˜¯æŠŠstatsdçš„æ•°æ®ç±»å‹ä¹Ÿåšä¸ºæ ‡ç­¾äº†ï¼Œå…¶ä»–æ•°æ®ç±»å‹è¿˜æœ‰gaugeã€counterã€setç­‰ page: home è¿™æ˜¯æˆ‘ä»¬ä»£ç é‡Œé™„åˆ°ç›‘æ§æŒ‡æ ‡åé¢çš„æ ‡ç­¾ï¼ŒTelegrafè‡ªåŠ¨å¸®è§£æå‡ºæ¥äº† service: n9e-webapi NewClientæ—¶å€™é™„åŠ çš„å…¨å±€é»˜è®¤æ ‡ç­¾ region: bj NewClientæ—¶å€™é™„åŠ çš„å…¨å±€é»˜è®¤æ ‡ç­¾  é™„å½•èµ„æ–™  Measure Anything, Measure Everything Statsdæ”¯æŒçš„çš„å®¢æˆ·ç«¯SDKåˆ—è¡¨  ",
    "description": "",
    "tags": null,
    "title": "åŸ‹ç‚¹ç›‘æ§ä¹‹StatsdSDK",
    "uri": "/usage/statsd/"
  },
  {
    "content": "è¯·å‚è€ƒå¦‚ä¸‹è§†é¢‘æ•™ç¨‹ï¼š\n 01-ä½¿ç”¨Docker Composeä¸€è¡Œå‘½ä»¤å®‰è£…å¤œèºv5 02-å¿«é€Ÿåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å¯åŠ¨å•æœºç‰ˆå¤œèºv5 03-è®²è§£å¤œèºv5äººå‘˜ç»„ç»‡ç›¸å…³åŠŸèƒ½ 04-è®²è§£å¤œèºv5ç›‘æ§çœ‹å›¾ç›¸å…³åŠŸèƒ½ 05-è®²è§£å¤œèºv5å‘Šè­¦è§„åˆ™çš„ä½¿ç”¨ 06-è®²è§£å¤œèºv5å‘Šè­¦å±è”½è§„åˆ™çš„ä½¿ç”¨ 07-è®²è§£å¤œèºå‘Šè­¦è®¢é˜…è§„åˆ™çš„ä½¿ç”¨ 08-è®²è§£å¤œèºv5æ´»è·ƒå‘Šè­¦å’Œå†å²å‘Šè­¦ 09-è®²è§£å¤œèºv5å‘Šè­¦è‡ªæ„ˆè„šæœ¬çš„ä½¿ç”¨ 10-è®²è§£å¤œèºç›‘æ§å¯¹è±¡çš„ç®¡ç†åŠŸèƒ½ 11-å¤œèºv5å¦‚ä½•æ¥å…¥å¤šä¸ªæ—¶åºå­˜å‚¨ 12-è®²è§£å¤œèºv5é…ç½®æ–‡ä»¶  å¦‚æœä»ç„¶æœ‰ä½¿ç”¨é—®é¢˜ï¼Œå¯ä»¥è”ç³»æˆ‘ä»¬ï¼Œè”ç³»æ–¹å¼å¦‚ä¸‹ï¼Œå…¬ä¼—å·ï¼š\n",
    "description": "",
    "tags": null,
    "title": "åŠŸèƒ½ä»‹ç»",
    "uri": "/usage/"
  },
  {
    "content": "ä¹‹å‰åœ¨å†™è°ƒç ”ç¬”è®°çš„æ—¶å€™ï¼Œæµ‹è¯•äº†PINGç›‘æ§å’ŒTCPæ¢æµ‹ç›‘æ§ï¼Œè°ƒç ”ç¬”è®°åœ¨ è¿™é‡Œ è¿™ä¸ªç« èŠ‚ä¸»è¦ç»™å¤§å®¶è®²è§£åŸŸåURLæ¢æµ‹ã€‚ç›´æ¥ä¸Šæµ‹è¯•é…ç½®ï¼š\n[[inputs.http_response]] urls = [\"https://www.baidu.com\", \"http://ulricqin.io/ping\"] response_timeout = \"5s\" method = \"GET\" fielddrop = [\"result_type\"] tagexclude = [\"result\", \"status_code\"] https://www.baidu.com æ˜¾ç„¶æ˜¯é€šçš„ï¼Œhttp://ulricqin.io/ping è¿™ä¸ªæ˜¯ä¸ªå‡çš„URLï¼Œä¸é€šï¼Œæˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹è¾“å‡ºçš„å†…å®¹ï¼š\n[root@10-255-0-34 telegraf-1.20.3]# ./usr/bin/telegraf --config etc/telegraf/telegraf.conf --input-filter http_response --test 2021-12-13T04:16:43Z I! Starting Telegraf 1.20.3 \u003e http_response,host=10-255-0-34,method=GET,server=https://www.baidu.com content_length=227i,http_response_code=200i,response_time=0.028757521,result_code=0i 1639369003000000000 \u003e http_response,host=10-255-0-34,method=GET,server=http://ulricqin.io/ping result_code=5i 1639369003000000000 è¿™é‡Œæœ‰ä¸ªå­—æ®µæ˜¯result_codeï¼Œç”¨è¿™ä¸ªå­—æ®µé…ç½®å‘Šè­¦å³å¯ï¼Œæ­£å¸¸å¯ä»¥è®¿é—®çš„URLï¼Œresult_codeæ˜¯0ï¼Œä¸æ­£å¸¸å°±æ˜¯é0ï¼Œå‘Šè­¦è§„åˆ™é‡Œå¯ä»¥é…ç½®å¦‚ä¸‹promqlï¼š\nhttp_response_result_code != 0 æˆ–è€…ç›´æ¥åœ¨å¤œèºçš„å‘Šè­¦è§„åˆ™é¡µé¢å¯¼å…¥è¿™æ¡å‘Šè­¦è§„åˆ™JSONï¼š\n[ { \"name\": \"æœ‰URLæ¢æµ‹å¤±è´¥ï¼Œè¯·æ³¨æ„\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"http_response_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] } ] å¦‚æœæƒ³å¯¹åŸŸåè¿”å›çš„statuscodeæˆ–è€…response bodyçš„å†…å®¹åšåˆ¤æ–­ï¼ŒTelegrafä¹Ÿæ˜¯æ”¯æŒçš„ï¼Œä½¿ç”¨response_status_codeå’Œresponse_string_matchè¿™äº›å­—æ®µé…ç½®ï¼Œé…ç½®æ–‡ä»¶é‡Œæœ‰æ ·ä¾‹ï¼Œå¤§å®¶å¯ä»¥è‡ªè¡Œå‚è€ƒä¸‹ã€‚\n",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§URL",
    "uri": "/usage/http_response/"
  },
  {
    "content": "å‰è¨€ è¯´åˆ°æ—¥å¿—ç›‘æ§ï¼Œå¤§å®¶ç¬¬ä¸€ååº”çš„å¯èƒ½æ˜¯ELKçš„æ–¹æ¡ˆï¼Œæˆ–è€…Lokiçš„æ–¹æ¡ˆï¼Œè¿™ä¸¤ä¸ªæ–¹æ¡ˆéƒ½æ˜¯æŠŠæ—¥å¿—é‡‡é›†äº†å‘åˆ°ä¸­å¿ƒï¼Œåœ¨ä¸­å¿ƒå­˜å‚¨ã€æŸ¥çœ‹ã€åˆ†æï¼Œä¸è¿‡è¿™ä¸ªæ–¹æ¡ˆç›¸å¯¹æ¯”è¾ƒé‡é‡çº§ä¸€äº›ï¼Œå¦‚æœæˆ‘ä»¬çš„éœ€æ±‚åªæ˜¯ä»æ—¥å¿—ä¸­æå–ä¸€äº›metricsæ•°æ®ï¼Œæ¯”å¦‚ç»Ÿè®¡ä¸€äº›æ—¥å¿—ä¸­å‡ºç°çš„Erroræ¬¡æ•°ä¹‹ç±»çš„ï¼Œåˆ™æœ‰ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ¡ˆã€‚\nè¿™ä¸ªæ–¹æ¡ˆåœ¨å¤œèºv4ç‰ˆæœ¬ä¸­æ˜¯æœ‰çš„ï¼Œä¸è¿‡åæ¥æ¨èå¤§å®¶å®¢æˆ·ç«¯ä½¿ç”¨Telegrafï¼ŒTelegrafæ²¡æœ‰è¿™ä¸ªèƒ½åŠ›ï¼Œæ‰€ä»¥v5ç‰ˆæœ¬çš„å¤œèºæ²¡æ³•ç›‘æ§æ—¥å¿—ï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿè¿™é‡Œç»™å¤§å®¶ä»‹ç»ä¸€ä¸ªGoogleå‡ºå“çš„å°å·¥å…·ï¼Œmtailï¼Œmtailå’Œå¤œèºv4çš„æ–¹æ¡ˆç±»ä¼¼ï¼Œå°±æ˜¯æµå¼è¯»å–æ—¥å¿—ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çš„æ–¹å¼ä»æ—¥å¿—ä¸­æå–metricsæŒ‡æ ‡ï¼Œè¿™ç§æ–¹å¼å¯ä»¥åˆ©ç”¨ç›®æ ‡æœºå™¨çš„ç®—åŠ›ï¼Œä¸è¿‡å¦‚æœé‡å¤ªå¤§ï¼Œå¯èƒ½ä¼šå½±å“ç›®æ ‡æœºå™¨ä¸Šçš„ä¸šåŠ¡ç¨‹åºï¼Œå¦å¤–ä¸€ä¸ªå¥½å¤„æ˜¯æ— ä¾µå…¥æ€§ï¼Œä¸éœ€è¦ä¸šåŠ¡åŸ‹ç‚¹ï¼Œå¦‚æœä¸šåŠ¡ç¨‹åºæ˜¯ç¬¬ä¸‰æ–¹ä¾›åº”å•†æä¾›çš„ï¼Œæˆ‘ä»¬æ”¹ä¸äº†å…¶ä»£ç ï¼Œmtailæ­¤æ—¶å°±éå¸¸åˆé€‚äº†ã€‚å½“ç„¶äº†ï¼Œå¦‚æœä¸šåŠ¡ç¨‹åºæ˜¯æˆ‘ä»¬å…¬å¸çš„äººè‡ªå·±å†™çš„ï¼Œé‚£è¿˜æ˜¯å»ºè®®ç”¨åŸ‹ç‚¹çš„æ–¹å¼é‡‡é›†æŒ‡æ ‡ï¼Œmtailåªæ˜¯ä½œä¸ºä¸€ä¸ªè¡¥å……å§ã€‚\nmtailç®€ä»‹ mtailçš„ä½¿ç”¨æ–¹æ¡ˆï¼Œå‚è€ƒå¦‚ä¸‹ä¸¤ä¸ªæ–‡æ¡£ï¼ˆä¸‹è½½çš„è¯å‚è€ƒReleasesé¡µé¢ï¼‰ï¼š\n Deploying Programming Guide  æˆ‘ä»¬æ‹¿mtailçš„å¯åŠ¨å‘½ä»¤æ¥ä¸¾ä¾‹å…¶ç”¨æ³•ï¼š\nmtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats é€šè¿‡ --progs å‚æ•°æŒ‡å®šä¸€ä¸ªç›®å½•ï¼Œè¿™ä¸ªç›®å½•é‡Œæ”¾ç½®ä¸€å †çš„*.mtailæ–‡ä»¶ï¼Œæ¯ä¸ªmtailæ–‡ä»¶å°±æ˜¯æè¿°çš„æ­£åˆ™æå–è§„åˆ™ï¼Œé€šè¿‡ --logs å‚æ•°æ¥æŒ‡å®šè¦ç›‘æ§çš„æ—¥å¿—ç›®å½•ï¼Œå¯ä»¥å†™é€šé…ç¬¦ï¼Œ--logs å¯ä»¥å†™å¤šæ¬¡ï¼Œä¸Šä¾‹ä¸­åªæ˜¯æŒ‡å®šäº† --progs å’Œ --logs ï¼Œæ²¡æœ‰å…¶ä»–å‚æ•°ï¼Œmtailå¯åŠ¨ä¹‹åä¼šè‡ªåŠ¨ç›‘å¬ä¸€ä¸ªç«¯å£3903ï¼Œåœ¨3903çš„/metricsæ¥å£æš´éœ²ç¬¦åˆPrometheusåè®®çš„ç›‘æ§æ•°æ®ï¼ŒPrometheusï¼ˆæˆ–è€…Telegrafï¼‰å°±å¯ä»¥ä» /metrics æ¥å£æå–ç›‘æ§æ•°æ®ã€‚\nè¿™æ ·çœ‹èµ·æ¥ï¼ŒåŸç†å°±å¾ˆæ¸…æ™°äº†ï¼Œmtailå¯åŠ¨ä¹‹åï¼Œæ ¹æ® --logs æ‰¾åˆ°ç›¸å…³æ—¥å¿—æ–‡ä»¶æ–‡ä»¶ï¼Œseekåˆ°æ–‡ä»¶æœ«å°¾ï¼Œå¼€å§‹æµå¼è¯»å–ï¼Œæ¯è¯»åˆ°ä¸€è¡Œï¼Œå°±æ ¹æ® --progs æŒ‡å®šçš„é‚£äº›è§„åˆ™æ–‡ä»¶åšåŒ¹é…ï¼Œçœ‹æ˜¯å¦ç¬¦åˆæŸäº›æ­£åˆ™ï¼Œä»ä¸­æå–æ—¶åºæ•°æ®ï¼Œç„¶åé€šè¿‡3903çš„/metricsæš´éœ²é‡‡é›†åˆ°çš„ç›‘æ§æŒ‡æ ‡ã€‚å½“ç„¶ï¼Œé™¤äº†Prometheusè¿™ç§/metricsæ–¹å¼æš´éœ²ï¼Œmtailè¿˜æ”¯æŒæŠŠç›‘æ§æ•°æ®ç›´æ¥æ¨ç»™graphiteæˆ–è€…statsdï¼Œå…·ä½“å¯ä»¥å‚è€ƒï¼šè¿™é‡Œ\nmtailæ ·ä¾‹ è¿™é‡Œæˆ‘ç”¨mtailç›‘æ§ä¸€ä¸‹n9e-serverçš„æ—¥å¿—ï¼Œä»ä¸­æå–ä¸€ä¸‹å„ä¸ªå‘Šè­¦è§„åˆ™è§¦å‘çš„notifyçš„æ•°é‡ï¼Œè¿™ä¸ªæ—¥å¿—ä¸¾ä¾‹ï¼š\n2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430 å¾ˆæ˜æ˜¾ï¼Œæ—¥å¿—ä¸­æœ‰è¿™ä¹ˆä¸ªå…³é”®å­—ï¼šnotify: rule_id=9ï¼Œå¯ä»¥ç”¨æ­£åˆ™æ¥åŒ¹é…ï¼Œç»Ÿè®¡å‡ºç°çš„è¡Œæ•°ï¼Œruleidä¹Ÿå¯ä»¥ä»ä¸­æå–åˆ°ï¼Œè¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠruleidä½œä¸ºæ ‡ç­¾ä¸ŠæŠ¥ï¼Œäºæ˜¯ä¹ï¼Œæˆ‘ä»¬å°±å¯ä»¥å†™å‡ºè¿™æ ·çš„mtailè§„åˆ™äº†ï¼š\n[root@10-255-0-34 nightingale]# cat /etc/mtail/n9e-server.mtail counter mtail_alert_rule_notify_total by ruleid /notify: rule_id=(?P\u003cruleid\u003e\\d+)/ { mtail_alert_rule_notify_total[$ruleid]++ } ç„¶åå¯åŠ¨ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œæˆ‘è¿™é‡Œå°±ç”¨nohupç®€å•æ¥åšï¼š\nnohup mtail -logtostderr --progs /etc/mtail --logs server.log \u0026\u003e stdout.log \u0026 mtailæ²¡æœ‰æŒ‡å®šç»å¯¹è·¯å¾„ï¼Œæ˜¯å› ä¸ºæˆ‘æŠŠmtailçš„äºŒè¿›åˆ¶ç›´æ¥æ”¾åœ¨äº† /usr/bin ä¸‹é¢äº†ï¼Œmtailé»˜è®¤ä¼šç›‘å¬åœ¨3903ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨å¦‚ä¸‹å‘½ä»¤éªŒè¯ï¼š\ncurl -s localhost:3903/metrics å¯ä»¥çœ‹åˆ°è¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\n# HELP mtail_alert_rule_notify_total defined at n9e-server.mtail:1:9-37 # TYPE mtail_alert_rule_notify_total counter mtail_alert_rule_notify_total{prog=\"n9e-server.mtail\",ruleid=\"9\"} 6 ä¸Šé¢çš„è¾“å‡ºåªæ˜¯æŒ‘é€‰äº†éƒ¨åˆ†å†…å®¹ï¼Œæ²¡æœ‰å…¨éƒ¨æ”¾å‡ºæ¥å“ˆï¼Œè¿™å°±è¡¨ç¤ºæ­£å¸¸é‡‡é›†åˆ°äº†ï¼Œå¦‚æœn9eçš„server.logä¸­å½“å‰æ²¡æœ‰æ‰“å°notifyç›¸å…³çš„æ—¥å¿—ï¼Œé‚£è¯·æ±‚/metricsæ¥å£æ˜¯æ²¡æ³•å¾—åˆ°ä¸Šé¢çš„è¾“å‡ºçš„ï¼Œå¯ä»¥æ‰‹å·¥é…ç½®ä¸€æ¡å¿…ç„¶ä¼šè§¦å‘çš„è§„åˆ™ï¼Œå¾…æ—¥å¿—é‡Œæœ‰ç›¸å…³è¾“å‡ºçš„æ—¶å€™å†æ¬¡è¯·æ±‚ /metrics æ¥å£ï¼Œåº”è¯¥å°±æœ‰äº†\næœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨Telegrafæ¥é‡‡é›†ä¸€ä¸‹ localhost:3903/metrics è¿™ä¸ªåœ°å€çš„è¾“å‡ºï¼Œåœ¨telegraf.confä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ï¼š\n[[inputs.prometheus]] urls = [\"http://localhost:3903/metrics\"] å®Œäº‹é‡å¯Telegrafæˆ–è€…ç»™Telegrafè¿›ç¨‹å‘ä¸€ä¸ªSIGHUPä¿¡å·ï¼š\nkill -HUP `pidof telegraf` ç­‰ä¸€ä¼šï¼Œå°±å¯ä»¥åœ¨é¡µé¢ä¸ŠæŸ¥åˆ°ç›¸å…³æŒ‡æ ‡äº†ï¼Œæˆ‘ä»¬æ‹¿ç€mtail_alert_rule_notify_totalè¿™ä¸ªæŒ‡æ ‡å»å³æ—¶æŸ¥è¯¢é‡ŒæŸ¥ï¼Œä¼šå‘ç°æŸ¥ä¸åˆ°æ•°æ®ï¼Œè€Œæ˜¯å‡ºç°äº†ä¸€ä¸ªmtail_alert_rule_notify_total_counterè¿™æ ·çš„æŒ‡æ ‡ï¼Œçœ‹èµ·æ¥åƒæ˜¯Telegrafå¯¹äºPrometheusåè®®çš„ç›‘æ§æ•°æ®ï¼Œè‡ªåŠ¨åŠ äº†åç¼€ï¼Œæ— æ‰€è°“äº†ï¼Œå¤§å®¶æ³¨æ„ä¸€ä¸‹å°±å¥½ã€‚å¦‚æœåœ¨prometheus.yamlä¸­é…ç½®scrape_configæ¥æŠ“å–mtailï¼Œåº”è¯¥ä¸ä¼šè‡ªåŠ¨åŠ ä¸Š_counterçš„åç¼€ã€‚\nå¦å¤–ï¼Œmtailçš„é…ç½®æ–‡ä»¶å¦‚æœå‘ç”Ÿå˜åŒ–ï¼Œæ˜¯éœ€è¦é‡å¯mtailæ‰èƒ½ç”Ÿæ•ˆçš„ï¼Œæˆ–è€…ä¹Ÿæ˜¯ç±»ä¼¼Telegrafé‚£æ ·å‘ä¸€ä¸ªSIGHUPä¿¡å·ç»™mtailï¼Œmtailæ”¶åˆ°ä¿¡å·å°±ä¼šé‡æ–°åŠ è½½é…ç½®ã€‚\nmtailæ›´å¤šæ ·ä¾‹ mtailçš„github repoä¸­æœ‰ä¸€ä¸ªexamplesï¼Œé‡Œè¾¹æœ‰æŒºå¤šä¾‹å­ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒã€‚æˆ‘åœ¨è¿™é‡Œå†ç»™å¤§å®¶ä¸¾1ä¸ªç®€å•ä¾‹å­ï¼Œæ¯”å¦‚æˆ‘ä»¬è¦ç»Ÿè®¡/var/log/messagesæ–‡ä»¶ä¸­çš„ Out of memory å…³é”®å­—ï¼Œmtailè§„åˆ™åº”è¯¥æ€ä¹ˆå†™å‘¢ï¼Ÿå…¶å®æ¯”ä¸Šé¢ä¸¾ä¾‹çš„mtail_alert_rule_notify_totalè¿˜è¦æ›´ç®€å•ï¼š\ncounter mtail_oom_total /Out of memory/ { mtail_oom_total++ } å…³äºæ—¶é—´æˆ³ æœ€åè¯´ä¸€ä¸‹æ—¶é—´æˆ³çš„é—®é¢˜ï¼Œæ—¥å¿—ä¸­æ¯ä¸€è¡Œä¸€èˆ¬éƒ½æ˜¯æœ‰ä¸ªæ—¶é—´æˆ³çš„ï¼Œå¤œèºv4ç‰ˆæœ¬åœ¨é¡µé¢ä¸Šé…ç½®é‡‡é›†è§„åˆ™çš„æ—¶å€™ï¼Œå°±æ˜¯è¦é€‰æ‹©æ—¶é—´æˆ³çš„ï¼Œä½†æ˜¯mtailï¼Œä¸Šé¢çš„ä¾‹å­ä¸­æ²¡æœ‰å¤„ç†æ—¶é—´æˆ³ï¼Œä¸ºå•¥ï¼Ÿå…¶å®mtailä¹Ÿå¯ä»¥æ”¯æŒä»æ—¥å¿—ä¸­æå–æ—¶é—´æˆ³ï¼Œå¦‚æœæ²¡æœ‰é…ç½®çš„è¯ï¼Œå°±ç”¨ç³»ç»Ÿå½“å‰æ—¶é—´ï¼Œä¸ªäººè®¤ä¸ºï¼Œç”¨ç³»ç»Ÿå½“å‰æ—¶é—´å°±å¯ä»¥äº†ï¼Œä»æ—¥å¿—ä¸­æå–æ—¶é—´ç¨å¾®è¿˜æœ‰ç‚¹éº»çƒ¦ï¼Œå½“ç„¶ï¼Œç³»ç»Ÿå½“å‰æ—¶é—´å’Œæ—¥å¿—ä¸­çš„æ—¶é—´å¯èƒ½ç¨å¾®æœ‰å·®åˆ«ï¼Œä½†æ˜¯ä¸ä¼šå·®å¾ˆå¤šçš„ï¼Œå¯ä»¥æ¥å—ï¼Œexamplesä¸­çš„mtailæ ·ä¾‹ï¼Œä¹ŸåŸºæœ¬éƒ½æ²¡æœ‰ç»™å‡ºæ—¶é—´æˆ³çš„æå–ï¼Œä¼°è®¡è¿™å°±æ˜¯æœ€ä½³å®è·µã€‚\n",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§æ—¥å¿—",
    "uri": "/usage/mtail/"
  },
  {
    "content": " ç›‘æ§æ–¹å¼ï¼šhttps://github.com/prometheus/mysqld_exporter å‘Šè­¦è§„åˆ™ï¼šhttps://github.com/didi/nightingale/blob/main/etc/alerts/mysql_by_exporter.json ç›‘æ§å¤§ç›˜ï¼šhttps://github.com/didi/nightingale/blob/main/etc/dashboards/mysql_by_exporter.json  ",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§MySQL",
    "uri": "/usage/mysql/"
  },
  {
    "content": " ç›‘æ§æ–¹å¼ï¼šhttps://github.com/oliver006/redis_exporter å‘Šè­¦è§„åˆ™ï¼šhttps://github.com/didi/nightingale/blob/main/etc/alerts/redis_by_exporter.json ç›‘æ§å¤§ç›˜ï¼šhttps://github.com/didi/nightingale/blob/main/etc/dashboards/redis_by_exporter.json  ",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§Redis",
    "uri": "/usage/redis/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "API",
    "uri": "/api/"
  },
  {
    "content": "  å¤šé›†ç¾¤éƒ¨ç½²çš„æ—¶å€™MySQLã€Redisåˆ†åˆ«éƒ¨ç½²å‡ ä¸ªï¼Ÿ   å…¬ä¼—å·æœ‰ä¸ªè§†é¢‘è®²è§£äº† å¦‚ä½•æ¥å…¥å¤šä¸ªæ—¶åºå­˜å‚¨ï¼Œ è¯·å…ˆæŸ¥çœ‹ã€‚MySQLæ˜¯åªéœ€è¦ä¸€ä¸ªï¼Œä¸ç®¡éƒ¨ç½²å¤šå°‘ä¸ªn9e-webapiå¤šå°‘ä¸ªn9e-serverã€‚redisä¹Ÿå¯ä»¥åªç”¨ä¸€ä¸ªï¼Œæ‰€æœ‰çš„n9e-webapiå’Œn9e-serverå…±äº«ï¼Œä½†æ˜¯ï¼Œå¦‚æœéƒ¨ç½²å¤šå¥—n9e-serverï¼ˆä¸€å¥—n9e-serverå¯èƒ½æ˜¯å¤šä¸ªn9e-serverå®ä¾‹ç»„æˆä¸€ä¸ªé›†ç¾¤ï¼‰åˆ†å¸ƒåœ¨ä¸åŒçš„åœ°åŸŸï¼Œç½‘ç»œé“¾è·¯å¯èƒ½ä¸å¤ªå¥½ï¼Œæ­¤æ—¶æ˜¯å»ºè®®ä¸€å¥—n9e-serverå¯¹åº”ä¸€ä¸ªredisï¼Œn9e-webapiè‡ªå·±ç”¨ä¸€ä¸ªredis\n æ¶æ„ä¸­å¯ä»¥å®Œå…¨ä¸ç”¨Prometheuså—ï¼Ÿ   åŸç†ä¸Šæ˜¯å¯ä»¥çš„ï¼ŒPrometheusåœ¨å¤œèºçš„æ¶æ„ä¸­ï¼Œæ˜¯ä½œä¸ºæ—¶åºåº“ä½¿ç”¨ï¼Œé™¤äº†Prometheusï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨VictoriaMetricsã€M3DBç­‰ï¼Œå› ä¸ºè¿™äº›æ—¶åºåº“éƒ½å®ç°äº†Prometheusçš„Querieræ¥å£ï¼Œè€Œå¤œèºä¾èµ–è¿™äº›æ¥å£æ‹‰å–ç›‘æ§æ•°æ®å’Œåšå‘Šè­¦åˆ¤æ–­ã€‚\n æœºå™¨åªèƒ½å½’å±ä¸€ä¸ªä¸šåŠ¡ç»„å—ï¼Ÿ   æ˜¯çš„ã€‚\nç”¨æˆ·å¯èƒ½ä¼šç»§ç»­è¿½é—®ï¼šä¸€å°æœºå™¨å¯èƒ½æœ‰æ··éƒ¨çš„æƒ…å†µï¼ŒåŒæ—¶éƒ¨ç½²å¤šä¸ªæœåŠ¡ï¼Œé‚£å¦‚ä½•æ¥æè¿°è¿™ç§ç°å®ï¼ˆæ¯•ç«Ÿï¼Œè½¯ä»¶å°±æ˜¯å¯¹ç°å®çš„å»ºæ¨¡ï¼‰å‘¢ï¼Ÿå…¶å®ï¼Œè¿™ç§å…³è”ä¿¡æ¯åœ¨ç›‘æ§ä¸­æ˜¯ä½¿ç”¨æ ‡ç­¾æ¥åæ˜ çš„ã€‚æ¯”å¦‚æŸä¸ªç›‘æ§æ•°æ®å¸¦æœ‰è¿™å‡ ä¸ªæ ‡ç­¾ï¼šhost=cs-node001.hna service=n9e-server method=get api=/ping statuscode=200 è¡¨ç¤ºï¼šè¿™ä¸ªç›‘æ§æ•°æ®æ˜¯n9e-serverè¿™ä¸ªæœåŠ¡çš„ï¼Œæ¥è‡ªcs-node001.hnaè¿™ä¸ªæœºå™¨ï¼Œè¿™æ¡ç›‘æ§æ•°æ®æè¿°çš„æ˜¯/pingæ¥å£ï¼Œ/pingæ¥å£æ˜¯ä¸ªgetæ¥å£ï¼Œstatuscodeæ˜¯200ï¼Œè¿™ä¸ªä¿¡æ¯éå¸¸ä¸°å¯Œï¼Œé‡Œè¾¹æ—¢æœ‰æœåŠ¡åç§°ï¼Œåˆæœ‰æœºå™¨ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§æ–¹å¼æˆ‘ä»¬å°±çŸ¥é“æœåŠ¡å’Œæœºå™¨çš„å…³è”å…³ç³»ã€‚\nå¤§å®¶ä¸è¦æŠŠCMDBä¸­çš„æœºå™¨åˆ†ç»„éœ€æ±‚æ”¾åˆ°å¤œèºä¸­æ¥ç»´æŠ¤ï¼Œè¿™æ˜¯èŒè´£ä¸Šçš„é”™é…ã€‚\né‚£ä¸ºä½•è¿˜è¦æä¾›ä¸šåŠ¡ç»„è¿™ä¸ªæ¦‚å¿µï¼Ÿå²‚ä¸æ˜¯å¤šä½™äº†ï¼Ÿä¸šåŠ¡ç»„æ›´å¤šçš„æ˜¯æƒ³å¤„ç†æƒé™çš„é—®é¢˜ï¼Œæ¯”å¦‚æˆ‘ä»¬çš„å‘Šè­¦è§„åˆ™ã€å±è”½è§„åˆ™ã€è®¢é˜…è§„åˆ™ã€ç›‘æ§å¤§ç›˜ã€è‡ªæ„ˆè„šæœ¬ç­‰ï¼Œåªèƒ½ç”±æˆ‘ä»¬è‡ªå·±ç®¡ç†ï¼Œä¸èƒ½è¢«æ— å…³äººå‘˜ä¿®æ”¹äº†æˆ–åˆ é™¤äº†ã€‚æŠŠè¿™äº›è§„åˆ™ç±»ä¿¡æ¯æ”¾åˆ°æŸä¸ªä¸šåŠ¡ç»„ä¸­ï¼Œåªæœ‰è¿™ä¸ªä¸šåŠ¡ç»„çš„ç®¡ç†å‘˜æœ‰æƒé™ç®¡ç†ï¼Œå…¶ä»–äººå°±æ²¡æœ‰æƒé™ä¹±æäº†ã€‚\né‚£æœºå™¨ä¸ºä½•è¦å½’å±ä¸šåŠ¡ç»„ï¼Ÿå…¶å®ä¹Ÿæ˜¯ä»æƒé™ä¸Šè€ƒè™‘çš„ï¼Œè‡ªæ„ˆè„šæœ¬æ˜¯å½’å±ä¸šåŠ¡ç»„çš„ï¼Œè„šæœ¬çš„æ‰§è¡Œéœ€è¦æœ‰æƒé™æ§åˆ¶ï¼Œä¸èƒ½éšä¾¿å»æœºå™¨ä¸Šè¿è¡Œï¼Œç°åœ¨çš„æ§åˆ¶é€»è¾‘æ˜¯è„šæœ¬åªèƒ½åœ¨è‡ªå·±çš„ä¸šåŠ¡ç»„ä¸‹è¾–çš„æœºå™¨ä¸Šè¿è¡Œã€‚\nç»¼ä¸Šï¼Œå¦ç™½è®²ï¼Œæˆ‘æ²¡æœ‰æƒ³åˆ°ä»€ä¹ˆåœºæ™¯æ˜¯å¿…é¡»è®©æœºå™¨ï¼ˆå³ç³»ç»Ÿä¸­çš„ç›‘æ§å¯¹è±¡ï¼‰å½’å±åˆ°å¤šä¸ªä¸šåŠ¡ç»„çš„ã€‚å…³é”®åŸå› æ˜¯ç›‘æ§æ•°æ®ä¸ŠæŠ¥çš„æ—¶å€™å°±æ˜¯è‡ªæè¿°çš„ï¼Œå·²ç»åŒ…å«äº†å„ç±»ä¿¡æ¯äº†ï¼Œä¸éœ€è¦é€šè¿‡å¤–æŒ‚çš„æ–¹å¼é‡æ–°å½’ç±»ç›‘æ§æ•°æ®ï¼Œè€Œæœºå™¨çš„åˆ†ç»„ï¼Œè™½ç„¶æœ‰éœ€æ±‚ï¼Œä½†é‚£æ˜¯CMDBçš„éœ€æ±‚ï¼Œä¹Ÿä¸æ˜¯ç›‘æ§è¦å¤„ç†çš„ã€‚\næ›´æ–°ï¼šå¦å¤–ï¼Œæœºå™¨ï¼ˆå³ç³»ç»Ÿä¸­çš„ç›‘æ§å¯¹è±¡ï¼‰å¯ä»¥æ‰“æ ‡ç­¾ï¼Œå¯ä»¥é€šè¿‡æ ‡ç­¾ä½“ç°ä¸€å®šçš„åˆ†ç±»ä¿¡æ¯ï¼Œæ¯”å¦‚region=bj env=prodè¡¨ç¤ºbjåŒºçš„ç”Ÿäº§ç¯å¢ƒçš„æœºå™¨ã€‚æ ‡ç­¾æ˜¯K=Vçš„æ ¼å¼ï¼ŒKå¯ä»¥ä½“ç°ç»´åº¦ä¿¡æ¯ï¼Œå¤§éƒ¨åˆ†å½’ç±»éœ€æ±‚éƒ½å¯ä»¥é€šè¿‡æ ‡ç­¾æ¥è§£å†³ï¼Œå”¯ç‹¬æ¯”è¾ƒéº»çƒ¦çš„æ˜¯ï¼Œåœ¨åŒä¸€ä¸ªç»´åº¦æœ‰å¤šä¸ªå€¼çš„æƒ…å†µï¼Œæ¯”å¦‚K=V1 K=V2è¿™ç§æƒ…å†µï¼Œè¿™ç§æƒ…å†µç›®å‰ä¸æ”¯æŒï¼Œå› ä¸ºæ ‡ç­¾ä¿¡æ¯ä¼šè¢«é™„åˆ°ç›‘æ§å¯¹è±¡çš„æ—¶åºæ•°æ®ä¸Šï¼Œæ—¶åºæ•°æ®çš„æ ‡ç­¾æ˜¯mapç»“æ„ï¼Œæ‰€ä»¥K=V1 K=V2è¿™ç§Kç›¸åŒçš„æƒ…å†µä¼šäº§ç”Ÿè¦†ç›–ï¼Œæ•…è€Œé¡µé¢ä¸Šç›‘æ§å¯¹è±¡æ‰“æ ‡ç­¾çš„æ—¶å€™å‹æ ¹å°±ä¸å…è®¸è¿™ç§æ ‡ç­¾ã€‚\n ä¸ºä½•æˆ‘çš„target_upæŒ‡æ ‡ä¸€ä¼šæ˜¯0ä¸€ä¼šæ˜¯1ï¼Œå¯¼è‡´ä¸€ä¼šæœ‰å‘Šè­¦ä¸€ä¼šåˆæ¢å¤äº†   è¿™ä¸ªå¾ˆå¯èƒ½æ˜¯å› ä¸ºè°ƒæ•´äº†å®¢æˆ·ç«¯é‡‡é›†ä¸ŠæŠ¥é¢‘ç‡å¯¼è‡´çš„ï¼Œé»˜è®¤Telegrafä¸ŠæŠ¥é¢‘ç‡æ˜¯10sï¼Œä¸ä¼šæœ‰è¿™ä¸ªé—®é¢˜ï¼Œn9e-serveræ¯15sç”Ÿæˆä¸€æ¬¡target_upçš„å€¼ï¼Œæ ‡è¯†æœºå™¨æ˜¯å¦åœ¨æ­£å¸¸ä¸ŠæŠ¥æ•°æ®ï¼Œå¦‚æœå‘ç°æœºå™¨æœ‰æŒ‡æ ‡åœ¨ä¸ŠæŠ¥ï¼Œtarget_upå°±ç½®ä¸º1ï¼Œå¦åˆ™å°±æ˜¯0ï¼Œå¦‚æœæŠŠå®¢æˆ·ç«¯é‡‡é›†ä¸ŠæŠ¥é¢‘ç‡è°ƒå¤§ï¼Œæ¯”å¦‚æ”¹æˆ60sï¼Œé‚£n9e-serveråœ¨æŸäº›å‘¨æœŸæ£€æŸ¥çš„æ—¶å€™ï¼Œç¡®å®å°±å‘ç°å®¢æˆ·ç«¯æ²¡æœ‰ä¸ŠæŠ¥æ•°æ®ï¼Œæ¯•ç«Ÿä¸ŠæŠ¥é¢‘ç‡å¤ªå¤§äº†ã€‚æ­¤æ—¶å¯ä»¥è°ƒæ•´server.confçš„é…ç½®ï¼ŒæŠŠæ£€æµ‹å®¢æˆ·ç«¯æ˜¯å¦å­˜æ´»çš„å‘¨æœŸä¹Ÿæ”¾å¤§ä¸€äº›ï¼Œæ¯”å¦‚è°ƒæ•´ä¸º60ç§’ï¼š\n[NoData] Metric = \"target_up\" # unit: second Interval = 60 å‘Šè­¦è§„åˆ™ä¹Ÿå¯ä»¥é’ˆå¯¹è¿™ç§æƒ…å†µåšä¸€äº›è°ƒæ•´ï¼Œæ¯”å¦‚æ”¹æˆï¼š\n# å‘Šè­¦è§„åˆ™çš„æŒç»­æ—¶é•¿è®¾ç½®ä¸º0ï¼Œè¯¥PromQLè¡¨ç¤º130så†…ä¸€ç›´éƒ½æ²¡æœ‰ç›‘æ§æ•°æ®ä¸ŠæŠ¥ï¼Œæ•…è€Œè¦æŠ¥è­¦ã€‚ max_over_time(target_up[130s]) == 0 target_upæŒ‡æ ‡æ˜¯0ï¼Œè¿˜æœ‰å¯èƒ½çš„åŸå› æ˜¯å®¢æˆ·ç«¯å¤¯ä½äº†ï¼Œå¯ä»¥é‡å¯ä¸€ä¸‹å®¢æˆ·ç«¯è¯•è¯•ï¼Œæˆ–è€…æ˜¯å®¢æˆ·ç«¯æ‰€åœ¨æœºå™¨å½“å‰å‹åŠ›è¿‡å¤§ï¼Œå½±å“äº†å®¢æˆ·ç«¯åˆ°æœåŠ¡ç«¯çš„ç½‘ç»œé€šä¿¡ã€‚\n å¤œèºç”¨çš„redisæ”¯æŒclusterç‰ˆæœ¬æˆ–è€…sentinelç‰ˆæœ¬å—ï¼Ÿ   ä¸æ”¯æŒï¼Œå°±æ˜¯ç”¨çš„å•æœºç‰ˆï¼Œæ”¹é€ æˆclusterç‰ˆæœ¬æˆ–è€…sentinelåº”è¯¥ä¹Ÿæ²¡å•¥å¤ªå¤§é—®é¢˜ï¼Œä¸€èˆ¬å…¬æœ‰äº‘ä¼šæä¾›é«˜å¯ç”¨çš„redisï¼Œä¸€ä¸»ä¸€ä»é‚£ç§ï¼Œè¶³å¤Ÿç”¨äº†ï¼Œè‡ªå·±æ­å»ºä¹Ÿå¯ä»¥ï¼Œæœºå™¨æŒ‚æ‰çš„æ¦‚ç‡å…¶å®å¾ˆå°ï¼Œæ»¡è¶³slaé—®é¢˜ä¸å¤§çš„\n Telegrafä¸ŠæŠ¥çš„ä¸»æœºæ ‡è¯†é»˜è®¤ç”¨çš„æœºå™¨åï¼Œå¯ä»¥è®©å®ƒè‡ªåŠ¨ä¸ŠæŠ¥IPä½œä¸ºæœ¬æœºæ ‡è¯†å—ï¼Ÿ   å¯ä»¥è®©å®ƒä¸ŠæŠ¥IPä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œä½†æ˜¯è¦æƒ³è‡ªåŠ¨è·å–IPï¼Œåšä¸åˆ°ã€‚ä¸ªäººå»ºè®®æ˜¯ä½¿ç”¨ä¸€äº›æ‰¹é‡æ‰§è¡Œå·¥å…·ï¼Œæ¯”å¦‚ansibleä¹‹ç±»çš„ï¼Œæ‰¹é‡éƒ¨ç½²Telegrafï¼Œéƒ¨ç½²è„šæœ¬é‡Œè‡ªåŠ¨è·å–ç›®æ ‡æœºå™¨çš„IPï¼Œç„¶åå¡«å……åˆ°telegraf.confä¸­ã€‚\n è§¦å‘å‘Šè­¦å’Œè§¦å‘æ¢å¤çš„é€»è¾‘æ˜¯ä»€ä¹ˆï¼Ÿ   å‘Šè­¦è§„åˆ™é‡Œæœ‰3ä¸ªé…ç½®éå¸¸å…³é”®ï¼Œpromqlã€æ‰§è¡Œé¢‘ç‡ã€æŒç»­æ—¶é•¿ï¼Œæ„æ€å°±æ˜¯æŒ‰ç…§æ‰§è¡Œé¢‘ç‡ï¼Œæ¯éš”ä¸€æ®µæ—¶é—´æ‰§è¡ŒpromqlæŸ¥è¯¢ï¼ˆå³æ—¶æŸ¥è¯¢ï¼Œå³è°ƒç”¨Prometheusåè®®çš„/api/v1/queryæ¥å£ï¼‰ï¼Œå¦‚æœæŸ¥åˆ°æ•°æ®å°±è®¤ä¸ºè§¦å‘äº†é˜ˆå€¼ï¼Œè§¦å‘äº†é˜ˆå€¼æ˜¯å¦ä¼šäº§ç”Ÿå‘Šè­¦äº‹ä»¶ï¼Œä¸ä¸€å®šï¼Œè¿˜è¦çœ‹æŒç»­æ—¶é•¿ï¼Œå¦‚æœæŒç»­æ—¶é•¿ä¸º0ï¼Œå°±ç›¸å½“äºä¸ç”¨ç­‰å¾…ï¼Œè§¦å‘äº†é˜ˆå€¼å°±ç«‹é©¬ç”Ÿæˆäº‹ä»¶ï¼Œå¦‚æœæŒç»­æ—¶é•¿å¤§äº0ï¼Œé‚£å°±è¦ç­‰å¾…ï¼Œè¦ä¿è¯æŒç»­æ—¶é•¿è¿™æ®µæ—¶é—´å†…ï¼Œæ¯æ¬¡æ‰§è¡Œpromqlçš„æŸ¥è¯¢éƒ½è§¦å‘é˜ˆå€¼ï¼Œæ‰è®¤ä¸ºåº”è¯¥ç”Ÿæˆäº‹ä»¶ã€‚æŒç»­æ—¶é•¿å°±ç›¸å½“äºprometheus.ymlä¸­çš„alert ruleä¸­çš„forã€‚\næ¯”å¦‚promqlä¸º cpu_usage_idle{cpu=\"cpu-total\"} \u003c 20ï¼Œæ‰§è¡Œé¢‘ç‡æ˜¯10sï¼ŒæŒç»­æ—¶é•¿æ˜¯60sï¼Œå°±è¡¨ç¤ºåœ¨60så†…æ¯10sæ‰§è¡Œä¸€æ¬¡promqlæŸ¥è¯¢ï¼Œçœ‹promqlæŸ¥è¯¢æ˜¯å¦è¿”å›å†…å®¹ï¼Œå¦‚æœ6æ¬¡éƒ½è¿”å›äº†ï¼Œè¯´æ˜åº”è¯¥ç”Ÿæˆå‘Šè­¦äº‹ä»¶ã€‚\næ¢å¤çš„é€»è¾‘ï¼šæ¯”å¦‚å·²ç»äº§ç”Ÿäº†å‘Šè­¦äº‹ä»¶ï¼Œç„¶åå†æ¬¡æ‹¿ç€promqlå»æŸ¥è¯¢ï¼Œå‘ç°æ²¡æœ‰è¿”å›å†…å®¹ï¼Œé‚£å°±è¯´æ˜å½“å‰çš„ç›‘æ§æ•°æ®å·²ç»ä¸ç¬¦åˆpromqlä¸­æŒ‡å®šçš„é˜ˆå€¼æ¡ä»¶äº†ï¼Œå°±è¡¨ç¤ºæ¢å¤äº†ã€‚å½“ç„¶ï¼Œ å¦‚æœæ•°æ®ä¸¢ç‚¹äº†ï¼Œpromqlè‡ªç„¶ä¹ŸæŸ¥ä¸åˆ°ï¼Œè¿™ç§æƒ…å†µä¹Ÿæ˜¯ä¼šæŠ¥æ¢å¤ï¼Œå› ä¸ºå¤œèºç¡®å®æ— æ³•åŒºåˆ†åˆ°åº•æ˜¯å› ä¸ºä¸¢ç‚¹äº†ï¼Œè¿˜æ˜¯å› ä¸ºæ²¡æœ‰æ»¡è¶³é˜ˆå€¼è€Œå¯¼è‡´æ²¡æœ‰è¿”å›å†…å®¹ã€‚é‚£ä½ å¯èƒ½ä¼šé—®ï¼ŒæŠŠpromqlè§£æä¸€ä¸‹ï¼Œå»æ‰promqlä¸­çš„æ“ä½œç¬¦å’Œé˜ˆå€¼ï¼Œåªæ‹¿ç€å‰é¢éƒ¨åˆ†å»æŸ¥è¯¢ï¼Œä¸å°±èƒ½åŒºåˆ†åˆ°åº•æ˜¯æ²¡æ•°æ®è¿˜æ˜¯å› ä¸ºæ²¡æœ‰æ»¡è¶³é˜ˆå€¼äº†å—ï¼Ÿå…¶å®å¾ˆéš¾ï¼Œä¸Šé¢ä¸¾ä¾‹çš„promqlæ˜¯ä¸€ç§ç®€å•æƒ…å†µï¼Œå¤æ‚çš„promqléå¸¸å¤æ‚ï¼Œæ²¡æ³•è¿™ä¹ˆè½»æ˜“çš„æ‹¿æ‰æ“ä½œç¬¦å’Œé˜ˆå€¼ã€‚\n å¦‚ä½•ç›‘æ§æœºå™¨çš„CPUã€å†…å­˜ã€ç£ç›˜ã€IOã€ç½‘ç»œã€è¿›ç¨‹ï¼Ÿ   è¿™ä¸ªé—®é¢˜ï¼Œæ–‡æ¡£é‡Œæœ‰ç­”æ¡ˆï¼ŒTelegrafç« èŠ‚ï¼Œæœ‰ä¸ªè°ƒç ”ç¬”è®°çš„é“¾æ¥ï¼Œè°ƒç ”ç¬”è®°ä¸­æè¿°çš„å¾ˆæ¸…æ¥šäº†ï¼Œé™¤äº†æœºå™¨å±‚é¢çš„è¿™äº›ç›‘æ§é¡¹ï¼Œè¿˜æœ‰è®²å¦‚ä½•åšPINGç›‘æ§ï¼ŒTCPæ¢æµ‹ç­‰\n å¤œèºå¯ä»¥æ¥å…¥åˆ°Grafanaæ¥å±•ç¤ºå—ï¼Ÿ   å¯ä»¥ã€‚ä½†ä¸æ˜¯æŠŠå¤œèºä½œä¸ºDataSourceï¼Œå› ä¸ºå®åœ¨æ˜¯æ²¡å¿…è¦ã€‚å¤œèºåç«¯å¯ä»¥æ¥å…¥å¤šä¸ªæ—¶åºåº“ï¼šPrometheusã€M3DBã€VictoriaMetricsç­‰ï¼Œè¿™äº›æ—¶åºåº“éƒ½å¯ä»¥ç›´æ¥ä½œä¸ºGrafanaçš„DataSourceï¼Œæ‰€ä»¥ï¼Œåªè¦ç›‘æ§æ•°æ®è¿›äº†è¿™äº›æ—¶åºåº“äº†ï¼ŒGrafanaå°±å¯ä»¥ç›´æ¥å±•ç¤ºäº†\n å¤œèºå¯ä»¥é…ç½®InfluxDBçš„QLåšå‘Šè­¦è§„åˆ™å—ï¼Ÿ   ä¸æ”¯æŒï¼Œå½“å‰åªæ”¯æŒé…ç½®promqlï¼Œå¤œèºæ¥å…¥æ—¶åºåº“ï¼Œæœ‰ä¸¤ä¸ªå±‚é¢çš„æ¥å…¥ï¼Œä¸€æ˜¯é€šè¿‡remote writeï¼ŒæŠŠå¤œèºæ”¶åˆ°çš„æ•°æ®è½¬å‘ç»™æ—¶åºåº“ï¼Œæ‰€æœ‰æ”¯æŒremote write æ¥å£çš„å­˜å‚¨éƒ½å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼æ¥å…¥å¤œèºï¼Œæ¥æ”¶å¤œèºè½¬å‘è¿‡æ¥çš„æ•°æ®ï¼›äºŒæ˜¯æ—¶åºåº“å¦‚æœå¼€æ”¾å…¼å®¹Prometheusçš„Querieræ¥å£ï¼Œé‚£å¤œèºè¿˜å¯ä»¥è¯»å–æ—¶åºåº“çš„æ•°æ®åšå‘Šè­¦åˆ¤æ–­ï¼Œå³Prometheusã€M3DBã€VictoriaMetricsã€Thanosç­‰è¿™äº›å­˜å‚¨ï¼Œéƒ½å®Œå…¨å…¼å®¹Prometheusçš„Querieræ¥å£ï¼Œåˆ™å¤œèºå¯ä»¥é…ç½®å‘Šè­¦è§„åˆ™ï¼Œä»è¿™äº›å­˜å‚¨ä¸­è¯»å–ç›‘æ§æ•°æ®åšå‘Šè­¦åˆ¤æ–­ã€‚è€ŒOpenTSDBã€InfluxDBç­‰ï¼Œå› ä¸ºä¸æ”¯æŒPrometheusçš„Querieræ¥å£ï¼Œæ‰€ä»¥å¤œèºçš„å‘Šè­¦è§„åˆ™ï¼Œæ²¡æ³•è¯»å–è¿™äº›å­˜å‚¨çš„æ•°æ®åšåˆ¤æ–­ï¼Œè¿™äº›å­˜å‚¨åªèƒ½ä½œä¸ºremote writeçš„å†™å…¥ç«¯ã€‚\n ä»å“ªé‡Œè·å–å¾®ä¿¡æœºå™¨äººtokenï¼Ÿ   é¦–å…ˆï¼Œæ˜¯ä¼ä¸šå¾®ä¿¡ï¼Œä¸æ˜¯å¾®ä¿¡ï¼Œåœ¨ä¼ä¸šå¾®ä¿¡é‡Œå»ºä¸ªç¾¤ï¼Œç‚¹å¼€ç¾¤ç®¡ç†ï¼Œæ·»åŠ æœºå™¨äººï¼Œå®Œäº‹æŸ¥çœ‹è¿™ä¸ªæœºå™¨äººçš„ä¿¡æ¯ï¼Œå³å¯çœ‹åˆ°webhookåœ°å€ï¼Œwebhookåœ°å€ä¸­åŒ…å«ä¸€ä¸ªkeyçš„å‚æ•°ï¼Œkey=åé¢å°±æ˜¯tokenã€‚æ‹¿ç€è¿™ä¸ªtokenï¼Œå»å¤œèºé‡Œåˆ›å»ºä¸€ä¸ªç”¨æˆ·ï¼Œæ¯”å¦‚å°±å«xxä¼å¾®æœºå™¨äººï¼Œç»™è¿™ä¸ªç”¨æˆ·è®¾ç½®ä¸€ä¸‹Wecom Robot Tokenï¼Œé…ç½®ä¸ºåˆšæ‰ä»webhookä¸­è·å–çš„tokenï¼Œåé¢æŠŠè¿™ä¸ªäººåŠ å…¥å‘Šè­¦æ¥æ”¶ç»„ï¼Œç›¸å…³çš„å‘Šè­¦å°±ä¼šå‘ç»™ä¼ä¸šå¾®ä¿¡çš„è¿™ä¸ªç¾¤ç»„ã€‚\n ç›‘æ§å¯¹è±¡åˆ—è¡¨ä¸­å¦‚ä½•æ·»åŠ ç›‘æ§å¯¹è±¡ï¼Ÿçœ‹åˆ°ç›‘æ§å¯¹è±¡åˆ—è¡¨å’Œå¯¹è±¡è§†è§’éƒ½æ˜¯ç©ºçš„   å…¬ä¼—å·çš„è§†é¢‘æ•™ç¨‹è¦æ•´ä½“çœ‹ä¸€éï¼Œå°±ç†è§£æ•´ä¸ªè®¾è®¡äº†ã€‚ç®€è€Œè¨€ä¹‹ï¼Œç›‘æ§æ•°æ®éœ€è¦ä¸ŠæŠ¥ç»™n9e-serverï¼Œç„¶åç”±n9e-serverè½¬å‘ç»™æ—¶åºåº“ï¼Œå³ç›‘æ§æ•°æ®è¦æµç»n9e-serverï¼Œn9e-serveræ‰æœ‰å¯èƒ½ä»ç›‘æ§æ•°æ®ä¸­æå–identæ ‡ç­¾çš„å€¼ï¼Œn9e-serverä¼šæŠŠidentæ ‡ç­¾çš„å€¼ä½œä¸ºç›‘æ§å¯¹è±¡æ³¨å†Œåˆ°æ•°æ®åº“ä¸­ï¼Œæ‰èƒ½åœ¨åˆ—è¡¨ä¸­çœ‹åˆ°ã€‚å¦‚æœç›‘æ§æ•°æ®çš„æ•´ä¸ªä¼ è¾“è¿‡ç¨‹æ²¡æœ‰æµç»n9e-serverï¼Œæˆ–ç›‘æ§æ•°æ®ä¸­æ²¡æœ‰identæ ‡ç­¾ï¼Œä¹Ÿå°±æ²¡æ³•æå–åˆ°äº†ã€‚\nå¤œèºå¯ä»¥æ”¯æŒTelegrafä½œä¸ºå®¢æˆ·ç«¯é‡‡é›†å™¨ï¼Œä¹Ÿå¯ä»¥æ”¯æŒgrafana-agentä½œä¸ºé‡‡é›†å™¨ï¼Œè¿™ä¿©é‡‡é›†å™¨å®é™…éƒ½æ²¡æ³•ä¸ŠæŠ¥identæ ‡ç­¾ï¼Œä½†æ˜¯Telegrafä¼šä¸ŠæŠ¥hostæ ‡ç­¾ï¼Œgrafana-agentä¼šä¸ŠæŠ¥agent_hostnameæ ‡ç­¾ï¼Œè¿™ä¿©æ ‡ç­¾ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºidentå­—æ®µã€‚\nå½“ç„¶ï¼Œå³ä½¿æ²¡æœ‰æ³¨å†Œåˆ°å¯¹è±¡è§†è§’ä¸­ï¼Œå…¶å®ä¹Ÿä¸è€½è¯¯ï¼Œæ²¡å•¥å¤§ä¸äº†çš„ï¼Œåªæ˜¯æœªæ¥çœ‹ç›‘æ§å›¾è¡¨çš„æ—¶å€™ï¼Œæ²¡æ³•ä½¿ç”¨å¯¹è±¡è§†è§’çœ‹å›¾ç½¢äº†ã€‚åé¢å¤œèºä¹Ÿä¼šæŒç»­ä¼˜åŒ–ï¼Œå¢åŠ è‡ªå®šä¹‰è§†å›¾ï¼Œåˆ°æ—¶å€™å¯¹è±¡è§†è§’çš„çœ‹å›¾å¯èƒ½å°±å¯æœ‰å¯æ— äº†ã€‚\n v5ç‰ˆæœ¬å¦‚ä½•é€šè¿‡apiæ¥å£ä¸ŠæŠ¥æ•°æ®çš„æ—¶å€™é¡ºä¾¿å¸¦ä¸Šaliaså­—æ®µï¼Ÿ   v5ç›®å‰æ”¯æŒçš„ä¸ŠæŠ¥æ¥å£æ˜¯opentsdbçš„åè®®ã€remote writeåè®®ã€datadogçš„åè®®ï¼Œéƒ½ä¸æ”¯æŒaliaså­—æ®µï¼Œè€Œæ•°æ®åº“ä¸­ä¹Ÿå¹²æ‰äº†è¿™ä¸ªå­—æ®µï¼Œæ‰€ä»¥ï¼Œv5æ²¡æ³•é€šè¿‡apiä¸ŠæŠ¥è¿™ä¸ªå­—æ®µäº†ï¼Œä¸è¿‡v5æœ‰å¤‡æ³¨å­—æ®µï¼Œå’Œè‡ªå®šä¹‰æ ‡ç­¾å­—æ®µï¼Œå¯ä»¥è€ƒè™‘ç”¨è¿™ä¿©å­—æ®µæ”¾ç½®åˆ«åï¼Œè¿™éœ€è¦ç›´æ¥æ“ä½œDBï¼Œæˆ–è€…é€šè¿‡APIä¿®æ”¹ç›‘æ§å¯¹è±¡ï¼Œæ€»ä¹‹ï¼Œæ— æ³•é€šè¿‡ä¸ŠæŠ¥æ•°æ®çš„æ¥å£æ¥æå®š\n v5é‚®ä»¶å‘Šè­¦çš„æœåŠ¡å™¨é…ç½®ï¼ˆsmtpï¼‰åœ¨å“ªé‡Œï¼Ÿ   v5.4ï¼ˆå«ï¼‰ä¹‹åçš„ç‰ˆæœ¬ï¼Œåœ¨server.confä¸­ï¼Œv5.4ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œåœ¨etc/script/notify.pyä¸­ï¼Œè„šæœ¬çš„å‰é¢å‡ è¡Œï¼Œå¾ˆå®¹æ˜“æ‰¾åˆ°\n æˆ‘åœ¨Aä¸šåŠ¡ç»„é…ç½®çš„å‘Šè­¦è§„åˆ™ï¼Œä¸ºä½•æ”¶åˆ°äº†Bä¸šåŠ¡ç»„çš„æœºå™¨çš„å‘Šè­¦ï¼Ÿ   å‘Šè­¦è§„åˆ™çš„é€»è¾‘å¯ä»¥æŸ¥çœ‹009å·é—®é¢˜ï¼Œæ¯æ¬¡å°±æ˜¯ç”¨promqlæŸ¥è¯¢æ—¶åºåº“ï¼Œè€Œæ—¶åºåº“é‡Œæ˜¯æ²¡æœ‰ä¸šåŠ¡ç»„çš„ä¿¡æ¯çš„ï¼Œæ‰€ä»¥promqlå°±ç”Ÿæ•ˆåˆ°äº†å…¨é‡çš„ç›‘æ§å¯¹è±¡ä¸Šäº†ã€‚æ¨èåšæ³•ï¼šaä¸šåŠ¡ç»„çš„æœºå™¨ï¼Œç»Ÿä¸€æ‰“ä¸Šbg=açš„æ ‡ç­¾ï¼Œbä¸šåŠ¡ç»„çš„æœºå™¨ç»Ÿä¸€æ‰“ä¸Šbg=bçš„æ ‡ç­¾ï¼Œé…ç½®å‘Šè­¦è§„åˆ™çš„æ—¶å€™ï¼Œè¦å¸¦ä¸Šè¿™ä¸ªæ ‡ç­¾åšç­›é€‰ï¼Œæ¯”å¦‚ cpu_usage_idle{bg=\"a\"}\u003c15 å°±è¡¨ç¤ºåªæœ‰bg=aè¿™ä¸ªæ ‡ç­¾çš„æœºå™¨ç”Ÿæ•ˆï¼Œå³åªæœ‰aä¸šåŠ¡ç»„çš„æœºå™¨ç”Ÿæ•ˆã€‚\nè¿‘æœŸå¤œèºæ–°ç‰ˆæœ¬æ”¯æŒåœ¨å‘Šè­¦è§„åˆ™é…ç½®çš„æ—¶å€™æŒ‡å®šåªåœ¨æœ¬ä¸šåŠ¡ç»„ç”Ÿæ•ˆï¼Œä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œåç»­ä¹Ÿä¼šæ”¯æŒæŠŠä¸šåŠ¡ç»„ç›´æ¥ä½œä¸ºæ ‡ç­¾é™„åˆ°æ—¶åºæ•°æ®ä¸Šï¼Œåˆ°æ—¶å€™å°±æ›´æ–¹ä¾¿äº†\n Telegrafæ¨é€æ•°æ®ç»™n9e-serverï¼Œå¦‚ä½•åŠ ä¸Šè®¤è¯æœºåˆ¶ä¿è¯å®‰å…¨ï¼Ÿ   Telegrafä½¿ç”¨datadogçš„outputåæ•°æ®ç»™n9e-serverï¼ˆç‰ˆæœ¬è¦åœ¨5.2.1ä»¥ä¸Šï¼‰\n[[outputs.datadog]] timeout = \"5s\" url = \"http://localhost:19000/datadog/api/v1/series\" apikey = \"datadog-api-key\" n9e-serverä¸­åŠ ä¸Šè¿™ä¸ªé…ç½®ï¼š\n[BasicAuth] apiKey = \"datadog-api-key\" æ³¨æ„ï¼šè¿™æ ·é…ç½®ä¹‹åï¼Œè¡¨ç¤ºn9e-serverçš„æ‰€æœ‰è¯·æ±‚éƒ½èµ°basic authè®¤è¯ï¼ŒåŸæ¥Telegrafé€šè¿‡openTSDBçš„æ¥å£åæ•°æ®çš„é“¾è·¯å°±èµ°ä¸é€šäº†\n ä»ä½ç‰ˆæœ¬æ€ä¹ˆå‘é«˜ç‰ˆæœ¬å‡çº§ï¼Ÿ   é¦–å…ˆå»githubçš„ releases é¡µé¢ æ‰¾åˆ°è‡ªå·±çš„ç‰ˆæœ¬ï¼Œç„¶åæŒ¨ä¸ªæŸ¥çœ‹æ¯ä¸ªæ¯”ä½ é«˜çš„ç‰ˆæœ¬ï¼Œçœ‹çœ‹å„ä¸ªç‰ˆæœ¬çš„release logä¸­å†™äº†è¦æ›´æ–°å“ªäº›å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨sqlç›¸å…³çš„ï¼Œæ¯”å¦‚ä½ çš„ç‰ˆæœ¬æ˜¯5.1.0ï¼Œå½“å‰ç‰ˆæœ¬æ˜¯5.3.0ï¼Œé‚£ä½ è¦çœ‹ ( 5.1.0, 5.3.0 ]ä¹‹é—´çš„æ‰€æœ‰ç‰ˆæœ¬ï¼Œä»ä½åˆ°é«˜æŒ¨ä¸ªæŸ¥çœ‹ï¼ŒæŠŠæ¯ä¸ªç‰ˆæœ¬çš„release logä¸­çš„sqléƒ½æ‰§è¡Œä¸€éï¼ˆå¦‚æœrelease logä¸­æ²¡æœ‰æsqlè¯­å¥ï¼Œè¯´æ˜è¿™å‡ ä¸ªç‰ˆæœ¬æ²¡æœ‰DBè¡¨ç»“æ„å˜æ›´ï¼Œé‚£æ›´ç®€å•äº†ï¼‰ï¼Œæœ€åæ›¿æ¢n9eäºŒè¿›åˆ¶å’Œetcä¸‹çš„å†…å®¹åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Œå¦‚æœä½ ä¹‹å‰etcä¸‹æœ‰äº›ç‰¹æ®Šé…ç½®ï¼Œè®°å¾—è¦åŸºäºæœ€æ–°çš„é…ç½®æ–‡ä»¶å†ä¿®æ”¹ä¸‹\n telegrafçš„åŸºæœ¬é…ç½®å’Œä¸­é—´ä»¶é‡‡é›†çš„é…ç½®éƒ½æ”¾åˆ°ä¸€ä¸ªtelegraf.confä¸­ä¸å¥½ç®¡ç†æ€ä¹ˆåŠï¼Ÿ   telegrafå¯åŠ¨çš„æ—¶å€™æ”¯æŒä¸¤ä¸ªå‚æ•°--configå’Œ--config-directoryï¼Œè¿™ä¿©å‚æ•°å¯ä»¥ä¸€å¹¶ä½¿ç”¨ï¼Œé€šè¿‡--configæŒ‡å®šä¸»é…ç½®æ–‡ä»¶ï¼Œé€šè¿‡--config-directoryæŒ‡å®šé…ç½®ç›®å½•ï¼Œå„ç§éé€šç”¨çš„é…ç½®ï¼Œéƒ½å¯ä»¥æ”¾åˆ°é…ç½®ç›®å½•é‡Œï¼Œæ¯ä¸ªé…ç½®æ–‡ä»¶ä»¥.confç»“å°¾ï¼Œè¿™æ ·telegrafå°±å¯ä»¥éƒ½è¯†åˆ«åˆ°äº†ï¼Œæ¯”å¦‚ï¼š\n./usr/bin/telegraf --config etc/telegraf/telegraf.conf --config-directory etc/telegraf.d ç„¶åæˆ‘åšäº†ä¸€ä¸ªmysql.confæ”¾åˆ°telegraf.dç›®å½•ä¸‹ï¼Œä¸“é—¨ç”¨äºç›‘æ§mysqlï¼Œå†…å®¹å¦‚ä¸‹ï¼Œä¾›å¤§å®¶å‚è€ƒï¼š\n[[inputs.mysql]] servers = [\"root:1234@tcp(localhost:3306)/?tls=false\"] metric_version = 2 gather_global_variables = true interval_slow = \"1m\" tagexclude = [\"innodb_version\"] Any Questions? å¦‚æœé—®é¢˜ä»ç„¶æ²¡æœ‰è§£å†³ï¼Œè¯·åŠ å¾®ä¿¡å…¬ä¼—å·ï¼šcloudmon å…¬ä¼—å·åº•éƒ¨èœå•æœ‰å„ç§ç­”ç–‘æ–¹å¼\n",
    "description": "",
    "tags": null,
    "title": "FAQ",
    "uri": "/faq/"
  },
  {
    "content": " Telegraf Windowsç‰ˆæœ¬çš„å®‰è£…ï¼Œä¿å§†çº§æ•™ç¨‹ - by SL Telegraf Linuxç‰ˆæœ¬çš„å®‰è£…ï¼Œä¿å§†çº§æ•™ç¨‹ - by SL å¼ƒç”¨Prometheusï¼Œæ­å»ºå•æœºç‰ˆæœ¬çš„VictoriaMetrics - by SL ä¸€é”®éƒ¨ç½²å¤œèºåˆ°Kubernetes - by é™¶æŸ’ ä½¿ç”¨Telegrafåšå¤œèº5.0çš„æ•°æ®é‡‡é›†ï¼Œæ ·ä¾‹åŒ…å«LinuxåŸºæœ¬ä¿¡æ¯é‡‡é›†ã€MySQLã€Redisçš„é‡‡é›† - by æŸ´ä»Šæ ‹@è‰¾æ´¾ telegrafå¸¸ç”¨ä¸­é—´ä»¶é‡‡é›† ä¿®æ”¹notify.pyä¸ºå¤œèºå¢åŠ çŸ­ä¿¡é€šçŸ¥èƒ½åŠ› - by æŸ´ä»Šæ ‹@è‰¾æ´¾ ä½¿ç”¨notify.pyæ¥å…¥é˜¿é‡Œäº‘è¯­éŸ³é€šçŸ¥ - by æœ Oracleçš„ç®€å•ç›‘æ§å®ç° - by æŸ´ä»Šæ ‹@è‰¾æ´¾ RocketMQç®€å•ç›‘æ§çš„å®ç° - by æŸ´ä»Šæ ‹@è‰¾æ´¾ æ‰‹æŠŠæ‰‹æ•™ä½ æ¥å…¥é’‰é’‰å‘Šè­¦ ä¸€æ–‡è¯´é€MySQLç›‘æ§ï¼Œä½¿ç”¨Prometheusç”Ÿæ€çš„Exporter Vsphere-monitoræ•°æ®ä¸ŠæŠ¥å¤œèºV5ç›‘æ§ ä½¿ç”¨pgä½œä¸ºæ•°æ®åº“æ›¿æ¢MySQL  ",
    "description": "",
    "tags": null,
    "title": "ç¤¾åŒºç”¨æˆ·å®è·µåˆ†äº«",
    "uri": "/usecase/"
  },
  {
    "content": " Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\n å¦‚æœæ‚¨ä½¿ç”¨å’Œç®¡ç†ç€Kubernetesé›†ç¾¤ä»¥åŠæ‚¨çš„åº”ç”¨è¿è¡Œåœ¨Kubernetesä¹‹ä¸Šï¼Œè¯·å‚è€ƒ åœ¨K8sä¸­ä½¿ç”¨grafana-agentã€‚\nåœ¨Windowsç¯å¢ƒå®‰è£…å’Œè¿è¡Œgrafana-agent  ä»Grafana github releasesä¸‹è½½Windowså®‰è£…æ–‡ä»¶ï¼› è¿è¡Œå®‰è£…æ–‡ä»¶åï¼Œä¼šå¯¹grafana-agentè¿›è¡Œé…ç½®ï¼Œå¹¶æ³¨å†Œä¸ºWindowsæœåŠ¡ï¼› æ›´è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼Œå¯ä»¥å‚è€ƒWindows Guideï¼›  åœ¨Dockerä¸­è¿è¡Œgrafana-agent å¦‚æœæ‚¨çš„å®¿ä¸»æœºä¸Šè¿è¡Œæœ‰dockeræœåŠ¡ï¼Œé‚£ä¹ˆä½¿ç”¨dockerè¿è¡Œgrafana-agent æ˜¯æœ€å¿«æ·çš„æ–¹å¼ã€‚åœ¨å‘½ä»¤è¡Œç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå³å¯åœ¨å®¹å™¨ä¸­å¯åŠ¨grafana-agentï¼š\n1. ç”Ÿæˆ grafana-agent çš„é…ç½®æ–‡ä»¶ cat \u003c\u003cEOF \u003e /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s configs: - name: flashtest host_filter: false scrape_configs: - job_name: local_scrape static_configs: - targets: ['127.0.0.1:12345'] labels: cluster: 'mymac' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e EOF 2. å¯åŠ¨ grafana-agent å®¹å™¨ docker run \\  -v /tmp/agent:/etc/agent/data \\  -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\  -p 12345:12345 \\  -d \\  grafana/agent \\  --config.file=/etc/agent/agent.yaml \\  --prometheus.wal-directory=/etc/agent/data æˆ–è€…æ‚¨ä¹Ÿå¯ä»¥ä» Dockerfile åœ¨æœ¬åœ° build é•œåƒä¹‹åå†è¿è¡Œï¼š\ncurl -sO https://raw.githubusercontent.com/grafana/agent/main/cmd/agent/Dockerfile docker build -t grafana/agent:latest -f ./Dockerfile ä¸Šè¿°æ­¥éª¤ä¸­ï¼Œå‡ ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹ï¼š\n remote_write å’Œ basic_auth ï¼Œè¯·æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µå¡«å†™ï¼› -p æŠŠå®¹å™¨ä¸­çš„ç«¯å£12345æ˜ å°„åˆ°ä¸»æœºï¼Œ-d æŠŠå®¹å™¨è¿›ç¨‹æ”¾åˆ°åå°è¿è¡Œï¼› -v /tmp/agent:/etc/agent/data æ˜¯æŠŠå®¿ä¸»æœºçš„ç›®å½• /tmp/agent æ˜ å°„åˆ°å®¹å™¨ä¸­ /etc/agent/dataï¼Œç”¨äº grafana-agent æŒä¹…åŒ–ä¿å­˜å…¶ WAL(Write Ahead Log) ï¼› -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml æ˜¯æŠŠ grafana-agent çš„é…ç½®æ–‡ä»¶ï¼Œæ”¾ç½®åˆ°å®¹å™¨æŒ‡å®šçš„ä½ç½®ï¼Œå³ /etc/agent/agent.yaml  3. éªŒè¯ grafana-agent æ˜¯å¦æ­£å¸¸å·¥ä½œ æ‚¨å¯ä»¥é€šè¿‡ç›´æ¥ curl http://localhost:12345/metrics æ¥éªŒè¯æ•°æ®çš„äº§ç”Ÿæ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¼šæ˜¾ç¤ºå¦‚ä¸‹ï¼š\nagent_build_info{branch=\"HEAD\",goversion=\"go1.17.6\",revision=\"36b8ca75\",version=\"v0.23.0\"} 1 agent_inflight_requests{method=\"GET\",route=\"metrics\"} 1 agent_metrics_active_configs 1 agent_metrics_active_instances 1 agent_tcp_connections{protocol=\"grpc\"} 0 agent_tcp_connections{protocol=\"http\"} 2 go_gc_duration_seconds_sum 0.0040902 go_gc_duration_seconds_count 6 go_goroutines 50 log_messages_total{level=\"debug\"} 44 log_messages_total{level=\"error\"} 0 log_messages_total{level=\"info\"} 13 log_messages_total{level=\"warn\"} 0 loki_logql_querystats_duplicates_total 0 loki_logql_querystats_ingester_sent_lines_total 0 net_conntrack_dialer_conn_attempted_total{dialer_name=\"local_scrape\"} 1 net_conntrack_dialer_conn_attempted_total{dialer_name=\"remote_storage_write_client\"} 1 net_conntrack_dialer_conn_closed_total{dialer_name=\"local_scrape\"} 0 net_conntrack_dialer_conn_closed_total{dialer_name=\"remote_storage_write_client\"} 0 net_conntrack_dialer_conn_established_total{dialer_name=\"local_scrape\"} 1 net_conntrack_dialer_conn_established_total{dialer_name=\"remote_storage_write_client\"} 1 process_cpu_seconds_total 11.53 process_max_fds 1.048576e+06 process_open_fds 17 process_resident_memory_bytes 9.4773248e+07 process_start_time_seconds 1.64499076013e+09 process_virtual_memory_bytes 1.356931072e+09 process_virtual_memory_max_bytes 1.8446744073709552e+19 prometheus_interner_num_strings 275 prometheus_interner_string_interner_zero_reference_releases_total 0 prometheus_sd_consulagent_rpc_duration_seconds_sum{call=\"services\",endpoint=\"agent\"} 0 prometheus_sd_consulagent_rpc_duration_seconds_count{call=\"services\",endpoint=\"agent\"} 0 prometheus_sd_consulagent_rpc_failures_total 0 prometheus_sd_dns_lookup_failures_total 0 prometheus_sd_dns_lookups_total 0 prometheus_sd_file_read_errors_total 0 prometheus_sd_file_scan_duration_seconds{quantile=\"0.5\"} NaN ... æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è®¿é—® grafana-agent æ‰€æš´éœ²çš„ APIï¼Œè·å–åˆ° targets åˆ—è¡¨æ¥ç¡®è®¤æ˜¯å¦ç¬¦åˆé¢„æœŸï¼š\ncurl http://localhost:12345/agent/api/v1/targets |jq  { \"status\": \"success\", \"data\": [ { \"instance\": \"7f383657f506f53a739e2df61be58891\", \"target_group\": \"local_scrape\", \"endpoint\": \"http://127.0.0.1:12345/metrics\", \"state\": \"up\", \"labels\": { \"cluster\": \"mymac\", \"instance\": \"127.0.0.1:12345\", \"job\": \"local_scrape\" }, \"discovered_labels\": { \"__address__\": \"127.0.0.1:12345\", \"__metrics_path__\": \"/metrics\", \"__scheme__\": \"http\", \"__scrape_interval__\": \"15s\", \"__scrape_timeout__\": \"10s\", \"cluster\": \"mymac\", \"job\": \"local_scrape\" }, \"last_scrape\": \"2022-02-16T07:18:55.6221085Z\", \"scrape_duration_ms\": 6, \"scrape_error\": \"\" } ] } åœ¨æœ¬æœºå®‰è£…è¿è¡Œgrafana-agent å¦‚æœæ‚¨çš„ä¸»æœºä¸Šæ²¡æœ‰dockeræˆ–è€…æ‚¨å¸Œæœ›ç›´æ¥æŠŠgrafana-agentè¿è¡Œåœ¨å®¿ä¸»æœºä¸Šï¼Œå¯ä»¥ä¾ç…§ä»¥ä¸‹æ­¥éª¤ï¼š\n1. ä¸‹è½½é¢„å…ˆç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶åŒ… ä¸‹è½½åœ°å€ä¸º: https://github.com/grafana/agent/releases/download/${version}/agent-${platform}-${arch}.zip\n å…¶ä¸­ï¼Œversionå½“å‰ä¸ºv0.23.0 å…¶ä¸­ï¼Œå¯ä¸‹è½½çš„platformå’Œarchåˆ—è¡¨å¦‚ä¸‹ï¼š  linux/amd64 linux/arm64 linux/armv7 linux/armv6 darwin/amd64 darwin/arm64 windows/amd64 linux/mipsle freebsd/amd64    æ¯”å¦‚ï¼Œæˆ‘ä»¬ç°åœ¨çš„æ“ä½œç³»ç»Ÿä¸ºLinuxï¼Œæ¶æ„ä¸ºAmd64ï¼Œ é‚£ä¹ˆgrafana-agentçš„äºŒè¿›åˆ¶åŒ…ä¸‹è½½å‘½ä»¤å¦‚ä¸‹ï¼š\n# download the binary curl -SOL \"https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\" # extract the binary gunzip ./agent-linux-amd64.zip # make sure it is executable chmod a+x \"agent-linux-amd64\" 2. ç”Ÿæˆ grafana-agent çš„é…ç½®æ–‡ä»¶ cat \u003c\u003cEOF \u003e ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF 3. å¯åŠ¨ grafana-agent nohup ./agent-linux-amd64 \\  -config.file ./agent-cfg.yaml \\  -metrics.wal-directory ./data \\  \u0026\u003e grafana-agent.log \u0026 4. éªŒè¯ grafana-agent æ˜¯å¦æ­£å¸¸å·¥ä½œ  æ‚¨å¯ä»¥é€šè¿‡ç›´æ¥ curl http://localhost:12345/metrics æ¥éªŒè¯æ•°æ®çš„äº§ç”Ÿæ˜¯å¦ç¬¦åˆé¢„æœŸï¼› æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è®¿é—® grafana-agent æ‰€æš´éœ²çš„ API ï¼Œè·å–åˆ° targets åˆ—è¡¨æ¥ç¡®è®¤æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œæ“ä½œå‘½ä»¤ä¸º curl http://localhost:12345/agent/api/v1/targetsï¼›  è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸçš„å°† grafana-agent è¿è¡Œèµ·æ¥ï¼Œå¹¶ä¸”å¼€å§‹æ”¶é›† grafana-agent è‡ªèº«çš„ metrics æŒ‡æ ‡ã€‚ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬è®²è¿°å¦‚ä½•é€šè¿‡ grafana-agent çš„å†…åµŒçš„å„ç§ exporter æ¥é‡‡é›†ä¸»æœºã€è¿›ç¨‹ã€MySQLç­‰ç›‘æ§æŒ‡æ ‡ã€‚\n",
    "description": "",
    "tags": null,
    "title": "ä½¿ç”¨Grafana-agenté‡‡é›†ç›‘æ§æ•°æ®",
    "uri": "/grafana-agent/"
  },
  {
    "content": "grafana-agent å†…ç½®äº† cadvisor, å¯ä»¥æ”¯æŒé‡‡é›†å®¹å™¨çš„å„é¡¹æŒ‡æ ‡ã€‚ä¸è¿‡ cadvisor é’ˆå¯¹å®¿ä¸»æœºéœ€è¦è®¾ç½®ç›¸å…³çš„æƒé™ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ cAdvisor docs.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter ç”Ÿæˆgrafana-agent-cfg.yaml é…ç½®æ–‡ä»¶ï¼Œå…¶ä¸­å¼€å¯cadvisor integrationï¼Œé…ç½®æ–‡ä»¶å…·ä½“ä¸¾ä¾‹å¦‚ä¸‹ï¼š\ncat \u003c\u003cEOF \u003e /tmp/grafana-agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: cadvisor: enabled: true EOF åœ¨dockerä¸­å¯åŠ¨ grafana-agentï¼ŒåŒæ—¶æ˜ å°„ç›¸å…³ç›®å½• docker run \\  -v /tmp/agent:/etc/agent/data \\  -v /tmp/grafana-agent-cfg.yaml:/etc/agent/agent.yaml \\  -p 12345:12345 \\  -d \\  --privileged \\  grafana/agent:latest \\  --config.file=/etc/agent/agent.yaml \\  --metrics.wal-directory=/etc/agent/data æ‰§è¡Œ curl http://localhost:12345/agent/api/v1/targets |jq,è¾“å‡ºç»“æœä¸­é¢„æœŸåº”è¯¥åŒ…å« integrations/cadvisor å­—æ®µï¼Œå¦‚ä¸‹ï¼š\n{ \"status\": \"success\", \"data\": [ { \"instance\": \"7f383657f506f53a739e2df61be58891\", \"target_group\": \"integrations/cadvisor\", \"endpoint\": \"http://127.0.0.1:12345/integrations/cadvisor/metrics\", \"state\": \"up\", \"labels\": { \"agent_hostname\": \"509c1284c59c\", \"instance\": \"509c1284c59c:12345\", \"job\": \"integrations/cadvisor\" }, \"discovered_labels\": { \"__address__\": \"127.0.0.1:12345\", \"__metrics_path__\": \"/integrations/cadvisor/metrics\", \"__scheme__\": \"http\", \"__scrape_interval__\": \"15s\", \"__scrape_timeout__\": \"10s\", \"agent_hostname\": \"509c1284c59c\", \"job\": \"integrations/cadvisor\" }, \"last_scrape\": \"2022-02-17T14:54:50.652267586Z\", \"scrape_duration_ms\": 30, \"scrape_error\": \"\" } ] } æ‰§è¡Œ curl http://localhost:12345/integrations/cadvisor/metrics,é¢„æœŸè¾“å‡ºç»“æœä¸‹ï¼š\ncadvisor_version_info{cadvisorRevision=\"\",cadvisorVersion=\"\",dockerVersion=\"\",kernelVersion=\"5.10.76-linuxkit\",osVersion=\"Debian GNU/Linux 10 (buster)\"} 1 container_blkio_device_usage_total{device=\"/dev/vda\",id=\"/\",major=\"254\",minor=\"0\",operation=\"Read\"} 4.6509056e+07 1645109878135 container_blkio_device_usage_total{device=\"/dev/vda\",id=\"/\",major=\"254\",minor=\"0\",operation=\"Write\"} 3.13243648e+09 1645109878135 container_cpu_load_average_10s{id=\"/\"} 0 1645109878135 container_cpu_system_seconds_total{id=\"/\"} 57.789 1645109878135 container_cpu_usage_seconds_total{cpu=\"total\",id=\"/\"} 91.57 1645109878135 container_cpu_user_seconds_total{id=\"/\"} 33.781 1645109878135 container_fs_inodes_free{device=\"/dev\",id=\"/\"} 254415 1645109878135 container_fs_inodes_free{device=\"/dev/shm\",id=\"/\"} 254551 1645109878135 container_fs_inodes_free{device=\"/dev/vda1\",id=\"/\"} 3.890602e+06 1645109878135 container_fs_inodes_free{device=\"/rootfs/dev/shm\",id=\"/\"} 254551 1645109878135 ... é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # CPU # å®¹å™¨è¿è¡Œç»è¿‡çš„cfså‘¨æœŸæ€»æ•° container_cpu_cfs_periods_total: Number of elapsed enforcement period intervals # å®¹å™¨è¿è¡Œæ—¶å‘ç”ŸèŠ‚æµçš„cfså‘¨æœŸæ€»æ•° container_cpu_cfs_throttled_periods_total: Number of throttled period intervals # å®¹å™¨å‘ç”ŸcpuèŠ‚æµçš„æ€»æ—¶é—´ container_cpu_cfs_throttled_seconds_total: Total time duration the container has been throttled container_cpu_load_average_10s: Value of container cpu load average over the last 10 seconds container_cpu_system_seconds_total: Cumulative system cpu time consumed container_cpu_usage_seconds_total: Cumulative cpu time consumed container_cpu_user_seconds_total: Cumulative user cpu time consumed # å®¹å™¨æè¿°ä¸­çš„CPUå‘¨æœŸé…ç½® container_spec_cpu_period: CPU period of the container # å®¹å™¨æè¿°ä¸­çš„CPU quotaé…ç½® container_spec_cpu_quota: CPU quota of the container # å®¹å™¨æè¿°ä¸­çš„CPUæƒé‡é…ç½® container_spec_cpu_shares: CPU share of the container # MEM container_memory_cache: Total page cache memory container_memory_failcnt: Number of memory usage hits limits container_memory_failures_total: Cumulative count of memory allocation failures container_memory_mapped_file: Size of memory mapped files container_memory_max_usage_bytes: Maximum memory usage recorded container_memory_rss: Size of RSS container_memory_swap: Container swap usage container_memory_usage_bytes: Current memory usage, including all memory regardless of when it was accessed container_oom_events_total: Count of out of memory events observed for the container container_spec_memory_limit_bytes: Memory limit for the container container_spec_memory_reservation_limit_bytes: Memory reservation limit for the container container_spec_memory_swap_limit_bytes: Memory swap limit for the container # Disk # è®¾å¤‡IOä½¿ç”¨æ€»é‡ container_blkio_device_usage_total: Blkio device bytes usage container_fs_inodes_free: Number of available Inodes container_fs_inodes_total: Total number of Inodes container_fs_io_current: Number of I/Os currently in progress # å®¹å™¨IOæ€»è€—æ—¶ container_fs_io_time_seconds_total: Cumulative count of seconds spent doing I/Os container_fs_io_time_weighted_seconds_total: Cumulative weighted I/O time container_fs_limit_bytes: Number of bytes that can be consumed by the container on this filesystem container_fs_reads_bytes_total: Cumulative count of bytes read container_fs_read_seconds_total: Cumulative count of seconds spent reading container_fs_reads_merged_total: Cumulative count of reads merged container_fs_reads_total: Cumulative count of reads completed container_fs_sector_reads_total: Cumulative count of sector reads completed container_fs_sector_writes_total: Cumulative count of sector writes completed container_fs_usage_bytes: Number of bytes that are consumed by the container on this filesystem container_fs_writes_bytes_total: Cumulative count of bytes written container_fs_write_seconds_total: Cumulative count of seconds spent writing container_fs_writes_merged_total: Cumulative count of writes merged container_fs_writes_total: Cumulative count of writes completed # Network container_network_receive_bytes_total: Cumulative count of bytes received container_network_receive_errors_total: Cumulative count of errors encountered while receiving container_network_receive_packets_dropped_total: Cumulative count of packets dropped while receiving container_network_receive_packets_total: Cumulative count of packets received container_network_transmit_bytes_total: Cumulative count of bytes transmitted container_network_transmit_errors_total: Cumulative count of errors encountered while transmitting container_network_transmit_packets_dropped_total: Cumulative count of packets dropped while transmitting container_network_transmit_packets_total: Cumulative count of packets transmitted # System container_tasks_state: Number of tasks in given state (sleeping, running, stopped, uninterruptible, or ioawaiting) # Others container_last_seen: Last time a container was seen by the exporter container_start_time_seconds: Start time of the container since unix epoch å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the cadvisor integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. [instance: \u003cstring\u003e | default = \u003cintegrations_config.instance\u003e] # Automatically collect metrics from this integration. If disabled, # the cadvisor integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/cadvisor/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # # cAdvisor-specific configuration options # # Convert container labels and environment variables into labels on prometheus metrics for each container. If false, then only metrics exported are container name, first alias, and image name. [store_container_labels: \u003cboolean\u003e | default = true] # List of container labels to be converted to labels on prometheus metrics for each container. store_container_labels must be set to false for this to take effect. allowlisted_container_labels: [ - \u003cstring\u003e ] # List of environment variable keys matched with specified prefix that needs to be collected for containers, only support containerd and docker runtime for now. env_metadata_allowlist: [ - \u003cstring\u003e ] # List of cgroup path prefix that needs to be collected even when docker_only is specified. raw_cgroup_prefix_allowlist: [ - \u003cstring\u003e ] # Path to a JSON file containing configuration of perf events to measure. Empty value disabled perf events measuring. [perf_events_config: \u003cboolean\u003e] # resctrl mon groups updating interval. Zero value disables updating mon groups. [resctrl_interval: \u003cint\u003e | default = 0] # List of `metrics` to be disabled. If set, overrides the default disabled metrics. disabled_metrics: [ - \u003cstring\u003e ] # List of `metrics` to be enabled. If set, overrides disabled_metrics enabled_metrics: [ - \u003cstring\u003e ] # Length of time to keep data stored in memory [storage_duration: \u003cduration\u003e | default = \"2m\"] # Containerd endpoint [containerd: \u003cstring\u003e | default = \"/run/containerd/containerd.sock\"] # Containerd namespace [containerd_namespace: \u003cstring\u003e | default = \"k8s.io\"] # Docker endpoint [docker: \u003cstring\u003e | default = \"unix:///var/run/docker.sock\"] # Use TLS to connect to docker [docker_tls: \u003cboolean\u003e | default = false] # Path to client certificate for TLS connection to docker [docker_tls_cert: \u003cstring\u003e | default = \"cert.pem\"] # Path to private key for TLS connection to docker [docker_tls_key: \u003cstring\u003e | default = \"key.pem\"] # Path to a trusted CA for TLS connection to docker [docker_tls_ca: \u003cstring\u003e | default = \"ca.pem\"] # Only report docker containers in addition to root stats [docker_only: \u003cboolean\u003e | default = false] ",
    "description": "",
    "tags": null,
    "title": "cAdvisor Exporter",
    "uri": "/grafana-agent/integrations/cadvisor-config/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "The consul_exporter_config block configures the consul_exporter integration, which is an embedded version of consul_exporter. This allows for the collection of consul metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the consul_exporter integration, allowing the Agent to automatically # collect system metrics from the configured consul server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of the server URL. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/consul_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # Prefix from which to expose key/value pairs. [kv_prefix: \u003cstring\u003e | default = \"\"] # Regex that determines which keys to expose. [kv_filter: \u003cstring\u003e | default = \".*\"] # Generate a health summary for each service instance. Needs n+1 queries to # collect all information. [generate_health_summary: \u003cbool\u003e | default = true] # HTTP API address of a Consul server or agent. Prefix with https:// to # connect using HTTPS. [server: \u003cstring\u003e | default = \"http://localhost:8500\"] # Disable TLS host verification. [insecure_skip_verify: \u003cbool\u003e | default = false] # File path to a PEM-encoded certificate authority used to validate the # authenticity of a server certificate. [ca_file: \u003cstring\u003e | default = \"\"] # File path to a PEM-encoded certificate used with the private key to verify # the exporter's authenticity. [cert_file: \u003cstring\u003e | default = \"\"] # File path to a PEM-encoded private key used with the certificate to verify # the exporter's authenticity. [key_file: \u003cstring\u003e | default = \"\"] # When provided, this overrides the hostname for the TLS certificate. It can # be used to ensure that the certificate name matches the hostname we declare. [server_name: \u003cstring\u003e | default = \"\"] # Timeout on HTTP requests to the Consul API. [timeout: \u003cduration\u003e | default = \"500ms\"] # Limit the maximum number of concurrent requests to consul. 0 means no limit. [concurrent_request_limit: \u003cint\u003e | default = 0] # Allows any Consul server (non-leader) to service a read. [allow_stale: \u003cbool\u003e | default = true] # Forces the read to be fully consistent. [require_consistent: \u003cbool\u003e | default = false] é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ consul_memberlist_tcp : irate(consul_memberlist_tcp{host=\"$consul\"}[1m]) consul_memberlist_udp : irate(consul_memberlist_udp{host=\"$consul\"}[1m]) consul_raft_apply[30s]) : delta(consul_raft_apply[30s]) consul_raft_commitTime : consul_raft_commitTime consul_raft_leader_dispatchLog : consul_raft_leader_dispatchLog consul_raft_leader_lastcontact : consul_raft_leader_lastcontact consul_raft_leader_lastcontact_count : consul_raft_leader_lastcontact_count consul_raft_replication_appendEntries_rpc : consul_raft_replication_appendEntries_rpc consul_raft_replication_heartbeat : consul_raft_replication_heartbeat consul_rpc_query : delta(consul_rpc_query{host=\"$consul\"}[30s]) consul_serf_coordinate_adjustment_ms : consul_serf_coordinate_adjustment_ms{host=\"$consul\"} labels) : COUNT (changes(consul_memberlist_gossep_sum[1m]) \u003e 0) BY (labels) node_cpu : sum(irate(node_cpu{mode=\"idle\", host=\"$consul\"}[1m])) * 100 / count_scalar(node_cpu{mode=\"user\", host=\"$consul\"}) node_load1 : node_load1{host=\"$consul\"} node_load15 : node_load15{host=\"$consul\"} node_load5 : node_load5{host=\"$consul\"} ",
    "description": "",
    "tags": null,
    "title": "Consul Exporter",
    "uri": "/grafana-agent/integrations/consul-exporter-config/"
  },
  {
    "content": "The dnsmasq_exporter_config block configures the dnsmasq_exporter integration, which is an embedded version of dnsmasq_exporter. This allows for the collection of metrics from dnsmasq servers.\nNote that currently, an Agent can only collect metrics from a single dnsmasq server. If you want to collect metrics from multiple servers, you can run multiple Agents and add labels using relabel_configs to differentiate between the servers:\ndnsmasq_exporter: enabled: true dnsmasq_address: dnsmasq-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: dnsmasq-a Full reference of options:\n# Enables the dnsmasq_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the dnsmasq_address # value. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # Address of the dnsmasq server in host:port form. [dnsmasq_address: \u003cstring\u003e | default = \"localhost:53\"] # Path to the dnsmasq leases file. If this file doesn't exist, scraping # dnsmasq # will fail with an warning log message. [leases_path: \u003cstring\u003e | default = \"/var/lib/misc/dnsmasq.leases\"] ",
    "description": "",
    "tags": null,
    "title": "dnsmasq Exporter",
    "uri": "/grafana-agent/integrations/dnsmasq-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†elasticsearch_exporterï¼Œå¯ä»¥é‡‡é›†Elasticsearchçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentä¸æ”¯æŒé…ç½®å¤šä¸ªelasticsearchçš„åœ°å€ï¼Œåªèƒ½é…ç½®ä¸€ä¸ªElasticSearchåœ°å€å¯¹å…¶è¿›è¡Œmetricsçš„é‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®elasticsearchå®ä¾‹çš„æœ€å°åŒ–æˆæƒï¼Œé¿å…è¿‡åº¦æˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨elasticsearch_exporter elasticsearch_exporter: enabled: true address: \"http://localhost:9200\" é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # Estimated size in bytes of breaker # æ–­è·¯å™¨é¢„ä¼°å†…å­˜å¤§å° # Gauge elasticsearch_breakers_estimated_size_bytes # Limit size in bytes for breaker # æ–­è·¯å™¨è®¾ç½®å†…å­˜é™åˆ¶ # Gauge elasticsearch_breakers_limit_size_bytes # tripped for breaker # æ–­è·¯å™¨ç´¯è®¡é˜»æ–­æ­¤æ—¶ # Counter  elasticsearch_breakers_tripped # The number of primary shards in your cluster. This is an aggregate total across all indices # é›†ç¾¤ä¸»åˆ†ç‰‡æ•°é‡ # Gauge elasticsearch_cluster_health_active_primary_shards # Aggregate total of all shards across all indices, which includes replica shards. # é›†ç¾¤åˆ†ç‰‡æ€»æ•° # Gauge elasticsearch_cluster_health_active_shards # Shards delayed to reduce reallocation overhead # æš‚ç¼“é‡åˆ†é…çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_delayed_unassigned_shards # Count of shards that are being freshly created # åˆ›å»ºä¸­çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_initializing_shards # Number of data nodes in the cluster # æ•°æ®èŠ‚ç‚¹æ•° # Gauge elasticsearch_cluster_health_number_of_data_nodes # Number of nodes in the cluster # èŠ‚ç‚¹æ€»æ•° # Gauge elasticsearch_cluster_health_number_of_nodes # Cluster level changes which have not yet been executed # ç­‰å¾…æ‰§è¡Œçš„é›†ç¾¤å˜æ›´æ€»æ•° # Gauge elasticsearch_cluster_health_number_of_pending_tasks # The number of shards that are currently moving from one node to another node # è¿ç§»ä¸­çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_relocating_shards # Whether all primary and replica shards are allocated # é›†ç¾¤å¥åº·åº¦ # Gauge elasticsearch_cluster_health_status # The number of shards that exist in the cluster state, but cannot be found in the cluster itself # é›†ç¾¤æœªåˆ†é…çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_unassigned_shards # Available space on block device in bytes # å¯ç”¨ç£ç›˜å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_filesystem_data_available_bytes # Size of block device in bytes # ç£ç›˜å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_filesystem_data_size_bytes # Count of documents on this node # èŠ‚ç‚¹æ–‡æ¡£æ€»æ•° # Gauge elasticsearch_indices_docs # Count of deleted documents on this node # èŠ‚ç‚¹åˆ é™¤æ–‡æ¡£æ•° # Gauge elasticsearch_indices_docs_deleted # Count of documents with only primary shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹ä¸»åˆ†ç‰‡æ–‡æ¡£æ€»æ•° # Gauge elasticsearch_indices_docs_primary # Evictions from field data # field data cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_fielddata_evictions # Field data cache memory usage in bytes # field data cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_fielddata_memory_size_bytes # Evictions from filter cache # filter cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_filter_cache_evictions # Filter cache memory usage in bytes # filter cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_flush_time_seconds # Total flushes # flushæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_flush_total # Total time get exists in seconds # getæˆåŠŸæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_exists_time_seconds # Total get exists operations # getæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_exists_total # Total time of get missing in seconds # getå¤±è´¥æ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_get_missing_time_seconds # Total get missing # getå¤±è´¥æ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_missing_total # Total get time in seconds # getæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_get_time_seconds # Total get # getæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_tota # Total time indexing delete in seconds # ç´¢å¼•åˆ é™¤ç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_indexing_delete_time_seconds_total # Total indexing deletes # ç´¢å¼•åˆ é™¤æ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_indexing_delete_total # Cumulative index time in seconds # indexæ“ä½œç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_indexing_index_time_seconds_total # Total index calls # indexæ“ä½œæ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_indexing_index_total # Cumulative docs merged # mergeæ–‡æ¡£æ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_merges_docs_total # Total merges # mergeæ“ä½œæ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_merges_total # Total merge size in bytes # mergeæ“ä½œæ•°æ®å¤§å°ç´¯è®¡ï¼ˆbyteï¼‰ # Counter elasticsearch_indices_merges_total_size_bytes_total # Total time spent merging in seconds # mergeæ“ä½œç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_merges_total_time_seconds_total # Evictions from query cache # query cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_query_cache_evictions # Query cache memory usage in bytes # query cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_query_cache_memory_size_bytes # Total time spent refreshing in seconds # refreshæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_refresh_time_seconds_total # Total refreshes # refreshæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_refresh_total # Total search fetch time in seconds # fetchæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_search_fetch_time_seconds # Total number of fetches # fetchæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_search_fetch_total # Total search query time in seconds # queryæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_search_query_time_seconds # Total number of queries # queryæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_search_query_total # Segments with only primary shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹ä¸»åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_count_primary # Segments with all shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹æ‰€æœ‰åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_count_total # Doc values with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡doc valueå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_primary # Doc values with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡doc valueå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_total # Size of fields with only primary shards on all nodes in bytes # åˆ†ç‰‡fieldå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fields_memory_bytes_primary # Size of fields with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡fieldå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fields_memory_bytes_total # Size of fixed bit with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡fixed bit setå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_primary # Size of fixed bit with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡fixed bit setå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_total # Index writer with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡ç´¢å¼•å†™å…¥æ•°æ®é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_primary # Index writer with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡ç´¢å¼•å†™å…¥æ•°æ®é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_total # Size of segments with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡segmentæ•° # Gauge elasticsearch_indices_segment_memory_bytes_primary # Size of segments with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_memory_bytes_total # Size of norms with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡normalization factorå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_norms_memory_bytes_primary # Size of norms with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡normalization factorå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_norms_memory_bytes_total # Size of points with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡pointå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_points_memory_bytes_primary # Size of points with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡pointå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_points_memory_bytes_total # Size of terms with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡termå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_terms_memory_primary # Number of terms with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡termå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_terms_memory_total # Size of version map with only primary shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡version mapå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_version_map_memory_bytes_primary # Size of version map with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡version mapå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_version_map_memory_bytes_total # Count of index segments # segmentä¸ªæ•° # Gauge elasticsearch_indices_segments_count # Current memory size of segments in bytes # segmentå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segments_memory_bytes # Current size of stored index data in bytes with only primary shards on all nodes # ä¸»åˆ†ç‰‡ç´¢å¼•å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_store_size_bytes_primary # Current size of stored index data in bytes with all shards on all nodes # æ‰€æœ‰åˆ†ç‰‡ç´¢å¼•å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_store_size_bytes_total # Throttle time for index store in seconds # ç´¢å¼•å­˜å‚¨é™åˆ¶è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_store_throttle_time_seconds_total # Total translog operations # tranlogæ“ä½œæ•°ç´¯è®¡ # Counter elasticsearch_indices_translog_operations # Total translog size in bytes # tranlogå¤§å°ç´¯è®¡ï¼ˆbyteï¼‰ # Counter elasticsearch_indices_translog_size_in_bytes # Count of JVM GC runs # GCè¿è¡Œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_jvm_gc_collection_seconds_count # GC run time in seconds # GCè¿è¡Œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Cæ¬§BTè€Œ elasticsearch_jvm_gc_collection_seconds_sum # JVM memory currently committed by area # JVMç”³è¯·å†…å­˜å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_committed_bytes # JVM memory max # JVMå†…å­˜é™åˆ¶å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_max_bytes # JVM memory peak used by pool # JVMå†…å­˜å³°å€¼å¤§å°ï¼ˆbyteï¼‰ # Counter elasticsearch_jvm_memory_pool_peak_used_bytes # JVM memory currently used by area # JVMå†…å­˜å ç”¨å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_used_bytes # Shortterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ1åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load1 # Midterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ5åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load15 # Longterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ15åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load5 # Percent CPU used by process # è¿›ç¨‹CPUå ç”¨ç‡ # Gauge elasticsearch_process_cpu_percent # Open file descriptors # è¿›ç¨‹æ‰“å¼€æ–‡ä»¶æ•° # Gauge elasticsearch_process_open_files_count # Thread Pool threads active # æ´»è·ƒçº¿ç¨‹æ€»æ•° # Gauge elasticsearch_thread_pool_active_count # Thread Pool operations completed # çº¿ç¨‹æ± completeæ¬¡æ•° # Counter elasticsearch_thread_pool_completed_count # Thread Pool operations rejected # çº¿ç¨‹æ± rejectæ¬¡æ•° # Counter elasticsearch_thread_pool_rejected_count # Total number of bytes received # ç½‘ç»œæ”¶æµé‡ï¼ˆbyteï¼‰ # Counter elasticsearch_transport_rx_size_bytes_total # Total number of bytes received # ç½‘ç»œå‘æµé‡ï¼ˆbyteï¼‰ # Counter elasticsearch_transport_tx_size_bytes_total å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the elasticsearch_exporter integration, allowing the Agent to automatically # collect system metrics from the configured ElasticSearch server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of address. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the elasticsearch_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/elasticsearch_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # HTTP API address of an Elasticsearch node. [ address: \u003cstring\u003e | default = \"http://localhost:9200\" ] # Timeout for trying to get stats from Elasticsearch. [ timeout: \u003cduration\u003e | default = \"5s\" ] # Export stats for all nodes in the cluster. If used, this flag will override the flag `node`. [ all: \u003cboolean\u003e ] # Node's name of which metrics should be exposed. [ node: \u003cboolean\u003e ] # Export stats for indices in the cluster. [ indices: \u003cboolean\u003e ] # Export stats for settings of all indices of the cluster. [ indices_settings: \u003cboolean\u003e ] # Export stats for cluster settings. [ cluster_settings: \u003cboolean\u003e ] # Export stats for shards in the cluster (implies indices). [ shards: \u003cboolean\u003e ] # Export stats for the cluster snapshots. [ snapshots: \u003cboolean\u003e ] # Cluster info update interval for the cluster label. [ clusterinfo_interval: \u003cduration\u003e | default = \"5m\" ] # Path to PEM file that contains trusted Certificate Authorities for the Elasticsearch connection. [ ca: \u003cstring\u003e ] # Path to PEM file that contains the private key for client auth when connecting to Elasticsearch. [ client_private_key: \u003cstring\u003e ] # Path to PEM file that contains the corresponding cert for the private key to connect to Elasticsearch. [ client_cert: \u003cstring\u003e ] # Skip SSL verification when connecting to Elasticsearch. [ ssl_skip_verify: \u003cboolean\u003e ] ",
    "description": "",
    "tags": null,
    "title": "Elasticsearch Exporter",
    "uri": "/grafana-agent/integrations/elasticsearch-exporter-config/"
  },
  {
    "content": "The github_exporter_config block configures the github_exporter integration, which is an embedded version of github_exporter. This allows for the collection of metrics from the github api.\nWe strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory security privileges necessary for monitoring your repositories, as per the official documentation. We also recommend that you use api_token_file parameter, to avoid setting the authentication token directly on the Agent config file.\nFull reference of options:\n# Enables the github_exporter integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of api_url. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the github_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/github_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # # Exporter-specific configuration options # # The full URI of the github API. [api_url: \u003cstring\u003e | default = \"https://api.github.com\"] # A list of github repositories for which to collect metrics. repositories: [ - \u003cstring\u003e ] # A list of github organizations for which to collect metrics. organizations: [ - \u003cstring\u003e ] # A list of github users for which to collect metrics. users: [ - \u003cstring\u003e ] # A github authentication token that allows the API to be queried more often. # Optional, but recommended. [api_token: \u003cstring\u003e] # A path to a file containing a github authentication token that allows the # API to be queried more often. If supplied, this supercedes `api_token` # Optional, but recommended. [api_token_file: \u003cstring\u003e] ",
    "description": "",
    "tags": null,
    "title": "Github Exporter",
    "uri": "/grafana-agent/integrations/github-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†kafka_exporterï¼Œæ¥é‡‡é›†kafkaçš„metricsæŒ‡æ ‡ã€‚\næˆ‘ä»¬å¼ºçƒˆæ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®kafkaå®ä¾‹çš„æœ€å°åŒ–æˆæƒï¼Œé¿å…è¿‡åº¦æˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒdocumentationã€‚\né…ç½®å¹¶å¯ç”¨kafka_exporter kafka_exporter: enabled: true # Address array (host:port) of Kafka server kafka_uris: ['xxx','yyy'] é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ kafka_brokers: count of kafka_brokers (gauge) kafka_topic_partitions: Number of partitions for this Topic (gauge) kafka_topic_partition_current_offset: Current Offset of a Broker at Topic/Partition (gauge) kafka_consumergroup_current_offset: Current Offset of a ConsumerGroup at Topic/Partition (gauge) kafka_consumer_lag_millis: Current approximation of consumer lag for a ConsumerGroup at Topic/Partition (gauge) kafka_topic_partition_under_replicated_partition: 1 if Topic/Partition is under Replicated å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the kafka_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the first kafka_uri value. If there is more than one string # in kafka_uri, the integration will fail to load and an instance value # must be manually provided. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # Address array (host:port) of Kafka server [kafka_uris: \u003c[]string\u003e] # Connect using SASL/PLAIN [use_sasl: \u003cbool\u003e] # Only set this to false if using a non-Kafka SASL proxy [use_sasl_handshake: \u003cbool\u003e | default = true] # SASL user name [sasl_username: \u003cstring\u003e] # SASL user password [sasl_password: \u003cstring\u003e] # The SASL SCRAM SHA algorithm sha256 or sha512 as mechanism [sasl_mechanism: \u003cstring\u003e] # Connect using TLS [use_tls: \u003cbool\u003e] # The optional certificate authority file for TLS client authentication [ca_file: \u003cstring\u003e] # The optional certificate file for TLS client authentication [cert_file: \u003cstring\u003e] # The optional key file for TLS client authentication [key_file: \u003cstring\u003e] # If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure [insecure_skip_verify: \u003cbool\u003e] # Kafka broker version [kafka_version: \u003cstring\u003e | default = \"2.0.0\"] # if you need to use a group from zookeeper [use_zookeeper_lag: \u003cbool\u003e] # Address array (hosts) of zookeeper server. [zookeeper_uris: \u003c[]string\u003e] # Kafka cluster name [kafka_cluster_name: \u003cstring\u003e] # Metadata refresh interval [metadata_refresh_interval: \u003cduration\u003e | default = \"1m\"] # If true, all scrapes will trigger kafka operations otherwise, they will share results. WARN: This should be disabled on large clusters [allow_concurrency: \u003cbool\u003e | default = true] # Maximum number of offsets to store in the interpolation table for a partition [max_offsets: \u003cint\u003e | default = 1000] # How frequently should the interpolation table be pruned, in seconds [prune_interval_seconds: \u003cint\u003e | default = 30] # Regex filter for topics to be monitored [topics_filter_regex: \u003cstring\u003e | default = \".*\"] # Regex filter for consumer groups to be monitored [groups_filter_regex: \u003cstring\u003e | default = \".*\"] ",
    "description": "",
    "tags": null,
    "title": "Kafka Exporter",
    "uri": "/grafana-agent/integrations/kafka-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†memcached_exporterï¼Œæ¥é‡‡é›†memcachedçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nå½“å‰grafana-agentåªæ”¯æŒé…ç½®ä¸€ä¸ªmemcachedçš„åœ°å€æ¥é‡‡é›†å…¶metricsæ•°æ®ã€‚å¦‚æœæ‚¨éœ€è¦é‡‡é›†å¤šä¸ªmemcachedçš„metricsæŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®ä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒmemcached serverçš„metricsã€‚\né…ç½®å¹¶å¯ç”¨memcached_exporter memcached_exporter: enabled: true memcached_address: memcached-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: memcached-a é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ memcached_commands_total : sum (memcached_commands_total{instance=~\"$node\", command=\"set\"}) / sum (memcached_commands_total{instance=~\"$node\", command=\"get\"}) memcached_commands_total : sum (memcached_commands_total{instance=~\"$node\", status=\"miss\"}) / sum (memcached_commands_total{instance=~\"$node\"}) memcached_commands_total : sum (memcached_commands_total{instance=~\"$node\"}) by (command) memcached_current_bytes : sum(memcached_current_bytes{instance=~\"$node\"}) / sum(memcached_limit_bytes{instance=~\"$node\"}) memcached_current_connections : sum (memcached_current_connections{instance=~\"$node\"}) by (instance) memcached_current_items : sum (memcached_current_items{instance=~\"$node\"}) memcached_items_evicted_total : sum(memcached_items_evicted_total{instance=~\"$node\"}) memcached_items_reclaimed_total : sum(memcached_items_reclaimed_total{instance=~\"$node\"}) memcached_read_bytes_total : sum(irate(memcached_read_bytes_total{instance=~\"$node\"}[5m])) memcached_written_bytes_total : irate(memcached_written_bytes_total{instance=~\"$node\"}[10m]) å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the memcached_exporter integration, allowing the Agent to automatically # collect system metrics from the configured memcached server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from # memcached_address. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the memcached_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/memcached_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # Address of the memcached server in host:port form. [memcached_address: \u003cstring\u003e | default = \"localhost:53\"] # Timeout for connecting to memcached. [timeout: \u003cduration\u003e | default = \"1s\"] ",
    "description": "",
    "tags": null,
    "title": "Memcached Exporter",
    "uri": "/grafana-agent/integrations/memcached-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†mongodb_exporterï¼Œå¯ä»¥é‡‡é›†mongodbçš„metricsã€‚\nè¯¥mongodb_exporterï¼Œä¸æ”¯æŒåŒæ—¶é…ç½®å¤šä¸ªmongodb nodeï¼Œç›®å‰åªæ”¯æŒé…ç½®ä¸€ä¸ªmongodb nodeï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚æ­¤å¤–æ‚¨éœ€è¦é€šè¿‡relabel_configså¯¹labelåšè‡ªå®šä¹‰å¤„ç†ï¼Œä¸€ä¸ªæ˜¯service_nameï¼Œç”¨æ¥æ ‡è¯†mongodb nodeï¼ˆä¾‹å¦‚ReplicaSet1-Node1ï¼‰ï¼›å¦ä¸€ä¸ªæ˜¯mongodb_clusterï¼Œæ ‡è¯†è¯¥mongodb clusterï¼ˆæ¯”å¦‚prod-clusterï¼‰\nä¸€ä¸ªrelabel_configsçš„ä¾‹å­ï¼š\nrelabel_configs: - source_labels: [__address__] target_label: service_name replacement: 'replicaset1-node1' - source_labels: [__address__] target_label: mongodb_cluster replacement: 'prod-cluster' å¼ºçƒˆæ¨èæ‚¨ä¸ºgrafana-agentè®¾ç½®ä¸€ä¸ªå•ç‹¬çš„è´¦å·æ¥è®¿é—®æ‚¨çš„mongodbï¼Œä»¥é¿å…è¿‡åº¦æˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œå…·ä½“å¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨mongodb_exporter # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e integrations: mongodb_exporter: enabled: true é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # Whether MongoDB is up. # å®ä¾‹æ˜¯å¦å­˜æ´» # Gauge mongodb_up # The number of seconds that the current MongoDB process has been active # å®ä¾‹å¯åŠ¨ç´¯è®¡æ—¶é—´ï¼ˆç§’ï¼‰ # Counter mongodb_instance_uptime_seconds # The amount of memory, in mebibyte (MiB), currently used by the database process # å†…å­˜å ç”¨ï¼ˆMiBï¼‰ # Gauge # mongodb_memory # The total combined latency in microseconds # ç´¯è®¡æ“ä½œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰ mongodb_mongod_op_latencies_latency_total # The total number of operations performed since startup # ç´¯è®¡æ“ä½œæ¬¡æ•° # Counter mongodb_mongod_op_latencies_ops_total # The total number of operations received since the mongod instance last started  # ç´¯è®¡æ¥æ”¶çš„æ“ä½œè¯·æ±‚æ¬¡æ•°ï¼ˆå³ä½¿æ“ä½œä¸æˆåŠŸä¹Ÿä¼šå¢åŠ ï¼‰ # Counter mongodb_op_counters_total # The number of incoming connections from clients to the database server. This number includes the current shell session # è¿æ¥æ•° # Gauge # mongodb_connections # The number of open cursors # æ‰“å¼€æ¸¸æ ‡æ•°é‡ # Gauge mongodb_mongod_metrics_cursor_open # The total number of document access and modification patterns # ç´¯è®¡æ–‡æ¡£æ“ä½œæ¬¡æ•° # Counter mongodb_mongod_metrics_document_total # The total number of operations queued waiting for the lock # å½“å‰æ’é˜Ÿç­‰å¾…è·å–é”çš„æ“ä½œä¸ªæ•° # Gauge mongodb_mongod_global_lock_current_queue # The total number of (index or document) items scanned during queries and query-plan evaluation # æŸ¥è¯¢å’ŒæŸ¥è¯¢è®¡åˆ’è¯„ä¼°è¿‡ç¨‹æ‰«æçš„ï¼ˆç´¢å¼•æˆ–æ–‡æ¡£ï¼‰æ¡ç›®æ€»æ•° # Counter  mongodb_mongod_metrics_query_executor_total # The number of assertions raised since the MongoDB process started # ç´¯è®¡æ–­è¨€é”™è¯¯æ¬¡æ•° # Counter mongodb_asserts_total # The total number of getLastError operations with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation (i.e. a w value greater than 1.) # ç´¯è®¡getLastErroræ“ä½œæ•°é‡ # Counter mongodb_mongod_metrics_get_last_error_wtime_num_total # The number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError. This number increments for both default and non-default write concern specifications. # ç´¯è®¡getLastErrorè¶…æ—¶æ“ä½œæ•°é‡ # Counter mongodb_mongod_metrics_get_last_error_wtimeouts_total # Size in byte of the data currently in cache # å½“å‰ç¼“å­˜æ•°æ®å¤§å°ï¼ˆbyteï¼‰ # Gauge mongodb_mongod_wiredtiger_cache_bytes # Size in byte of the data read into or write from cache  # å†™å…¥æˆ–è¯»å–çš„ç¼“å­˜æ•°æ®å¤§å°ï¼ˆbyteï¼‰ # Counter mongodb_mongod_wiredtiger_cache_bytes_total # Number of pages currently held in the cache # å½“å‰ç¼“å­˜é¡µæ•°é‡ # Gauge mongodb_mongod_wiredtiger_cache_pages # The total number of pages (modified or unmodified) evicted # ç´¯è®¡ç¼“å­˜ç§»é™¤é¡µæ•°é‡ # Counter mongodb_mongod_wiredtiger_cache_evicted_total # The total number of page faults # ç´¯è®¡ç¼ºé¡µä¸­æ–­æ¬¡æ•° # Counter mongodb_extra_info_page_faults_total # The total number of bytes that the server has sent over network connections initiated by clients or other mongod or mongos instances. # ç´¯è®¡å‘é€ç½‘ç»œæµé‡ï¼ˆbyteï¼‰ # Counter mongodb_ss_network_bytesOut # The total number of bytes that the server has received over network connections initiated by clients or other mongod or mongos instances # ç´¯è®¡æ¥æ”¶ç½‘ç»œæµé‡ï¼ˆbyteï¼‰ # Counter mongodb_ss_network_bytesIn # The timestamp the node was elected as replica leader # å‰¯æœ¬é›†é€‰ä¸»æ—¶é—´ # Gauge mongodb_mongod_replset_member_election_date # The replication lag that this member has with the primary # å‰¯æœ¬é›†æˆå‘˜ä¸»ä»å»¶è¿Ÿï¼ˆç§’ï¼‰ # Gauge mongodb_mongod_replset_member_replication_lag å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the mongodb_exporter integration [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the mongodb_uri field. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the mongodb_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mongodb_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # metrics.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # metrics.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # MongoDB node connection URL, which must be in the [`Standard Connection String Format`](https://docs.mongodb.com/manual/reference/connection-string/#std-label-connections-standard-connection-string-format) [mongodb_uri: \u003cstring\u003e] ",
    "description": "",
    "tags": null,
    "title": "Mongodb Exporter",
    "uri": "/grafana-agent/integrations/mongodb-exporter-config/"
  },
  {
    "content": "grafana-agent å†…ç½®é›†æˆäº† mysqld_exporterï¼Œ æ¥æ”¶é›†MySQL Serverçš„metricsæŒ‡æ ‡ã€‚\nç›®å‰ä¸€ä¸ªgrafana-agentå®ä¾‹ï¼Œåªèƒ½é…ç½®å’Œé‡‡é›†ä¸€ä¸ªMySQL serverçš„metricsï¼Œå› æ­¤å¦‚æœæ‚¨æƒ³è¦é…ç½®é‡‡é›†å¤šä¸ªMySQL serverçš„æŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®ä¾‹ï¼Œå¹¶ä½¿ç”¨ relabel_configs æœºåˆ¶æ¥ç»™ä¸åŒçš„MySQL serverçš„metricsæ•°æ®åšåŒºåˆ†ã€‚\né…ç½®å¹¶å¯ç”¨mysqld_exporter ä¸‹é¢æ˜¯å¼€å¯äº†mysqld_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹:\nmysqld_exporter: enabled: true data_source_name: root@(server-a:3306)/ relabel_configs: - source_labels: [__address__] target_label: instance replacement: server-a ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæ¨èæ‚¨ä¸ºgrafana-agent mysqld_exporter é…ç½®ä¸€ä¸ªå•ç‹¬çš„æ•°æ®åº“è´¦å·ï¼Œå¹¶æˆäºˆåˆé€‚çš„æƒé™ï¼Œéœ€è¦çš„æƒé™é…ç½®è¯¦æƒ…å¯ä»¥å‚è€ƒ MySQL Expoter å®˜æ–¹æ–‡æ¡£.\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ mysql_global_status_uptime: The number of seconds that the server has been up.(Gauge) mysql_global_status_uptime_since_flush_status: The number of seconds since the most recent FLUSH STATUS statement.(Gauge) mysql_global_status_queries: The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count COM_PING or COM_STATISTICS commands.(Counter) mysql_global_status_threads_connected: The number of currently open connections.(Counter) mysql_global_status_connections: The number of connection attempts (successful or not) to the MySQL server.(Gauge) mysql_global_status_max_used_connections: The maximum number of connections that have been in use simultaneously since the server started.(Gauge) mysql_global_status_threads_running: The number of threads that are not sleeping.(Gauge) mysql_global_status_questions: The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries variable. This variable does not count COM_PING, COM_STATISTICS, COM_STMT_PREPARE, COM_STMT_CLOSE, or COM_STMT_RESET commands.(Counter) mysql_global_status_threads_cached: The number of threads in the thread cache.(Counter) mysql_global_status_threads_created: The number of threads created to handle connections. If Threads_created is big, you may want to increase the thread_cache_size value. The cache miss rate can be calculated as Threads_created/Connections.(Counter) mysql_global_status_created_tmp_tables: The number of internal temporary tables created by the server while executing statements.(Counter) mysql_global_status_created_tmp_disk_tables: The number of internal on-disk temporary tables created by the server while executing statements. You can compare the number of internal on-disk temporary tables created to the total number of internal temporary tables created by comparing Created_tmp_disk_tables and Created_tmp_tables values.(Counter) mysql_global_status_created_tmp_files: How many temporary files mysqld has created.(Counter) mysql_global_status_select_full_join: The number of joins that perform table scans because they do not use indexes. If this value is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_full_range_join: The number of joins that used a range search on a reference table.(Counter) mysql_global_status_select_range: The number of joins that used ranges on the first table. This is normally not a critical issue even if the value is quite large.(Counter) mysql_global_status_select_range_check: The number of joins without keys that check for key usage after each row. If this is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_scan: The number of joins that did a full scan of the first table.(Counter) mysql_global_status_sort_rows: The number of sorted rows.(Counter) mysql_global_status_sort_range: The number of sorts that were done using ranges.(Counter) mysql_global_status_sort_merge_passes: The number of merge passes that the sort algorithm has had to do. If this value is large, you should consider increasing the value of the sort_buffer_size system variable.(Counter) mysql_global_status_sort_scan: The number of sorts that were done by scanning the table.(Counter) mysql_global_status_slow_queries: The number of queries that have taken more than long_query_time seconds. This counter increments regardless of whether the slow query log is enabled.(Counter) mysql_global_status_aborted_connects: The number of failed attempts to connect to the MySQL server.(Counter) mysql_global_status_aborted_clients: The number of connections that were aborted because the client died without closing the connection properly.(Counter) mysql_global_status_table_locks_immediate: The number of times that a request for a table lock could be granted immediately. Locks Immediate rising and falling is normal activity.(Counter) mysql_global_status_table_locks_waited: The number of times that a request for a table lock could not be granted immediately and a wait was needed. If this is high and you have performance problems, you should first optimize your queries, and then either split your table or tables or use replication.(Counter) mysql_global_status_bytes_received: The number of bytes received from all clients.(Counter) mysql_global_status_bytes_sent: The number of bytes sent to all clients.(Counter) mysql_global_status_innodb_page_size: InnoDB page size (default 16KB). Many values are counted in pages; the page size enables them to be easily converted to bytes.(Gauge) mysql_global_status_buffer_pool_pages: The number of pages in the InnoDB buffer pool.(Gauge) mysql_global_status_commands_total: The number of times each xxx statement has been executed.(Counter) mysql_global_status_handlers_total: Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes. This is in fact the layer between the Storage Engine and MySQL.(Counter) mysql_global_status_opened_files: The number of files that have been opened with my_open() (a mysys library function). Parts of the server that open files without using this function do not increment the count.(Counter) mysql_global_status_open_tables: The number of tables that are open.(Gauge) mysql_global_status_opened_tables: The number of tables that have been opened. If Opened_tables is big, your table_open_cache value is probably too small.(Counter) mysql_global_status_table_open_cache_hits: The number of hits for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_misses: The number of misses for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_overflows: The number of overflows for the open tables cache.(Counter) mysql_global_status_innodb_num_open_files: The number of files InnoDB currently holds open.(Gauge) mysql_global_variables_thread_cache_size: How many threads the server should cache for reuse.(Gauge) mysql_global_variables_max_connections: The maximum permitted number of simultaneous client connections.(Gauge) mysql_global_variables_innodb_buffer_pool_size: The size in bytes of the buffer pool, the memory area where InnoDB caches table and index data. The default value is 134217728 bytes (128MB).(Gauge) mysql_global_variables_innodb_log_buffer_size: The size in bytes of the buffer that InnoDB uses to write to the log files on disk.(Gauge) mysql_global_variables_key_buffer_size: Index blocks for MyISAM tables are buffered and are shared by all threads.(Gauge) mysql_global_variables_query_cache_size: The amount of memory allocated for caching query results.(Gauge) mysql_global_variables_table_open_cache: The number of open tables for all threads.(Gauge) mysql_global_variables_open_files_limit: The number of file descriptors available to mysqld from the operating system.(Gauge) mysqld-exporter-configè¯¦ç»†é…ç½®é¡¹è¯´æ˜ # Enables the mysqld_exporter integration, allowing the Agent to collect # metrics from a MySQL server. [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is a truncated version of the # connection DSN, containing only the server and db name. (Credentials # are not included.) [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the mysqld_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mysqld_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Data Source Name specifies the MySQL server to connect to. This is REQUIRED # but may also be specified by the MYSQLD_EXPORTER_DATA_SOURCE_NAME # environment variable. If neither are set, the integration will fail to # start. # # The format of this is specified here: https://github.com/go-sql-driver/mysql#dsn-data-source-name # # A working example value for a server with no required password # authentication is: \"root@(localhost:3306)/\" data_source_name: \u003cstring\u003e # A list of collector names to enable on top of the default set. enable_collectors: [ - \u003cstring\u003e ] # A list of collector names to disable from the default set. disable_collectors: [ - \u003cstring\u003e ] # A list of collectors to run. Fully overrides the default set. set_collectors: [ - \u003cstring\u003e ] # Set a lock_wait_timeout on the connection to avoid long metadata locking. [lock_wait_timeout: \u003cint\u003e | default = 2] # Add a low_slow_filter to avoid slow query logging of scrapes. NOT supported # by Oracle MySQL. [log_slow_filter: \u003cbool\u003e | default = false] ## Collector-specific options # Minimum time a thread must be in each state to be counted. [info_schema_processlist_min_time: \u003cint\u003e | default = 0] # Enable collecting the number of processes by user. [info_schema_processlist_processes_by_user: \u003cbool\u003e | default = true] # Enable collecting the number of processes by host. [info_schema_processlist_processes_by_host: \u003cbool\u003e | default = true] # The list of databases to collect table stats for. * for all [info_schema_tables_databases: \u003cstring\u003e | default = \"*\"] # Limit the number of events statements digests by response time. [perf_schema_eventsstatements_limit: \u003cint\u003e | default = 250] # Limit how old the 'last_seen' events statements can be, in seconds. [perf_schema_eventsstatements_time_limit: \u003cint\u003e | default = 86400] # Maximum length of the normalized statement text. [perf_schema_eventsstatements_digtext_text_limit: \u003cint\u003e | default = 120] # Regex file_name filter for performance_schema.file_summary_by_instance [perf_schema_file_instances_filter: \u003cstring\u003e | default = \".*\"] # Remove path prefix in performance_schema.file_summary_by_instance [perf_schema_file_instances_remove_prefix: \u003cstring\u003e | default = \"/var/lib/mysql\"] # Database from where to collect heartbeat data. [heartbeat_database: \u003cstring\u003e | default = \"heartbeat\"] # Table from where to collect heartbeat data. [heartbeat_table: \u003cstring\u003e | default = \"heartbeat\"] # Use UTC for timestamps of the current server (`pt-heartbeat` is called with `--utc`) [heartbeat_utc: \u003cbool\u003e | default = false] # Enable collecting user privileges from mysql.user [mysql_user_privileges: \u003cbool\u003e | default = false] ",
    "description": "",
    "tags": null,
    "title": "MySQLd Exporter",
    "uri": "/grafana-agent/integrations/mysqld-exporter-config/"
  },
  {
    "content": "grafana-agent å†…ç½®äº† node_exporter, å¯ä»¥é€šè¿‡åœ¨é…ç½®æ–‡ä»¶ä¸­ integrations éƒ¨åˆ†å®šä¹‰ node_exporter_config æ¥å¼€å¯è¯¥åŠŸèƒ½ã€‚\né…ç½®å¹¶å¯ç”¨node_exporter ä¸‹é¢æ˜¯å¼€å¯äº†node_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼Œç”Ÿæˆçš„é…ç½®æ–‡ä»¶ä¿å­˜ä¸º ./grafana-agent-cfg.yaml:\ncat \u003c\u003cEOF \u003e ./grafana-agent-cfg.yaml # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e integrations: node_exporter: enabled: true EOF æ³¨æ„ï¼š remote_write å¯ä»¥é…ç½®åœ¨ global éƒ¨åˆ†ï¼Œä¹Ÿå¯ä»¥é’ˆå¯¹æ¯ä¸ª integration å•ç‹¬é…ç½®ä¸åŒçš„remote_write åœ°å€ã€‚\né‡å¯grafana-agentåï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªå‘½ä»¤ï¼ŒéªŒè¯ node_exporter å·¥ä½œæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚\ncurl http://localhost:12345/integrations/node_exporter/metrics ï¼Œé¢„æœŸè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\nnode_boot_time_seconds 1.643256088e+09 node_context_switches_total 1.5136425575e+10 node_cooling_device_cur_state{name=\"0\",type=\"Processor\"} 0 node_cooling_device_cur_state{name=\"1\",type=\"Processor\"} 0 node_cooling_device_cur_state{name=\"2\",type=\"Processor\"} 0 node_cooling_device_cur_state{name=\"3\",type=\"Processor\"} 0 node_cooling_device_max_state{name=\"0\",type=\"Processor\"} 0 node_cooling_device_max_state{name=\"1\",type=\"Processor\"} 0 node_cooling_device_max_state{name=\"2\",type=\"Processor\"} 0 node_cooling_device_max_state{name=\"3\",type=\"Processor\"} 0 node_cpu_seconds_total{cpu=\"0\",mode=\"idle\"} 1.66906519e+06 node_cpu_seconds_total{cpu=\"0\",mode=\"iowait\"} 5031.48 node_cpu_seconds_total{cpu=\"0\",mode=\"irq\"} 0 node_cpu_seconds_total{cpu=\"0\",mode=\"nice\"} 82.84 node_cpu_seconds_total{cpu=\"0\",mode=\"softirq\"} 2332.39 curl http://localhost:12345/agent/api/v1/targets | jqï¼Œé¢„æœŸè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\n{ \"status\": \"success\", \"data\": [ { \"instance\": \"b81030837ec7f1d162489cb4009325c9\", \"target_group\": \"integrations/node_exporter\", \"endpoint\": \"http://127.0.0.1:12345/integrations/node_exporter/metrics\", \"state\": \"up\", \"labels\": { \"agent_hostname\": \"tt-fc-dev01.nj\", \"instance\": \"tt-fc-dev01.nj:12345\", \"job\": \"integrations/node_exporter\" }, \"discovered_labels\": { \"__address__\": \"127.0.0.1:12345\", \"__metrics_path__\": \"/integrations/node_exporter/metrics\", \"__scheme__\": \"http\", \"__scrape_interval__\": \"15s\", \"__scrape_timeout__\": \"10s\", \"agent_hostname\": \"tt-fc-dev01.nj\", \"job\": \"integrations/node_exporter\" }, \"last_scrape\": \"2022-02-16T18:53:08.79288957+08:00\", \"scrape_duration_ms\": 20, \"scrape_error\": \"\" }, { \"instance\": \"b81030837ec7f1d162489cb4009325c9\", \"target_group\": \"local_scrape\", \"endpoint\": \"http://127.0.0.1:12345/metrics\", \"state\": \"up\", \"labels\": { \"cluster\": \"txnjdev01\", \"instance\": \"127.0.0.1:12345\", \"job\": \"local_scrape\" }, \"discovered_labels\": { \"__address__\": \"127.0.0.1:12345\", \"__metrics_path__\": \"/metrics\", \"__scheme__\": \"http\", \"__scrape_interval__\": \"15s\", \"__scrape_timeout__\": \"10s\", \"cluster\": \"txnjdev01\", \"job\": \"local_scrape\" }, \"last_scrape\": \"2022-02-16T18:53:22.336820442+08:00\", \"scrape_duration_ms\": 4, \"scrape_error\": \"\" } ] } å¯ä»¥çœ‹åˆ°ï¼Œä¸Šé¢çš„è¿”å›ç»“æœçš„ targets åˆ—è¡¨ä¸­ï¼Œå·²ç»æ–°å¢äº†ä¸€ä¸ªinstanceï¼Œå…¶ job ä¸º integrations/node_exporterï¼Œè¿™è¯´æ˜ node_exporter å·²ç»åœ¨æ­£å¸¸å·¥ä½œäº†ã€‚\næ³¨æ„ï¼šå¦‚æœ grafana-agent æ˜¯è¿è¡Œåœ¨å®¹å™¨ä¸­æ—¶ï¼Œé‚£ä¹ˆè¦åšä»¥ä¸‹ä¿®æ”¹è°ƒæ•´ï¼š\n ç¡®ä¿åœ¨è¿è¡Œå®¹å™¨æ—¶ï¼Œå°†å®¿ä¸»æœºçš„ç›¸å…³ç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œå³ -v \"/:/host/root\"ã€ -v \"/sys:/host/sys\"ã€-v \"/proc:/host/proc\".  docker run \\ --net=\"host\" \\ --pid=\"host\" \\ --cap-add=SYS_TIME \\ -d \\ -v \"/:/host/root:ro\" \\ -v \"/sys:/host/sys:ro\" \\ -v \"/proc:/host/proc:ro\" \\ -v /tmp/grafana-agent:/etc/agent/data \\ -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\ grafana/agent \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data å…¶ä¸­ï¼Œé…ç½®æ–‡ä»¶ /tmp/grafana-agent-config.yaml ä¸­ node_exporter éƒ¨åˆ†è¦æŒ‡å®š rootfs/sysfs/procfs åœ¨å®¹å™¨ä¸­çš„è·¯å¾„ï¼Œæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆè¯¥æµ‹è¯•é…ç½®æ–‡ä»¶ï¼ˆå½“ç„¶ï¼Œæ‚¨éœ€è¦æŠŠ remote_write æ›¿æ¢ä¸ºé€‚åˆæ‚¨çš„åœ°å€ï¼‰ã€‚  cat \u003c\u003cEOF \u003e /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e integrations: node_exporter: enabled: true rootfs_path: /host/root sysfs_path: /host/sys procfs_path: /host/proc EOF æ³¨æ„ï¼šå¦‚æœ grafana-agent æ˜¯è¿è¡Œåœ¨ K8s ç¯å¢ƒä¸­ï¼Œé‚£ä¹ˆè°ƒæ•´æ­¥éª¤å¦‚ä¸‹ï¼š\n æ¨èå°† grafana-agent çš„é…ç½®æ–‡ä»¶å­˜å‚¨åœ¨configmapä¸­, manifestæ–‡ä»¶å¦‚ä¸‹ï¼š  cat \u003c\u003cEOF | apiVersion: v1 kind: ConfigMap metadata: name: grafana-agent namespace: ${NAMESPACE} data: agent.yaml: |server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: agent: enabled: true node_exporter: enabled: true  EOF envsubst | kubectl apply -f - kubectl describe configmap grafana-agent ç”Ÿæˆgrafana-agentçš„pod manifestæ–‡ä»¶å¦‚ä¸‹ï¼Œå¹¶åˆ›å»ºç›¸åº”Podå®ä¾‹ï¼š  cat \u003c\u003c EOF | apiVersion: v1 kind: Pod metadata: name: grafana-agent namespace: ${NAMESPACE} spec: containers: - image: grafana/agent name: grafana-agent args: - --config.file=/fcetc/agent.yaml - --metrics.wal-directory=/etc/agent/data securityContext: capabilities: add: [\"SYS_TIME\"] privileged: true runAsUser: 0 volumeMounts: - name: rootfs mountPath: /host/root readOnly: true - name: sysfs mountPath: /host/sys readOnly: true - name: procfs mountPath: /host/proc readOnly: true - name: fccfg mountPath: /fcetc hostPID: true hostNetwork: true dnsPolicy: ClusterFirstWithHostNet volumes: - name: rootfs hostPath: path: / - name: sysfs hostPath: path: /sys - name: procfs hostPath: path: /proc - name: fccfg configMap: name: grafana-agent EOF envsubst |kubectl apply -f - kubectl logs grafana-agent #æŸ¥çœ‹ grafana-agent çš„æ—¥å¿— node_exporteré‡‡é›†çš„å…³é”®æŒ‡æ ‡è§£æ # SYSTEM # CPU context switch æ¬¡æ•° node_context_switches_total: context_switches # Interrupts æ¬¡æ•° node_intr_total: Interrupts # è¿è¡Œçš„è¿›ç¨‹æ•° node_procs_running: Processes in runnable state # ç†µæ± å¤§å° node_entropy_available_bits: Entropy available to random number generators node_time_seconds: System time in seconds since epoch (1970) node_boot_time_seconds: Node boot time, in unixtime # CPU node_cpu_seconds_total: Seconds the CPUs spent in each mode node_load1: cpu load 1m node_load5: cpu load 5m node_load15: cpu load 15m # MEM # å†…æ ¸æ€ # ç”¨æˆ·è¿½è¸ªå·²ä»äº¤æ¢åŒºè·å–ä½†å°šæœªä¿®æ”¹çš„é¡µé¢çš„å†…å­˜ node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # å†…æ ¸ç”¨äºç¼“å­˜æ•°æ®ç»“æ„ä¾›è‡ªå·±ä½¿ç”¨çš„å†…å­˜ node_memory_Slab_bytes: Memory used by the kernel to cache data structures for its own use # slabä¸­å¯å›æ”¶çš„éƒ¨åˆ† node_memory_SReclaimable_bytes: SReclaimable - Part of Slab, that might be reclaimed, such as caches # slabä¸­ä¸å¯å›æ”¶çš„éƒ¨åˆ† node_memory_SUnreclaim_bytes: Part of Slab, that cannot be reclaimed on memory pressure # Vmallocå†…å­˜åŒºçš„å¤§å° node_memory_VmallocTotal_bytes: Total size of vmalloc memory area # vmallocå·²åˆ†é…çš„å†…å­˜ï¼Œè™šæ‹Ÿåœ°å€ç©ºé—´ä¸Šçš„è¿ç»­çš„å†…å­˜ node_memory_VmallocUsed_bytes: Amount of vmalloc area which is used # vmallocåŒºå¯ç”¨çš„è¿ç»­æœ€å¤§å¿«çš„å¤§å°ï¼Œé€šè¿‡æ­¤æŒ‡æ ‡å¯ä»¥çŸ¥é“vmallocå¯åˆ†é…è¿ç»­å†…å­˜çš„æœ€å¤§å€¼ node_memory_VmallocChunk_bytes: Largest contigious block of vmalloc area which is free # å†…å­˜çš„ç¡¬ä»¶æ•…éšœåˆ é™¤æ‰çš„å†…å­˜é¡µçš„æ€»å¤§å° node_memory_HardwareCorrupted_bytes: Amount of RAM that the kernel identified as corrupted / not working # ç”¨äºåœ¨è™šæ‹Ÿå’Œç‰©ç†å†…å­˜åœ°å€ä¹‹é—´æ˜ å°„çš„å†…å­˜ node_memory_PageTables_bytes: Memory used to map between virtual and physical memory addresses (gauge) # å†…æ ¸æ ˆå†…å­˜ï¼Œå¸¸é©»å†…å­˜ï¼Œä¸å¯å›æ”¶ node_memory_KernelStack_bytes: Kernel memory stack. This is not reclaimable # ç”¨æ¥è®¿é—®é«˜ç«¯å†…å­˜ï¼Œå¤åˆ¶é«˜ç«¯å†…å­˜çš„ä¸´æ—¶bufferï¼Œç§°ä¸ºâ€œbounce bufferingâ€ï¼Œä¼šé™ä½I/O æ€§èƒ½ node_memory_Bounce_bytes: Memory used for block device bounce buffers #ç”¨æˆ·æ€ # å•ä¸ªå·¨é¡µå¤§å° node_memory_Hugepagesize_bytes: Huge Page size # ç³»ç»Ÿåˆ†é…çš„å¸¸é©»å·¨é¡µæ•° node_memory_HugePages_Total: Total size of the pool of huge pages # ç³»ç»Ÿç©ºé—²çš„å·¨é¡µæ•° node_memory_HugePages_Free: Huge pages in the pool that are not yet allocated # è¿›ç¨‹å·²ç”³è¯·ä½†æœªä½¿ç”¨çš„å·¨é¡µæ•° node_memory_HugePages_Rsvd: Huge pages for which a commitment to allocate from the pool has been made, but no allocation # è¶…è¿‡ç³»ç»Ÿè®¾å®šçš„å¸¸é©»HugePagesæ•°é‡çš„ä¸ªæ•° node_memory_HugePages_Surp: Huge pages in the pool above the value in /proc/sys/vm/nr_hugepages # é€æ˜å·¨é¡µ Transparent HugePages (THP) node_memory_AnonHugePages_bytes: Memory in anonymous huge pages # inactivelistä¸­çš„File-backedå†…å­˜ node_memory_Inactive_file_bytes: File-backed memory on inactive LRU list # inactivelistä¸­çš„Anonymouså†…å­˜ node_memory_Inactive_anon_bytes: Anonymous and swap cache on inactive LRU list, including tmpfs (shmem) # activelistä¸­çš„File-backedå†…å­˜ node_memory_Active_file_bytes: File-backed memory on active LRU list # activelistä¸­çš„Anonymouså†…å­˜ node_memory_Active_anon_bytes: Anonymous and swap cache on active least-recently-used (LRU) list, including tmpfs # ç¦æ­¢æ¢å‡ºçš„é¡µï¼Œå¯¹åº” Unevictable é“¾è¡¨ node_memory_Unevictable_bytes: Amount of unevictable memory that can't be swapped out for a variety of reasons # å…±äº«å†…å­˜ node_memory_Shmem_bytes: Used shared memory (shared between several processes, thus including RAM disks) # åŒ¿åé¡µå†…å­˜å¤§å° node_memory_AnonPages_bytes: Memory in user pages not backed by files # è¢«å…³è”çš„å†…å­˜é¡µå¤§å° node_memory_Mapped_bytes: Used memory in mapped pages files which have been mmaped, such as libraries # file-backedå†…å­˜é¡µç¼“å­˜å¤§å° node_memory_Cached_bytes: Parked file data (file content) cache # ç³»ç»Ÿä¸­æœ‰å¤šå°‘åŒ¿åé¡µæ›¾ç»è¢«swap-outã€ç°åœ¨åˆè¢«swap-inå¹¶ä¸”swap-inä¹‹åé¡µé¢ä¸­çš„å†…å®¹ä¸€ç›´æ²¡å‘ç”Ÿå˜åŒ– node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # è¢«mlock()ç³»ç»Ÿè°ƒç”¨é”å®šçš„å†…å­˜å¤§å° node_memory_Mlocked_bytes: Size of pages locked to memory using the mlock() system call # å—è®¾å¤‡(block device)æ‰€å ç”¨çš„ç¼“å­˜é¡µ node_memory_Buffers_bytes: Block device (e.g. harddisk) cache node_memory_SwapTotal_bytes: Memory information field SwapTotal_bytes node_memory_SwapFree_bytes: Memory information field SwapFree_bytes # DISK node_filesystem_files_free: Filesystem space available to non-root users in byte node_filesystem_free_bytes: Filesystem free space in bytes node_filesystem_size_bytes: Filesystem size in bytes node_filesystem_files_free: Filesystem total free file nodes node_filesystem_files: Filesystem total free file nodes node_filefd_maximum: Max open files node_filefd_allocated: Open files node_filesystem_readonly: Filesystem read-only status node_filesystem_device_error: Whether an error occurred while getting statistics for the given device node_disk_reads_completed_total: The total number of reads completed successfully node_disk_writes_completed_total: The total number of writes completed successfully node_disk_reads_merged_total: The number of reads merged node_disk_writes_merged_total: The number of writes merged node_disk_read_bytes_total: The total number of bytes read successfully node_disk_written_bytes_total: The total number of bytes written successfully node_disk_io_time_seconds_total: Total seconds spent doing I/Os node_disk_read_time_seconds_total: The total number of seconds spent by all reads node_disk_write_time_seconds_total: The total number of seconds spent by all writes node_disk_io_time_weighted_seconds_total: The weighted of seconds spent doing I/Os # NET node_network_receive_bytes_total: Network device statistic receive_bytes (counter) node_network_transmit_bytes_total: Network device statistic transmit_bytes (counter) node_network_receive_packets_total: Network device statistic receive_bytes node_network_transmit_packets_total: Network device statistic transmit_bytes node_network_receive_errs_total: Network device statistic receive_errs node_network_transmit_errs_total: Network device statistic transmit_errs node_network_receive_drop_total: Network device statistic receive_drop node_network_transmit_drop_total: Network device statistic transmit_drop node_nf_conntrack_entries: Number of currently allocated flow entries for connection tracking node_sockstat_TCP_alloc: Number of TCP sockets in state alloc node_sockstat_TCP_inuse: Number of TCP sockets in state inuse node_sockstat_TCP_orphan: Number of TCP sockets in state orphan node_sockstat_TCP_tw: Number of TCP sockets in state tw node_netstat_Tcp_CurrEstab: Statistic TcpCurrEstab node_sockstat_sockets_used: Number of IPv4 sockets in use node_expoter integration å®Œæ•´çš„é…ç½®é¡¹è¯´æ˜ # Enables the node_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the node_exporter integration will be run but not scraped and thus not remote-written. Metrics for the # integration will be exposed at /integrations/node_exporter/metrics and can # be scraped by an external process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timtout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cboolean\u003e | default = false] # Optionally defines the the list of enabled-by-default collectors. # Anything not provided in the list below will be disabled by default, # but requires at least one element to be treated as defined. # # This is useful if you have a very explicit set of collectors you wish # to run. set_collectors: - [\u003cstring\u003e] # Additional collectors to enable on top of the default set of enabled # collectors or on top of the list provided by set_collectors. # # This is useful if you have a few collectors you wish to run that are # not enabled by default, but do not want to explicitly provide an entire # list through set_collectors. enable_collectors: - [\u003cstring\u003e] # Additional collectors to disable on top of the default set of disabled # collectors. Takes precedence over enable_collectors. # # This is useful if you have a few collectors you do not want to run that # are enabled by default, but do not want to explicitly provide an entire # list through set_collectors. disable_collectors: - [\u003cstring\u003e] # procfs mountpoint. [procfs_path: \u003cstring\u003e | default = \"/proc\"] # sysfs mountpoint. [sysfs_path: \u003cstring\u003e | default = \"/sys\"] # rootfs mountpoint. If running in docker, the root filesystem of the host # machine should be mounted and this value should be changed to the mount # directory. [rootfs_path: \u003cstring\u003e | default = \"/\"] # Expose expensive bcache priority stats. [enable_bcache_priority_stats: \u003cboolean\u003e] # Regexp of `bugs` field in cpu info to filter. [cpu_bugs_include: \u003cstring\u003e] # Enable the node_cpu_guest_seconds_total metric. [enable_cpu_guest_seconds_metric: \u003cboolean\u003e | default = true] # Enable the cpu_info metric for the cpu collector. [enable_cpu_info_metric: \u003cboolean\u003e | default = true] # Regexp of `flags` field in cpu info to filter. [cpu_flags_include: \u003cstring\u003e] # Regexmp of devices to ignore for diskstats. [diskstats_ignored_devices: \u003cstring\u003e | default = \"^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\\\d+n\\\\d+p)\\\\d+$\"] # Regexp of ethtool devices to exclude (mutually exclusive with ethtool_device_include) [ethtool_device_exclude: \u003cstring\u003e] # Regexp of ethtool devices to include (mutually exclusive with ethtool_device_exclude) [ethtool_device_include: \u003cstring\u003e] # Regexp of ethtool stats to include. [ethtool_metrics_include: \u003cstring\u003e | default = \".*\"] # Regexp of mount points to ignore for filesystem collector. [filesystem_mount_points_exclude: \u003cstring\u003e | default = \"^/(dev|proc|sys|var/lib/docker/.+)($|/)\"] # Regexp of filesystem types to ignore for filesystem collector. [filesystem_fs_types_exclude: \u003cstring\u003e | default = \"^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\"] # How long to wait for a mount to respond before marking it as stale. [filesystem_mount_timeout: \u003cduration\u003e | default = \"5s\"] # Array of IPVS backend stats labels. # # The default is [local_address, local_port, remote_address, remote_port, proto, local_mark]. ipvs_backend_labels: [- \u003cstring\u003e] # NTP server to use for ntp collector [ntp_server: \u003cstring\u003e | default = \"127.0.0.1\"] # NTP protocol version [ntp_protocol_version: \u003cint\u003e | default = 4] # Certify that the server address is not a public ntp server. [ntp_server_is_local: \u003cboolean\u003e | default = false] # IP TTL to use wile sending NTP query. [ntp_ip_ttl: \u003cint\u003e | default = 1] # Max accumulated distance to the root. [ntp_max_distance: \u003cduration\u003e | default = \"3466080us\"] # Offset between local clock and local ntpd time to tolerate. [ntp_local_offset_tolerance: \u003cduration\u003e | default = \"1ms\"] # Regexp of net devices to ignore for netclass collector. [netclass_ignored_devices: \u003cstring\u003e | default = \"^$\"] # Ignore net devices with invalid speed values. This will default to true in # node_exporter 2.0. [netclass_ignore_invalid_speed_device: \u003cboolean\u003e | default = false] # Enable collecting address-info for every device. [netdev_address_info: \u003cboolean\u003e] # Regexp of net devices to exclude (mutually exclusive with include) [netdev_device_exclude: \u003cstring\u003e | default = \"\"] # Regexp of net devices to include (mutually exclusive with exclude) [netdev_device_include: \u003cstring\u003e | default = \"\"] # Regexp of fields to return for netstat collector. [netstat_fields: \u003cstring\u003e | default = \"^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$\"] # List of CPUs from which perf metrics should be collected. [perf_cpus: \u003cstring\u003e | default = \"\"] # Array of perf tracepoints that should be collected. perf_tracepoint: [- \u003cstring\u003e] # Regexp of power supplies to ignore for the powersupplyclass collector. [powersupply_ignored_supplies: \u003cstring\u003e | default = \"^$\"] # Path to runit service directory. [runit_service_dir: \u003cstring\u003e | default = \"/etc/service\"] # XML RPC endpoint for the supervisord collector. # # Setting SUPERVISORD_URL in the environment will override the default value. # An explicit value in the YAML config takes precedence over the environment # variable. [supervisord_url: \u003cstring\u003e | default = \"http://localhost:9001/RPC2\"] # Regexp of systemd units to include. Units must both match include and not # match exclude to be collected. [systemd_unit_include: \u003cstring\u003e | default = \".+\"] # Regexp of systemd units to exclude. Units must both match include and not # match exclude to be collected. [systemd_unit_exclude: \u003cstring\u003e | default = \".+\\\\.(automount|device|mount|scope|slice)\"] # Enables service unit tasks metrics unit_tasks_current and unit_tasks_max [systemd_enable_task_metrics: \u003cboolean\u003e | default = false] # Enables service unit metric service_restart_total [systemd_enable_restarts_metrics: \u003cboolean\u003e | default = false] # Enables service unit metric unit_start_time_seconds [systemd_enable_start_time_metrics: \u003cboolean\u003e | default = false] # Regexp of tapestats devices to ignore. [tapestats_ignored_devices: \u003cstring\u003e | default = \"^$\"] # Directory to read *.prom files from for the textfile collector. [textfile_directory: \u003cstring\u003e | default = \"\"] # Regexp of fields to return for the vmstat collector. [vmstat_fields: \u003cstring\u003e | default = \"^(oom_kill|pgpg|pswp|pg.*fault).*\"] node_exporter è‡ªå®šä¹‰ collectors æ‚¨å¯ä»¥åœ¨ integrations node_export é…ç½®ä¸­ï¼Œé€šè¿‡è®¾ç½®å’Œä¿®æ”¹ set_collectors enable_collectors disable_collectorsï¼Œä»¥æ§åˆ¶å“ªäº› collector ç”Ÿæ•ˆã€‚\nconst ( CollectorARP = \"arp\" CollectorBCache = \"bcache\" CollectorBTRFS = \"btrfs\" CollectorBonding = \"bonding\" CollectorBootTime = \"boottime\" CollectorBuddyInfo = \"buddyinfo\" CollectorCPU = \"cpu\" CollectorCPUFreq = \"cpufreq\" CollectorConntrack = \"conntrack\" CollectorDMI = \"dmi\" CollectorDRBD = \"drbd\" CollectorDRM = \"drm\" CollectorDevstat = \"devstat\" CollectorDiskstats = \"diskstats\" CollectorEDAC = \"edac\" CollectorEntropy = \"entropy\" CollectorEthtool = \"ethtool\" CollectorExec = \"exec\" CollectorFibrechannel = \"fibrechannel\" CollectorFileFD = \"filefd\" CollectorFilesystem = \"filesystem\" CollectorHWMon = \"hwmon\" CollectorIPVS = \"ipvs\" CollectorInfiniband = \"infiniband\" CollectorInterrupts = \"interrupts\" CollectorKSMD = \"ksmd\" CollectorLnstat = \"lnstat\" CollectorLoadAvg = \"loadavg\" CollectorLogind = \"logind\" CollectorMDADM = \"mdadm\" CollectorMeminfo = \"meminfo\" CollectorMeminfoNuma = \"meminfo_numa\" CollectorMountstats = \"mountstats\" CollectorNFS = \"nfs\" CollectorNFSD = \"nfsd\" CollectorNTP = \"ntp\" CollectorNVME = \"nvme\" CollectorNetclass = \"netclass\" CollectorNetdev = \"netdev\" CollectorNetstat = \"netstat\" CollectorNetworkRoute = \"network_route\" CollectorOS = \"os\" CollectorPerf = \"perf\" CollectorPowersuppply = \"powersupplyclass\" CollectorPressure = \"pressure\" CollectorProcesses = \"processes\" CollectorQDisc = \"qdisc\" CollectorRAPL = \"rapl\" CollectorRunit = \"runit\" CollectorSchedstat = \"schedstat\" CollectorSockstat = \"sockstat\" CollectorSoftnet = \"softnet\" CollectorStat = \"stat\" CollectorSupervisord = \"supervisord\" CollectorSystemd = \"systemd\" CollectorTCPStat = \"tcpstat\" CollectorTapestats = \"tapestats\" CollectorTextfile = \"textfile\" CollectorThermal = \"thermal\" CollectorThermalzone = \"thermal_zone\" CollectorTime = \"time\" CollectorTimex = \"timex\" CollectorUDPQueues = \"udp_queues\" CollectorUname = \"uname\" CollectorVMStat = \"vmstat\" CollectorWiFi = \"wifi\" CollectorXFS = \"xfs\" CollectorZFS = \"zfs\" CollectorZoneinfo = \"zoneinfo\" ) ",
    "description": "",
    "tags": null,
    "title": "Node Exporter",
    "uri": "/grafana-agent/integrations/node-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†postgres_exporterï¼Œæ¥é‡‡é›†Postgres Serverçš„metricsé‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæ¨èæ‚¨åˆ†é…ç‹¬ç«‹çš„è´¦å·ï¼Œä¾›grafana-agentæ¥è¿æ¥åˆ°Postgres serverï¼Œä»¥é¿å…è¿‡åº¦æˆæƒå¸¦æ¥çš„å®‰å…¨æ€§é—®é¢˜ï¼Œå…·ä½“å¯ä»¥é¤ä½ è€ƒpostgres exporterå®˜æ–¹æ–‡æ¡£.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: postgres_exporter: enabled: true EOF é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ pg_locks_count : pg_locks_count{datname=~\"$datname\", instance=~\"$instance\", mode=~\"$mode\"} != 0 pg_postmaster_start_time_seconds : pg_postmaster_start_time_seconds{release=\"$release\", instance=\"$instance\"} * 1000 pg_settings_effective_cache_size_bytes : pg_settings_effective_cache_size_bytes{instance=\"$instance\"} pg_settings_maintenance_work_mem_bytes : pg_settings_maintenance_work_mem_bytes{instance=\"$instance\"} pg_settings_max_connections : pg_settings_max_connections{release=\"$release\", instance=\"$instance\"} pg_settings_max_parallel_workers : pg_settings_max_parallel_workers{instance=\"$instance\"} pg_settings_max_wal_size_bytes : pg_settings_max_wal_size_bytes{instance=\"$instance\"} pg_settings_max_worker_processes : pg_settings_max_worker_processes{instance=\"$instance\"} pg_settings_random_page_cost : pg_settings_random_page_cost{instance=\"$instance\"} pg_settings_seq_page_cost : pg_settings_seq_page_cost pg_settings_shared_buffers_bytes : pg_settings_shared_buffers_bytes{instance=\"$instance\"} pg_settings_work_mem_bytes : pg_settings_work_mem_bytes{instance=\"$instance\"} pg_stat_activity_count : pg_stat_activity_count{datname=~\"$datname\", instance=~\"$instance\", state=\"active\"} !=0 pg_stat_activity_count : pg_stat_activity_count{datname=~\"$datname\", instance=~\"$instance\", state=~\"idle|idle in transaction|idle in transaction (aborted)\"} pg_stat_bgwriter_buffers_alloc : irate(pg_stat_bgwriter_buffers_alloc{instance=\"$instance\"}[5m]) pg_stat_bgwriter_buffers_backend : irate(pg_stat_bgwriter_buffers_backend{instance=\"$instance\"}[5m]) pg_stat_bgwriter_buffers_backend_fsync : irate(pg_stat_bgwriter_buffers_backend_fsync{instance=\"$instance\"}[5m]) pg_stat_bgwriter_buffers_checkpoint : irate(pg_stat_bgwriter_buffers_checkpoint{instance=\"$instance\"}[5m]) pg_stat_bgwriter_buffers_clean : irate(pg_stat_bgwriter_buffers_clean{instance=\"$instance\"}[5m]) pg_stat_bgwriter_checkpoint_sync_time : irate(pg_stat_bgwriter_checkpoint_sync_time{instance=\"$instance\"}[5m]) pg_stat_bgwriter_checkpoint_write_time : irate(pg_stat_bgwriter_checkpoint_write_time{instance=\"$instance\"}[5m]) pg_stat_database_blks_hit : pg_stat_database_blks_hit{instance=\"$instance\", datname=~\"$datname\"} / (pg_stat_database_blks_read{instance=\"$instance\", datname=~\"$datname\"} + pg_stat_database_blks_hit{instance=\"$instance\", datname=~\"$datname\"}) pg_stat_database_conflicts : irate(pg_stat_database_conflicts{instance=\"$instance\", datname=~\"$datname\"}[5m]) pg_stat_database_deadlocks : irate(pg_stat_database_deadlocks{instance=\"$instance\", datname=~\"$datname\"}[5m]) pg_stat_database_temp_bytes : irate(pg_stat_database_temp_bytes{instance=\"$instance\", datname=~\"$datname\"}[5m]) pg_stat_database_tup_deleted : pg_stat_database_tup_deleted{datname=~\"$datname\", instance=~\"$instance\"} != 0 pg_stat_database_tup_fetched : SUM(pg_stat_database_tup_fetched{datname=~\"$datname\", instance=~\"$instance\"}) pg_stat_database_tup_fetched : pg_stat_database_tup_fetched{datname=~\"$datname\", instance=~\"$instance\"} != 0 pg_stat_database_tup_inserted : SUM(pg_stat_database_tup_inserted{release=\"$release\", datname=~\"$datname\", instance=~\"$instance\"}) pg_stat_database_tup_inserted : pg_stat_database_tup_inserted{datname=~\"$datname\", instance=~\"$instance\"} != 0 pg_stat_database_tup_returned : pg_stat_database_tup_returned{datname=~\"$datname\", instance=~\"$instance\"} != 0 pg_stat_database_tup_updated : SUM(pg_stat_database_tup_updated{datname=~\"$datname\", instance=~\"$instance\"}) pg_stat_database_tup_updated : pg_stat_database_tup_updated{datname=~\"$datname\", instance=~\"$instance\"} != 0 pg_stat_database_xact_commit : irate(pg_stat_database_xact_commit{instance=\"$instance\", datname=~\"$datname\"}[5m]) pg_stat_database_xact_rollback : irate(pg_stat_database_xact_rollback{instance=\"$instance\", datname=~\"$datname\"}[5m]) pg_static : pg_static{release=\"$release\", instance=\"$instance\"} process_cpu_seconds_total : avg(rate(process_cpu_seconds_total{release=\"$release\", instance=\"$instance\"}[5m]) * 1000) process_open_fds : process_open_fds{release=\"$release\", instance=\"$instance\"} process_resident_memory_bytes : avg(rate(process_resident_memory_bytes{release=\"$release\", instance=\"$instance\"}[5m])) process_virtual_memory_bytes : avg(rate(process_virtual_memory_bytes{release=\"$release\", instance=\"$instance\"}[5m])) å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the postgres_exporter integration, allowing the Agent to automatically # collect system metrics from the configured postgres server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from a truncated version of # the first DSN in data_source_names. The truncated DSN includes the hostname # and database name (if used) of the server, but does not include any user # information. # # If data_source_names contains more than one entry, the integration will fail to # load and a value for instance must be manually provided. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the postgres_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/postgres_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # Data Source Names specifies the Postgres server(s) to connect to. This is # REQUIRED but may also be specified by the POSTGRES_EXPORTER_DATA_SOURCE_NAME # environment variable, where DSNs the environment variable are separated by # commas. If neither are set, the integration will fail to start. # # The format of this is specified here: https://pkg.go.dev/github.com/lib/pq#ParseURL # # A working example value for a server with a password is: # \"postgresql://username:passwword@localhost:5432/database?sslmode=disable\" # # Multiple DSNs may be provided here, allowing for scraping from multiple # servers. data_source_names: - \u003cstring\u003e # Disables collection of metrics from pg_settings. [disable_settings_metrics: \u003cboolean\u003e | default = false] # Autodiscover databases to collect metrics from. If false, only collects # metrics from databases collected from data_source_names. [autodiscover_databases: \u003cboolean\u003e | default = false] # Excludes specific databases from being collected when autodiscover_databases # is true. exclude_databases: [ - \u003cstring\u003e ] # Includes only specific databases (excluding all others) when autodiscover_databases # is true. include_databases: [ - \u003cstring\u003e ] # Path to a YAML file containing custom queries to run. Check out # postgres_exporter's queries.yaml for examples of the format: # https://github.com/prometheus-community/postgres_exporter/blob/master/queries.yaml [query_path: \u003cstring\u003e | default = \"\"] # When true, only exposes metrics supplied from query_path. [disable_default_metrics: \u003cboolean\u003e | default = false] ",
    "description": "",
    "tags": null,
    "title": "Postgres Exporter",
    "uri": "/grafana-agent/integrations/postgres-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®é›†æˆäº†process-exporterï¼ŒåŸºäº/procçš„æ–‡ä»¶åˆ†æç»“æœï¼Œæ¥æ”¶é›†Linuxç³»ç»Ÿè¿›ç¨‹ç›¸å…³çš„æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼ŒéLinuxç³»ç»Ÿå¼€å¯è¯¥exporterä¸èµ·ä½œç”¨ï¼‰ã€‚\nå¦‚æœgrafana-agentè¿è¡Œåœ¨containerä¸­ï¼Œé‚£ä¹ˆåœ¨å®¹å™¨çš„å¯åŠ¨å‘½ä»¤ä¸­ï¼Œè¦åšä»¥ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\ndocker run \\  -v \"/proc:/proc:ro\" \\  -v /tmp/agent:/etc/agent \\  -v /path/to/config.yaml:/etc/agent-config/agent.yaml \\  grafana/agent \\  --config.file=/etc/agent-config/agent.yaml æ³¨æ„ï¼Œå°†/path/to/config.yamlæ›¿æ¢æˆæ‚¨è‡ªå·±ç›¸åº”çš„é…ç½®æ–‡ä»¶ã€‚\nå¦‚æœgrafana-agentè¿è¡Œåœ¨Kubernetesä¸­ï¼Œé‚£ä¹ˆåŒæ ·çš„éœ€è¦åœ¨manifestæ–‡ä»¶ä¸­ï¼Œåšå¦‚ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\napiVersion: v1 kind: Pod metadata: name: grafana-agent spec: containers: - image: grafana/agent name: agent args: - --config.file=/etc/agent-config/agent.yaml volumeMounts: - name: procfs mountPath: /proc readOnly: true volumes: - name: procfs hostPath: path: /proc é…ç½®å¹¶å¯ç”¨process_exporter å¦‚ä¸‹çš„é…ç½®ï¼Œå°†ä¼šå¼€å¯process_exporterï¼Œå¹¶è¿½è¸ªç³»ç»Ÿä¸­çš„æ‰€æœ‰è¿›ç¨‹ã€‚\nprocess_exporter: enabled: true process_names: - name: \"{{.Comm}}\" cmdline: - '.+' é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # Context switches # ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°é‡ # Counter namedprocess_namegroup_context_switches_total # Cpu user/system usage in seconds # CPU æ—¶é—´ï¼ˆç§’ï¼‰ # Counter namedprocess_namegroup_cpu_seconds_total # Major page faults # ä¸»è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_major_page_faults_total # Minor page faults # æ¬¡è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_minor_page_faults_total # number of bytes of memory in use # å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge namedprocess_namegroup_memory_bytes # number of processes in this group # åŒåè¿›ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_procs # Number of processes in states Running, Sleeping, Waiting, Zombie, or Other # åŒåè¿›ç¨‹çŠ¶æ€åˆ†å¸ƒ # Gauge namedprocess_namegroup_states # Number of threads # çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_threads # start time in seconds since 1970/01/01 of oldest process in group # å¯åŠ¨æ—¶é—´æˆ³ # Gauge namedprocess_namegroup_oldest_start_time_seconds # number of open file descriptors for this group # æ‰“å¼€æ–‡ä»¶æè¿°ç¬¦æ•°é‡ # Gauge namedprocess_namegroup_open_filedesc # the worst (closest to 1) ratio between open fds and max fds among all procs in this group # æ‰“å¼€æ–‡ä»¶æ•° / å…è®¸æ‰“å¼€æ–‡ä»¶æ•° # Gauge namedprocess_namegroup_worst_fd_ratio # number of bytes read by this group # è¯»æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_read_bytes_total # number of bytes written by this group # å†™æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_write_bytes_total # Number of threads in this group waiting on each wchan # å†…æ ¸wchanç­‰å¾…çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_threads_wchan process_exporterçš„è¯¦ç»†é…ç½®é¡¹è¯´æ˜ # Enables the process_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the process_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/process_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # procfs mountpoint. [procfs_path: \u003cstring\u003e | default = \"/proc\"] # If a proc is tracked, track with it any children that aren't a part of their # own group. [track_children: \u003cboolean\u003e | default = true] # Report on per-threadname metrics as well. [track_threads: \u003cboolean\u003e | default = true] # Gather metrics from smaps file, which contains proportional resident memory # size. [gather_smaps: \u003cboolean\u003e | default = true] # Recheck process names on each scrape. [recheck_on_scrape: \u003cboolean\u003e | default = false] # A collection of matching rules to use for deciding which processes to # monitor. Each config can match multiple processes to be tracked as a single # process \"group.\" process_names: [- \u003cprocess_matcher_config\u003e]  process_matcher_config\n # The name to use for identifying the process group name in the metric. By # default, it uses the base path of the executable. # # The following template variables are available: # # - {{.Comm}}: Basename of the original executable from /proc/\u003cpid\u003e/stat # - {{.ExeBase}}: Basename of the executable from argv[0] # - {{.ExeFull}}: Fully qualified path of the executable # - {{.Username}}: Username of the effective user # - {{.Matches}}: Map containing all regex capture groups resulting from # matching a process with the cmdline rule group. # - {{.PID}}: PID of the process. Note that the PID is copied from the # first executable found. # - {{.StartTime}}: The start time of the process. This is useful when combined # with PID as PIDS get reused over time. [name: \u003cstring\u003e | default = \"{{.ExeBase}}\"] # A list of strings that match the base executable name for a process, truncated # at 15 characters. It is derived from reading the second field of # /proc/\u003cpid\u003e/stat minus the parens. # # If any of the strings match, the process will be tracked. comm: [- \u003cstring\u003e] # A list of strings that match argv[0] for a process. If there are no slashes, # only the basename of argv[0] needs to match. Otherwise the name must be an # exact match. For example, \"postgres\" may match any postgres binary but # \"/usr/local/bin/postgres\" can only match a postgres at that path exactly. # # If any of the strings match, the process will be tracked. exe: [- \u003cstring\u003e] # A list of regular expressions applied to the argv of the process. Each # regex here must match the corresponding argv for the process to be tracked. # The first element that is matched is argv[1]. # # Regex Captures are added to the .Matches map for use in the name. cmdline: [- \u003cstring\u003e] ",
    "description": "",
    "tags": null,
    "title": "Process Exporter",
    "uri": "/grafana-agent/integrations/process-exporter-config/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†redis_exporterï¼Œå¯ä»¥é‡‡é›†Redis serverçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentï¼Œåªæ”¯æŒé…ç½®ä¸€ä¸ªRedis serveråœ°å€ï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚å¦‚æœæ‚¨å¸Œæœ›é‡‡é›†å¤šä¸ªrediså®ä¾‹çš„metricsæ•°æ®ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®ä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒrediså®ä¾‹çš„æ•°æ®ã€‚\né…ç½®å¹¶å¯ç”¨redis_exporter redis_exporter: enabled: true redis_addr: \"redis-2:6379\" relabel_configs: - source_labels: [__address__] target_label: instance replacement: redis-2 æˆ‘ä»¬å¼ºçƒˆæ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®rediså®ä¾‹çš„æœ€å°åŒ–æˆæƒï¼Œé¿å…è¿‡åº¦æˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ redis_active_defrag_running: When activedefrag is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize. redis_allocator_active_bytes: Total bytes in the allocator active pages, this includes external-fragmentation. redis_allocator_allocated_bytes: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as used_memory. redis_allocator_frag_bytes: Delta between allocator_active and allocator_allocated. See note about mem_fragmentation_bytes. redis_allocator_frag_ratio: Ratio between allocator_active and allocator_allocated. This is the true (external) fragmentation metric (not mem_fragmentation_ratio). redis_allocator_resident_bytes: Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS (by MEMORY PURGE, or just waiting). redis_allocator_rss_bytes: Delta between allocator_resident and allocator_active. redis_allocator_rss_ratio: Ratio between allocator_resident and allocator_active. This usually indicates pages that the allocator can and probably will soon release back to the OS. redis_aof_current_rewrite_duration_sec: Duration of the on-going AOF rewrite operation if any. redis_aof_enabled: Flag indicating AOF logging is activated. redis_aof_last_bgrewrite_status: Status of the last AOF rewrite operation. redis_aof_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last AOF rewrite operation. redis_aof_last_rewrite_duration_sec: Duration of the last AOF rewrite operation in seconds. redis_aof_last_write_status: Status of the last write operation to the AOF. redis_aof_rewrite_in_progress: Flag indicating a AOF rewrite operation is on-going. redis_aof_rewrite_scheduled: Flag indicating an AOF rewrite operation will be scheduled once the on-going RDB save is complete. redis_blocked_clients: Number of clients pending on a blocking call (BLPOP, BRPOP, BRPOPLPUSH, BLMOVE, BZPOPMIN, BZPOPMAX). redis_client_recent_max_input_buffer_bytes: Biggest input buffer among current client connections. redis_client_recent_max_output_buffer_bytes: Biggest output buffer among current client connections. redis_cluster_enabled: Indicate Redis cluster is enabled. redis_commands_duration_seconds_total: The total CPU time consumed by these commands.(Counter) redis_commands_processed_total: Total number of commands processed by the server.(Counter) redis_commands_total: The number of calls that reached command execution (not rejected).(Counter) redis_config_maxclients: The value of the maxclients configuration directive. This is the upper limit for the sum of connected_clients, connected_slaves and cluster_connections. redis_config_maxmemory: The value of the maxmemory configuration directive. redis_connected_clients: Number of client connections (excluding connections from replicas). redis_connected_slaves: Number of connected replicas. redis_connections_received_total: Total number of connections accepted by the server.(Counter) redis_cpu_sys_children_seconds_total: System CPU consumed by the background processes.(Counter) redis_cpu_sys_seconds_total: System CPU consumed by the Redis server, which is the sum of system CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_cpu_user_children_seconds_total: User CPU consumed by the background processes.(Counter) redis_cpu_user_seconds_total: User CPU consumed by the Redis server, which is the sum of user CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_db_keys: Total number of keys by DB. redis_db_keys_expiring: Total number of expiring keys by DB redis_defrag_hits: Number of value reallocations performed by active the defragmentation process. redis_defrag_misses: Number of aborted value reallocations started by the active defragmentation process. redis_defrag_key_hits: Number of keys that were actively defragmented. redis_defrag_key_misses: Number of keys that were skipped by the active defragmentation process. redis_evicted_keys_total: Number of evicted keys due to maxmemory limit.(Counter) redis_expired_keys_total: Total number of key expiration events.(Counter) redis_expired_stale_percentage: The percentage of keys probably expired. redis_expired_time_cap_reached_total: The count of times that active expiry cycles have stopped early. redis_exporter_last_scrape_connect_time_seconds: The duration(in seconds) to connect when scrape. redis_exporter_last_scrape_duration_seconds: The last scrape duration. redis_exporter_last_scrape_error: The last scrape error status. redis_exporter_scrape_duration_seconds_count: Durations of scrapes by the exporter redis_exporter_scrape_duration_seconds_sum: Durations of scrapes by the exporter redis_exporter_scrapes_total: Current total redis scrapes.(Counter) redis_instance_info: Information about the Redis instance. redis_keyspace_hits_total: Hits total.(Counter) redis_keyspace_misses_total: Misses total.(Counter) redis_last_key_groups_scrape_duration_milliseconds: Duration of the last key group metrics scrape in milliseconds. redis_last_slow_execution_duration_seconds: The amount of time needed for last slow execution, in seconds. redis_latest_fork_seconds: The amount of time needed for last fork, in seconds. redis_lazyfree_pending_objects: The number of objects waiting to be freed (as a result of calling UNLINK, or FLUSHDB and FLUSHALL with the ASYNC option). redis_master_repl_offset: The server's current replication offset. redis_mem_clients_normal: Memory used by normal clients.(Gauge) redis_mem_clients_slaves: Memory used by replica clients - Starting Redis 7.0, replica buffers share memory with the replication backlog, so this field can show 0 when replicas don't trigger an increase of memory usage. redis_mem_fragmentation_bytes: Delta between used_memory_rss and used_memory. Note that when the total fragmentation bytes is low (few megabytes), a high ratio (e.g. 1.5 and above) is not an indication of an issue. redis_mem_fragmentation_ratio: Ratio between used_memory_rss and used_memory. Note that this doesn't only includes fragmentation, but also other process overheads (see the allocator_* metrics), and also overheads like code, shared libraries, stack, etc. redis_mem_not_counted_for_eviction_bytes: (Gauge) redis_memory_max_bytes: Max memory limit in bytes. redis_memory_used_bytes: Total number of bytes allocated by Redis using its allocator (either standard libc, jemalloc, or an alternative allocator such as tcmalloc) redis_memory_used_dataset_bytes: The size in bytes of the dataset (used_memory_overhead subtracted from used_memory) redis_memory_used_lua_bytes: Number of bytes used by the Lua engine. redis_memory_used_overhead_bytes: The sum in bytes of all overheads that the server allocated for managing its internal data structures. redis_memory_used_peak_bytes: Peak memory consumed by Redis (in bytes) redis_memory_used_rss_bytes: Number of bytes that Redis allocated as seen by the operating system (a.k.a resident set size). This is the number reported by tools such as top(1) and ps(1) redis_memory_used_scripts_bytes: Number of bytes used by cached Lua scripts redis_memory_used_startup_bytes: Initial amount of memory consumed by Redis at startup in bytes redis_migrate_cached_sockets_total: The number of sockets open for MIGRATE purposes redis_net_input_bytes_total: Total input bytes(Counter) redis_net_output_bytes_total: Total output bytes(Counter) redis_process_id: Process ID redis_pubsub_channels: Global number of pub/sub channels with client subscriptions redis_pubsub_patterns: Global number of pub/sub pattern with client subscriptions redis_rdb_bgsave_in_progress: Flag indicating a RDB save is on-going redis_rdb_changes_since_last_save: Number of changes since the last dump redis_rdb_current_bgsave_duration_sec: Duration of the on-going RDB save operation if any redis_rdb_last_bgsave_duration_sec: Duration of the last RDB save operation in seconds redis_rdb_last_bgsave_status: Status of the last RDB save operation redis_rdb_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last RDB save operation redis_rdb_last_save_timestamp_seconds: Epoch-based timestamp of last successful RDB save redis_rejected_connections_total: Number of connections rejected because of maxclients limit(Counter) redis_repl_backlog_first_byte_offset: The master offset of the replication backlog buffer redis_repl_backlog_history_bytes: Size in bytes of the data in the replication backlog buffer redis_repl_backlog_is_active: Flag indicating replication backlog is active redis_replica_partial_resync_accepted: The number of accepted partial resync requests(Gauge) redis_replica_partial_resync_denied: The number of denied partial resync requests(Gauge) redis_replica_resyncs_full: The number of full resyncs with replicas redis_replication_backlog_bytes: Memory used by replication backlog redis_second_repl_offset: The offset up to which replication IDs are accepted. redis_slave_expires_tracked_keys: The number of keys tracked for expiry purposes (applicable only to writable replicas)(Gauge) redis_slowlog_last_id: Last id of slowlog redis_slowlog_length: Total slowlog redis_start_time_seconds: Start time of the Redis instance since unix epoch in seconds. redis_target_scrape_request_errors_total: Errors in requests to the exporter redis_up: Flag indicating redis instance is up redis_uptime_in_seconds: Number of seconds since Redis server start å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the redis_exporter integration, allowing the Agent to automatically # collect system metrics from the configured redis address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of redis_addr. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the redis_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/redis_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # exporter-specific configuration options # Address of the redis instance. redis_addr: \u003cstring\u003e # User name to use for authentication (Redis ACL for Redis 6.0 and newer). [redis_user: \u003cstring\u003e] # Password of the redis instance. [redis_password: \u003cstring\u003e] # Path of a file containing a passord. If this is defined, it takes precedece # over redis_password. [redis_password_file: \u003cstring\u003e] # Namespace for the metrics. [namespace: \u003cstring\u003e | default = \"redis\"] # What to use for the CONFIG command. [config_command: \u003cstring\u003e | default = \"CONFIG\"] # Comma separated list of key-patterns to export value and length/size, searched for with SCAN. [check_keys: \u003cstring\u003e] # Comma separated list of LUA regex for grouping keys. When unset, no key # groups will be made. [check_key_groups: \u003cstring\u003e] # Check key or key groups batch size hint for the underlying SCAN. Keeping the same name for backwards compatibility, but this applies to both key and key groups batch size configuration. [check_key_groups_batch_size: \u003cint\u003e | default = 10000] # The maximum number of distinct key groups with the most memory utilization # to present as distinct metrics per database. The leftover key groups will be # aggregated in the 'overflow' bucket. [max_distinct_key_groups: \u003cint\u003e | default = 100] # Comma separated list of single keys to export value and length/size. [check_single_keys: \u003cstring\u003e] # Comma separated list of stream-patterns to export info about streams, groups and consumers, searched for with SCAN. [check_streams: \u003cstring\u003e] # Comma separated list of single streams to export info about streams, groups and consumers. [check_single_streams: \u003cstring\u003e] # Comma separated list of individual keys to export counts for. [count_keys: \u003cstring\u003e] # Path to Lua Redis script for collecting extra metrics. [script_path: \u003cstring\u003e] # Timeout for connection to Redis instance (in Golang duration format). [connection_timeout: \u003ctime.Duration\u003e | default = \"15s\"] # Name of the client key file (including full path) if the server requires TLS client authentication. [tls_client_key_file: \u003cstring\u003e] # Name of the client certificate file (including full path) if the server requires TLS client authentication. [tls_client_cert_file: \u003cstring\u003e] # Name of the CA certificate file (including full path) if the server requires TLS client authentication. [tls_ca_cert_file: \u003cstring\u003e] # Whether to set client name to redis_exporter. [set_client_name: \u003cbool\u003e] # Whether to scrape Tile38 specific metrics. [is_tile38: \u003cbool\u003e] # Whether to scrape Client List specific metrics. [export_client_list: \u003cbool\u003e] # Whether to include the client's port when exporting the client list. Note # that including this will increase the cardinality of all redis metrics. [export_client_port: \u003cbool\u003e] # Whether to also export go runtime metrics. [redis_metrics_only: \u003cbool\u003e] # Whether to ping the redis instance after connecting. [ping_on_connect: \u003cbool\u003e] # Whether to include system metrics like e.g. redis_total_system_memory_bytes. [incl_system_metrics: \u003cbool\u003e] # Whether to to skip TLS verification. [skip_tls_verification: \u003cbool\u003e] ",
    "description": "",
    "tags": null,
    "title": "Redis Exporter",
    "uri": "/grafana-agent/integrations/redis-exporter-config/"
  },
  {
    "content": "The statsd_exporter_config block configures the statsd_exporter integration, which is an embedded version of statsd_exporter. This allows for the collection of statsd metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the statsd_exporter integration, allowing the Agent to automatically # collect system metrics from the configured statsd server address [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the statsd_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/statsd_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # The UDP address on which to receive statsd metric lines. An empty string # will disable UDP collection. [listen_udp: \u003cstring\u003e | default = \":9125\"] # The TCP address on which to receive statsd metric lines. An empty string # will disable TCP collection. [listen_tcp: \u003cstring\u003e | default = \":9125\"] # The Unixgram socket path to receive statsd metric lines. An empty string # will disable unixgram collection. [listen_unixgram: \u003cstring\u003e | default = \"\"] # The permission mode of the unixgram socket, when enabled. [unix_socket_mode: \u003cstring\u003e | default = \"755\"] # An optional mapping config that can translate dot-separated StatsD metrics # into labeled Prometheus metrics. For full instructions on how to write this # object, see the official documentation from the statsd_exporter: # # https://github.com/prometheus/statsd_exporter#metric-mapping-and-configuration # # Note that a SIGHUP will not reload this config. [mapping_config: \u003cstatsd_exporter.mapping_config\u003e] # Size (in bytes) of the operating system's transmit read buffer associated # with the UDP or unixgram connection. Please make sure the kernel parameters # net.core.rmem_max is set to a value greater than the value specified. [read_buffer: \u003cint\u003e | default = 0] # Maximum size of your metric mapping cache. Relies on least recently used # replacement policy if max size is reached. [cache_size: \u003cint\u003e | default = 1000] # Metric mapping cache type. Valid values are \"lru\" and \"random\". [cache_type: \u003cstring\u003e | default = \"lru\"] # Size of internal queue for processing events. [event_queue_size: \u003cint\u003e | default = 10000] # Number of events to hold in queue before flushing. [event_flush_threshold: \u003cint\u003e | default = 1000] # Number of events to hold in queue before flushing. [event_flush_interval: \u003cduration\u003e | default = \"200ms\"] # Parse DogStatsd style tags. [parse_dogstatsd_tags: \u003cbool\u003e | default = true] # Parse InfluxDB style tags. [parse_influxdb_tags: \u003cbool\u003e | default = true] # Parse Librato style tags. [parse_librato_tags: \u003cbool\u003e | default = true] # Parse SignalFX style tags. [parse_signalfx_tags: \u003cbool\u003e | default = true] ",
    "description": "",
    "tags": null,
    "title": "Statsd Exporter",
    "uri": "/grafana-agent/integrations/statsd-exporter-config/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": "grafana-agentå†…ç½®äº†windows_exporterçš„å®ç°ï¼Œå¯ä»¥é‡‡é›†åˆ°windowså¹³å°çš„æŒ‡æ ‡ã€‚\né…ç½®å¹¶å¯ç”¨windows_exporter # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u003cstring\u003e password: \u003cstring\u003e integrations: windows_exporter: enabled: true é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ windows_cpu_clock_interrupts_total: Total number of received and serviced clock tick interrupts(counter) windows_cpu_core_frequency_mhz: Core frequency in megahertz(gauge) windows_cpu_cstate_seconds_total: Time spent in low-power idle state(counter) windows_cpu_dpcs_total: Total number of received and serviced deferred procedure calls (DPCs)(counter) windows_cpu_idle_break_events_total: Total number of time processor was woken from idle(counter) windows_cpu_interrupts_total: Total number of received and serviced hardware interrupts(counter) windows_cpu_parking_status: Parking Status represents whether a processor is parked or not(gauge) windows_cpu_processor_performance: Processor Performance is the average performance of the processor while it is executing instructions, as a percentage of the nominal performance of the processor. On some processors, Processor Performance may exceed 100%(gauge) windows_cpu_time_total: Time that processor spent in different modes (idle, user, system, ...)(counter) windows_cs_hostname: Labeled system hostname information as provided by ComputerSystem.DNSHostName and ComputerSystem.Domain(gauge) windows_cs_logical_processors: ComputerSystem.NumberOfLogicalProcessors(gauge) windows_cs_physical_memory_bytes: ComputerSystem.TotalPhysicalMemory(gauge) windows_exporter_build_info: A metric with a constant '1' value labeled by version, revision, branch, and goversion from which windows_exporter was built.(gauge) windows_exporter_collector_duration_seconds: Duration of a collection.(gauge) windows_exporter_collector_success: Whether the collector was successful.(gauge) windows_exporter_collector_timeout: Whether the collector timed out.(gauge) windows_exporter_perflib_snapshot_duration_seconds: Duration of perflib snapshot capture(gauge) windows_logical_disk_free_bytes: Free space in bytes (LogicalDisk.PercentFreeSpace)(gauge) windows_logical_disk_idle_seconds_total: Seconds that the disk was idle (LogicalDisk.PercentIdleTime)(counter) windows_logical_disk_read_bytes_total: The number of bytes transferred from the disk during read operations (LogicalDisk.DiskReadBytesPerSec)(counter) windows_logical_disk_read_latency_seconds_total: Shows the average time, in seconds, of a read operation from the disk (LogicalDisk.AvgDiskSecPerRead)(counter) windows_logical_disk_read_seconds_total: Seconds that the disk was busy servicing read requests (LogicalDisk.PercentDiskReadTime)(counter) windows_logical_disk_read_write_latency_seconds_total: Shows the time, in seconds, of the average disk transfer (LogicalDisk.AvgDiskSecPerTransfer)(counter) windows_logical_disk_reads_total: The number of read operations on the disk (LogicalDisk.DiskReadsPerSec)(counter) windows_logical_disk_requests_queued: The number of requests queued to the disk (LogicalDisk.CurrentDiskQueueLength)(gauge) windows_logical_disk_size_bytes: Total space in bytes (LogicalDisk.PercentFreeSpace_Base)(gauge) windows_logical_disk_split_ios_total: The number of I/Os to the disk were split into multiple I/Os (LogicalDisk.SplitIOPerSec)(counter) windows_logical_disk_write_bytes_total: The number of bytes transferred to the disk during write operations (LogicalDisk.DiskWriteBytesPerSec)(counter) windows_logical_disk_write_latency_seconds_total: Shows the average time, in seconds, of a write operation to the disk (LogicalDisk.AvgDiskSecPerWrite)(counter) windows_logical_disk_write_seconds_total: Seconds that the disk was busy servicing write requests (LogicalDisk.PercentDiskWriteTime)(counter) windows_logical_disk_writes_total: The number of write operations on the disk (LogicalDisk.DiskWritesPerSec)(counter) windows_net_bytes_received_total: (Network.BytesReceivedPerSec)(counter) windows_net_bytes_sent_total: (Network.BytesSentPerSec)(counter) windows_net_bytes_total: (Network.BytesTotalPerSec)(counter) windows_net_current_bandwidth: (Network.CurrentBandwidth)(gauge) windows_net_packets_outbound_discarded_total: (Network.PacketsOutboundDiscarded)(counter) windows_net_packets_outbound_errors_total: (Network.PacketsOutboundErrors)(counter) windows_net_packets_received_discarded_total: (Network.PacketsReceivedDiscarded)(counter) windows_net_packets_received_errors_total: (Network.PacketsReceivedErrors)(counter) windows_net_packets_received_total: (Network.PacketsReceivedPerSec)(counter) windows_net_packets_received_unknown_total: (Network.PacketsReceivedUnknown)(counter) windows_net_packets_sent_total: (Network.PacketsSentPerSec)(counter) windows_net_packets_total: (Network.PacketsPerSec)(counter) windows_os_info: OperatingSystem.Caption, OperatingSystem.Version(gauge) windows_os_paging_free_bytes: OperatingSystem.FreeSpaceInPagingFiles(gauge) windows_os_paging_limit_bytes: OperatingSystem.SizeStoredInPagingFiles(gauge) windows_os_physical_memory_free_bytes: OperatingSystem.FreePhysicalMemory(gauge) windows_os_process_memory_limix_bytes: OperatingSystem.MaxProcessMemorySize(gauge) windows_os_processes: OperatingSystem.NumberOfProcesses(gauge) windows_os_processes_limit: OperatingSystem.MaxNumberOfProcesses(gauge) windows_os_time: OperatingSystem.LocalDateTime(gauge) windows_os_timezone: OperatingSystem.LocalDateTime(gauge) windows_os_users: OperatingSystem.NumberOfUsers(gauge) windows_os_virtual_memory_bytes: OperatingSystem.TotalVirtualMemorySize(gauge) windows_os_virtual_memory_free_bytes: OperatingSystem.FreeVirtualMemory(gauge) windows_os_visible_memory_bytes: OperatingSystem.TotalVisibleMemorySize(gauge) windows_service_info: A metric with a constant '1' value labeled with service information(gauge) windows_service_start_mode: The start mode of the service (StartMode)(gauge) windows_service_state: The state of the service (State)(gauge) windows_service_status: The status of the service (Status)(gauge) windows_system_context_switches_total: Total number of context switches (WMI source is PerfOS_System.ContextSwitchesPersec)(counter) windows_system_exception_dispatches_total: Total number of exceptions dispatched (WMI source is PerfOS_System.ExceptionDispatchesPersec)(counter) windows_system_processor_queue_length: Length of processor queue (WMI source is PerfOS_System.ProcessorQueueLength)(gauge) windows_system_system_calls_total: Total number of system calls (WMI source is PerfOS_System.SystemCallsPersec)(counter) windows_system_system_up_time: System boot time (WMI source is PerfOS_System.SystemUpTime)(gauge) windows_system_threads: Current number of threads (WMI source is PerfOS_System.Threads)(gauge) å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜ # Enables the windows_exporter integration, allowing the Agent to automatically # collect system metrics from the local windows instance [enabled: \u003cboolean\u003e | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u003cstring\u003e] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/windows_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u003cboolean\u003e | default = \u003cintegrations_config.scrape_integrations\u003e] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e] # Allows for relabeling labels on the target. relabel_configs: [- \u003crelabel_config\u003e ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u003crelabel_config\u003e ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u003cduration\u003e | default = \"60m\"] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u003cbool\u003e | default = false] # # Exporter-specific configuration options # # List of collectors to enable. Any non-experimental collector from the # embeded version of windows_exporter can be enabeld here. [enabled_collectors: \u003cstring\u003e | default = \"cpu,cs,logical_disk,net,os,service,system,textfile\"] # Settings for collectors which accept configuration. Settings specified here # are only used if the corresponding collector is enabled in # enabled_collectors. # Configuration for Exchange Mail Server exchange: # Comma-separated List of collectors to use. Defaults to all, if not specified. # Maps to collectors.exchange.enabled in windows_exporter [enabled_list: \u003cstring\u003e] # Configuration for the IIS web server iis: # Regexp of sites to whitelist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-whitelist in windows_exporter [site_whitelist: \u003cstring\u003e | default = \".+\"] # Regexp of sites to blacklist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-blacklist in windows_exporter [site_blacklist: \u003cstring\u003e | default = \"\"] # Regexp of apps to whitelist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-whitelist in windows_exporter [app_whitelist: \u003cstring\u003e | default=\".+\"] # Regexp of apps to blacklist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-blacklist in windows_exporter [app_blacklist: \u003cstring\u003e | default=\".+\"] # Configuration for reading metrics from a text files in a directory text_file: # Directory to read text files with metrics from. # Maps to collector.textfile.directory in windows_exporter [text_file_directory: \u003cstring\u003e | default=\"C:\\Program Files\\windows_exporter\\textfile_inputs\"] # Configuration for SMTP metrics smtp: # Regexp of virtual servers to whitelist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-whitelist in windows_exporter [whitelist: \u003cstring\u003e | default=\".+\"] # Regexp of virtual servers to blacklist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-blacklist in windows_exporter [blacklist: \u003cstring\u003e | default=\"\"] # Configuration for Windows Services service: # \"WQL 'where' clause to use in WMI metrics query. Limits the response to the services you specify and reduces the size of the response. # Maps to collector.service.services-where in windows_exporter [where_clause: \u003cstring\u003e | default=\"\"] # Configuration for Windows Processes process: # Regexp of processes to include. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.whitelist in windows_exporter [whitelist: \u003cstring\u003e | default=\".+\"] # Regexp of processes to exclude. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.blacklist in windows_exporter [blacklist: \u003cstring\u003e | default=\"\"] # Configuration for NICs network: # Regexp of NIC's to whitelist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-whitelist in windows_exporter [whitelist: \u003cstring\u003e | default=\".+\"] # Regexp of NIC's to blacklist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-blacklist in windows_exporter [blacklist: \u003cstring\u003e | default=\"\"] # Configuration for Microsoft SQL Server mssql: # Comma-separated list of mssql WMI classes to use. # Maps to collectors.mssql.classes-enabled in windows_exporter [enabled_classes: \u003cstring\u003e | default=\"accessmethods,availreplica,bufman,databases,dbreplica,genstats,locks,memmgr,sqlstats,sqlerrors,transactions\"] # Configuration for Microsoft Queue msqm: # WQL 'where' clause to use in WMI metrics query. Limits the response to the msmqs you specify and reduces the size of the response. # Maps to collector.msmq.msmq-where in windows_exporter [where_clause: \u003cstring\u003e | default=\"\"] # Configuration for disk information logical_disk: # Regexp of volumes to whitelist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-whitelist in windows_exporter [whitelist: \u003cstring\u003e | default=\".+\"] # Regexp of volumes to blacklist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-blacklist in windows_exporter [blacklist: \u003cstring\u003e | default=\".+\"] ",
    "description": "",
    "tags": null,
    "title": "Windows Exporter",
    "uri": "/grafana-agent/integrations/windows-exporter-config/"
  },
  {
    "content": "å¤œèºç®€ä»‹  å¤œèºï¼ˆ Nightingale ï¼‰æ˜¯ä¸€æ¬¾å›½äº§å¼€æºã€äº‘åŸç”Ÿç›‘æ§ç³»ç»Ÿï¼ŒNightingale åœ¨ 2020.3.20 å‘å¸ƒ v1 ç‰ˆæœ¬ï¼Œç›®å‰æ˜¯ v5 ç‰ˆæœ¬ï¼Œä»è¿™ä¸ªç‰ˆæœ¬å¼€å§‹ï¼Œä¸ Prometheusã€VictoriaMetricsã€Grafanaã€Telegrafã€Datadog ç­‰ç”Ÿæ€åšäº†ååŒé›†æˆï¼ŒåŠ›äº‰æ‰“é€ å›½å†…æœ€å¥½ç”¨çš„å¼€æºè¿ç»´ç›‘æ§ç³»ç»Ÿã€‚å‡ºè‡ª Open-Falcon ç ”å‘å›¢é˜Ÿã€‚\n é¡¹ç›®ä»£ç   åç«¯ï¼šğŸ’¡ https://github.com/didi/nightingale å‰ç«¯ï¼šğŸ’¡ https://github.com/n9e/fe-v5  å‰åç«¯éƒ½æ˜¯å¼€æºçš„ï¼Œå¦‚æœè§‰å¾—ä¸é”™ï¼Œæ¬¢è¿ star ä¸€ä¸‹ï¼Œç»™æˆ‘ä»¬æŒç»­åšæŒçš„åŠ¨åŠ›ï¼\näº§å“æˆªå›¾ æŸ¥çœ‹ç›‘æ§æ•°æ®ï¼Œå³ç›‘æ§å¤§ç›˜é¡µé¢ï¼š\né…ç½®å‘Šè­¦è§„åˆ™çš„åˆ—è¡¨é¡µé¢ï¼š\næ´»è·ƒå‘Šè­¦åˆ—è¡¨é¡µé¢ï¼Œå³å½“å‰æœªæ¢å¤çš„å‘Šè­¦é¡µé¢ï¼š\näº§å“æ¶æ„ Nightingale æœ‰å››ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼š\n Query Proxyï¼šæ‰¿æ¥å‰ç«¯æ—¶åºæ•°æ®æŸ¥è¯¢è¯·æ±‚ï¼Œè½¬å‘ç»™æ—¶åºåº“ï¼Œå¹¶å°†æ—¶åºåº“è¿”å›çš„ç»“æœè¿”å›ç»™å‰ç«¯ Push Gatewayï¼šæ‰¿æ¥å„ç±»é‡‡é›†å®¢æˆ·ç«¯çš„ç›‘æ§æ•°æ®æ¨é€ï¼Œç„¶åæŠŠæ•°æ®è½¬å­˜åˆ°åç«¯å¤šç§æ—¶åºåº“ Conf Managerï¼šé…ç½®ç®¡ç†ï¼Œæ¯”å¦‚å‘Šè­¦è§„åˆ™ã€å±è”½è§„åˆ™ã€è®¢é˜…è§„åˆ™ã€è‡ªæ„ˆè„šæœ¬ã€æƒé™ç­‰ç›¸å…³é…ç½®çš„ç®¡ç† Alerting Engineï¼šå‘Šè­¦å¼•æ“ï¼Œæ ¹æ®ç”¨æˆ·é…ç½®çš„ PromQLï¼ŒæŸ¥è¯¢æ—¶åºåº“ï¼Œåˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å‘Šè­¦å¹¶å‘é€  ç³»ç»Ÿæ¶æ„ å¤œèº v5 çš„è®¾è®¡éå¸¸ç®€å•ï¼Œæ ¸å¿ƒæ˜¯ server å’Œ webapi ä¸¤ä¸ªæ¨¡å—ï¼Œwebapi æ— çŠ¶æ€ï¼Œæ”¾åˆ°ä¸­å¿ƒç«¯ï¼Œæ‰¿æ¥å‰ç«¯è¯·æ±‚ï¼Œå°†ç”¨æˆ·é…ç½®å†™å…¥æ•°æ®åº“ï¼›server æ˜¯å‘Šè­¦å¼•æ“å’Œæ•°æ®è½¬å‘æ¨¡å—ï¼Œä¸€èˆ¬éšç€æ—¶åºåº“èµ°ï¼Œä¸€ä¸ªæ—¶åºåº“å°±å¯¹åº”ä¸€å¥— serverï¼Œæ¯å¥— server å¯ä»¥åªç”¨ä¸€ä¸ªå®ä¾‹ï¼Œä¹Ÿå¯ä»¥å¤šä¸ªå®ä¾‹ç»„æˆé›†ç¾¤ï¼Œserver å¯ä»¥æ¥æ”¶ Telegrafã€Grafana-Agentã€Datadog-Agentã€Falcon-Plugins ä¸ŠæŠ¥çš„æ•°æ®ï¼Œå†™å…¥åç«¯æ—¶åºåº“ï¼Œå‘¨æœŸæ€§ä»æ•°æ®åº“åŒæ­¥å‘Šè­¦è§„åˆ™ï¼Œç„¶åæŸ¥è¯¢æ—¶åºåº“åšå‘Šè­¦åˆ¤æ–­ã€‚æ¯å¥— server ä¾èµ–ä¸€ä¸ª redisã€‚æ¶æ„å›¾å¦‚ä¸‹ï¼š\näº§å“å¯¹æ¯” ä¸ Open-Falcon çš„åŒºåˆ« å› ä¸ºå¼€å‘ Open-Falcon å’Œ Nightingale çš„æ˜¯ä¸€æ‹¨äººï¼Œæ‰€ä»¥å¾ˆå¤šç¤¾åŒºä¼™ä¼´ä¼šæ¯”è¾ƒå¥½å¥‡ï¼Œä¸ºä½•è¦æ–°åšä¸€ä¸ªç›‘æ§å¼€æºè½¯ä»¶ã€‚æ ¸å¿ƒç‚¹æ˜¯ Open-Falcon å’Œ Nightingale çš„å·®å¼‚ç‚¹å®åœ¨æ˜¯å¤ªå¤§äº†ï¼ŒNightingale å¹¶éæ˜¯ Open-Falcon è®¾è®¡é€»è¾‘çš„ä¸€ä¸ªå»¶ç»­ï¼Œå°±çœ‹åšä¸¤ä¸ªä¸åŒçš„è½¯ä»¶å°±å¥½ã€‚\nOpen-Falcon æ˜¯ 14 å¹´å¼€å‘çš„ï¼Œå½“æ—¶æ˜¯æƒ³è§£å†³ Zabbix çš„ä¸€äº›å®¹é‡é—®é¢˜ï¼Œå¯ä»¥çœ‹åšæ˜¯ç‰©ç†æœºæ—¶ä»£çš„äº§ç‰©ï¼Œæ•´ä¸ªè®¾è®¡åå‘è¿ç»´è§†è§’ï¼Œè™½ç„¶æ•°æ®ç»“æ„ä¸Šå·²ç»å¼€å§‹è®¾è®¡äº†æ ‡ç­¾ï¼Œä½†æ˜¯æŸ¥è¯¢è¯­æ³•è¿˜æ˜¯æ¯”è¾ƒç®€å•ï¼Œæ— æ³•åº”å¯¹æ¯”è¾ƒå¤æ‚çš„åœºæ™¯ã€‚\nNightingale ç›´æ¥æ”¯æŒ PromQLï¼Œæ”¯æŒ Prometheusã€M3DBã€VictoriaMetrics å¤šç§æ—¶åºåº“ï¼Œæ”¯æŒ Telegrafã€Datadog-Agentã€Grafana-Agent åšç›‘æ§æ•°æ®é‡‡é›†ï¼Œæ”¯æŒ Grafana çœ‹å›¾ï¼Œæ•´ä¸ªè®¾è®¡æ›´åŠ äº‘åŸç”Ÿã€‚\nä¸ Prometheus çš„åŒºåˆ« Nightingale å¯ä»¥ç®€å•çœ‹åšæ˜¯ Prometheus çš„ä¸€ä¸ªä¼ä¸šçº§ç‰ˆæœ¬ï¼ŒæŠŠ Prometheus å½“åš Nightingale çš„ä¸€ä¸ªå†…éƒ¨ç»„ä»¶ï¼ˆæ—¶åºåº“ï¼‰ï¼Œå½“ç„¶ï¼Œä¹Ÿä¸æ˜¯å¿…é¡»çš„ï¼Œæ—¶åºåº“é™¤äº† Prometheusï¼Œè¿˜å¯ä»¥ä½¿ç”¨ VictoriaMetricsã€M3DB ç­‰ï¼Œå„ç§ Exporter é‡‡é›†å™¨ä¹Ÿå¯ä»¥ç»§ç»­ä½¿ç”¨ã€‚\nNightingale å¯ä»¥æ¥å…¥å¤šä¸ª Prometheusï¼Œå¯ä»¥å…è®¸ç”¨æˆ·åœ¨é¡µé¢ä¸Šé…ç½®å‘Šè­¦è§„åˆ™ã€å±è”½è§„åˆ™ã€è®¢é˜…è§„åˆ™ï¼Œåœ¨é¡µé¢ä¸ŠæŸ¥çœ‹å‘Šè­¦äº‹ä»¶ã€åšå‘Šè­¦äº‹ä»¶èšåˆç»Ÿè®¡ï¼Œé…ç½®å‘Šè­¦è‡ªæ„ˆæœºåˆ¶ï¼Œç®¡ç†ç›‘æ§å¯¹è±¡ï¼Œé…ç½®ç›‘æ§å¤§ç›˜ç­‰ï¼Œå°±æŠŠ Nightingale çœ‹åšæ˜¯ Prometheus çš„ä¸€ä¸ª WEBUI ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œä¸è¿‡å®é™…ä¸Šï¼Œå®ƒè¿œè¿œä¸æ­¢æ˜¯ä¸€ä¸ª WEBUIï¼Œç”¨ä¸€ä¸‹å°±ä¼šæ·±æœ‰æ„Ÿè§¦ã€‚\nåŠ å…¥ç¤¾åŒº å¾®ä¿¡å…¬ä¼—å·:cloudmonï¼ˆäº‘åŸç”Ÿç›‘æ§ï¼‰è¿™æ˜¯å¤œèºçš„å¤§æœ¬è¥ï¼Œå¯ä»¥åœ¨å…¬ä¼—å·èœå•é‡Œæ‰¾åˆ°åŠ ç¾¤å…¥å£ã€ç¤¾åŒºç­”ç–‘å…¥å£ï¼Œå…³æ³¨èµ·æ¥å§ï¼æˆ‘ä»¬å›¢é˜Ÿåšè¿ç»´ç›‘æ§è¿™ä¸ªäº‹æƒ…å·®ä¸å¤šæœ‰ 10 å¹´äº†ï¼Œä¸€ç›´åœ¨åšæŒï¼Œå¸Œæœ›èƒ½æŠŠè¿™ä¸ªäº‹åšåˆ°æè‡´ï¼Œæ¬¢è¿åŠ å…¥æˆ‘ä»¬ä¸€èµ·ï¼\n",
    "description": "",
    "tags": null,
    "title": "å¤œèºæ‰‹å†Œ",
    "uri": "/"
  },
  {
    "content": " Acknowledgement: grafana-agent is powered by Grafana Agent. Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\nThe Grafana Agent uses the same code as Prometheus, but tackles these issues by only using the most relevant parts of Prometheus for interaction with hosted metrics:\n Service Discovery Scraping Write Ahead Log (WAL) Remote Write   å¯¹äºKubernetesé›†ç¾¤åŠå…¶ä¸Šåº”ç”¨ï¼Œæˆ‘ä»¬æ¨èä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼Œå»ºç«‹èµ·å®Œæ•´çš„kubernetesæŒ‡æ ‡ç›‘æ§ä½“ç³»ï¼š\nå‰ç½®ä¾èµ–  å¦‚ä½•åœ¨K8sä¸­è¿è¡Œå’Œå¯åŠ¨grafana-agentï¼Œè¯·å‚è€ƒåœ¨kubernetesä¸­è¿è¡Œgrafana-agentæ”¶é›†ã€‚ æ¨èæ‚¨ä»¥daemonsetï¼Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨ä¸€ä¸ªgrafana-agentå®ä¾‹ã€‚  é€šè¿‡kubeletæ¥äº†è§£å’Œç›‘æ§k8sèŠ‚ç‚¹çš„åŸºæœ¬è¿è¡ŒçŠ¶æ€æ•°æ® æ–¹æ¡ˆä¸€ï¼šç›´æ¥è®¿é—®kubeletæ¥è·å–èŠ‚ç‚¹çŠ¶æ€æŒ‡æ ‡æ•°æ® Kubeletç»„ä»¶è¿è¡Œåœ¨Kubernetesé›†ç¾¤çš„å„ä¸ªèŠ‚ç‚¹ä¸­ï¼Œå…¶è´Ÿè´£ç»´æŠ¤å’Œç®¡ç†èŠ‚ç‚¹ä¸ŠPodçš„è¿è¡ŒçŠ¶æ€ã€‚kubeletç»„ä»¶çš„æ­£å¸¸è¿è¡Œç›´æ¥å…³ç³»åˆ°è¯¥èŠ‚ç‚¹æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸çš„è¢«Kubernetesé›†ç¾¤æ­£å¸¸ä½¿ç”¨ã€‚\nåŸºäºPrometheusåœ¨K8sç¯å¢ƒä¸‹çš„æœåŠ¡å‘ç°èƒ½åŠ›ï¼Œåœ¨Nodeæ¨¡å¼ï¼Œgrafana-agentä¼šè‡ªåŠ¨å‘ç°Kubernetesä¸­æ‰€æœ‰NodeèŠ‚ç‚¹çš„ä¿¡æ¯å¹¶ä½œä¸ºç›‘æ§çš„ç›®æ ‡Targetã€‚ è€Œè¿™äº›Targetçš„è®¿é—®åœ°å€å®é™…ä¸Šå°±æ˜¯Kubeletçš„è®¿é—®åœ°å€ã€‚\n åˆ›å»ºConfigMapï¼Œå…¶ä¸­åŒ…å«grafana-agentçš„é…ç½®æ–‡ä»¶å¦‚ä¸‹\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u003c\u003cEOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: |server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/kubelet scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f -  é‡å»ºgrafana-agentå®ä¾‹\n kubectl rollout restart daemonset/grafana-agent è¿™é‡Œä½¿ç”¨Nodeæ¨¡å¼è‡ªåŠ¨å‘ç°é›†ç¾¤ä¸­æ‰€æœ‰Kubeletä½œä¸ºç›‘æ§çš„æ•°æ®é‡‡é›†ç›®æ ‡ï¼ŒåŒæ—¶é€šè¿‡labelmapæ­¥éª¤ï¼Œå°†NodeèŠ‚ç‚¹ä¸Šçš„æ ‡ç­¾ï¼Œä½œä¸ºæ ·æœ¬çš„æ ‡ç­¾ä¿å­˜åˆ°æ—¶é—´åºåˆ—å½“ä¸­ã€‚ é‡æ–°åŠ è½½grafana-agentçš„é…ç½®æ–‡ä»¶ï¼Œå¹¶é‡å»ºgrafana-agentçš„Podå®ä¾‹åï¼Œåœ¨nightingale dashboardä¸­æœç´¢{job=\"integrations/kubernetes/kubelet\"}ï¼Œå³å¯çœ‹åˆ°ç›¸åº”çš„æ—¶åºæ•°æ®äº†ã€‚\næ–¹æ¡ˆäºŒï¼šé€šè¿‡kube-apiserveræä¾›çš„APIé—´æ¥è·å–kubeletçš„æŒ‡æ ‡æ•°æ® ä¸åŒäºä¸Šé¢ç¬¬ä¸€ç§æ–¹æ³•ï¼Œå…¶ç›´æ¥é€šè¿‡kubeletçš„metricsæœåŠ¡é‡‡é›†ç›‘æ§æ•°æ®ï¼Œæ–¹æ³•äºŒé€šè¿‡Kubernetesçš„api-serveræä¾›çš„ä»£ç†APIè®¿é—®å„ä¸ªèŠ‚ç‚¹ä¸­kubeletçš„metricsæœåŠ¡ã€‚\n åˆ›å»ºConfigMapï¼Œå…¶ä¸­åŒ…å«grafana-agentçš„é…ç½®æ–‡ä»¶å¦‚ä¸‹\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u003c\u003cEOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: |server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/kubelet' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/\\${1}/proxy/metrics EOF envsubst | kubectl apply -n $NAMESPACE -f - é€šè¿‡relabelingï¼Œå°†ä»Kubernetesè·å–åˆ°çš„é»˜è®¤åœ°å€__address__æ›¿æ¢ä¸ºkubernetes.default.svc:443ã€‚åŒæ—¶å°†__metrics_path__æ›¿æ¢ä¸ºapi-serverçš„ä»£ç†åœ°å€/api/v1/nodes/${1}/proxy/metricsã€‚\né€šè¿‡è·å–å„ä¸ªèŠ‚ç‚¹ä¸­kubeletçš„ç›‘æ§æŒ‡æ ‡ï¼Œæ‚¨å¯ä»¥è¯„ä¼°é›†ç¾¤ä¸­å„èŠ‚ç‚¹çš„æ€§èƒ½è¡¨ç°ã€‚ä¾‹å¦‚:\n1. é€šè¿‡æŒ‡æ ‡kubelet_pod_start_duration_secondså¯ä»¥è·å¾—å½“å‰èŠ‚ç‚¹ä¸­Podå¯åŠ¨æ—¶é—´ç›¸å…³çš„ç»Ÿè®¡æ•°æ®ã€‚\nkubelet_pod_start_duration_seconds{quantile=\"0.99\"} 2. Podå¹³å‡å¯åŠ¨æ—¶é—´ï¼ˆåŒ…å«é•œåƒä¸‹è½½æ—¶é—´ï¼‰ï¼š\nkubelet_pod_start_duration_seconds_sum / kubelet_pod_start_duration_seconds_count é™¤æ­¤ä»¥å¤–ï¼Œç›‘æ§æŒ‡æ ‡kubelet_docker_*è¿˜å¯ä»¥ä½“ç°å‡ºkubeletä¸å½“å‰èŠ‚ç‚¹çš„dockeræœåŠ¡çš„è°ƒç”¨æƒ…å†µï¼Œä»è€Œå¯ä»¥åæ˜ å‡ºdockeræœ¬èº«æ˜¯å¦ä¼šå½±å“kubeletçš„æ€§èƒ½è¡¨ç°ç­‰é—®é¢˜ã€‚\né€šè¿‡cAdvisoræ¥äº†è§£å’Œç›‘æ§èŠ‚ç‚¹ä¸­çš„å®¹å™¨è¿è¡ŒçŠ¶æ€ å„èŠ‚ç‚¹çš„kubeletç»„ä»¶ä¸­é™¤äº†åŒ…å«è‡ªèº«çš„ç›‘æ§æŒ‡æ ‡ä¿¡æ¯ä»¥å¤–ï¼Œkubeletç»„ä»¶è¿˜å†…ç½®äº†å¯¹cAdvisorçš„æ”¯æŒã€‚cAdvisorèƒ½å¤Ÿè·å–å½“å‰èŠ‚ç‚¹ä¸Šè¿è¡Œçš„æ‰€æœ‰å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œé€šè¿‡è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€å¯ä»¥è·å–åˆ°cadvisorçš„ç›‘æ§æŒ‡æ ‡ï¼Œå› æ­¤å’Œè·å–kubeletç›‘æ§æŒ‡æ ‡ç±»ä¼¼ï¼Œè¿™é‡ŒåŒæ ·é€šè¿‡nodeæ¨¡å¼è‡ªåŠ¨å‘ç°æ‰€æœ‰çš„kubeletä¿¡æ¯ï¼Œå¹¶é€šè¿‡é€‚å½“çš„relabelè¿‡ç¨‹ï¼Œä¿®æ”¹ç›‘æ§é‡‡é›†ä»»åŠ¡çš„é…ç½®ã€‚ ä¸é‡‡é›†kubeletè‡ªèº«ç›‘æ§æŒ‡æ ‡ç›¸ä¼¼ï¼Œè¿™é‡Œä¹Ÿæœ‰ä¸¤ç§æ–¹å¼é‡‡é›†cadvisorä¸­çš„ç›‘æ§æŒ‡æ ‡ï¼š\næ–¹æ¡ˆä¸€ï¼šç›´æ¥è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€ï¼Œéœ€è¦è·³è¿‡caè¯ä¹¦è®¤è¯ export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u003c\u003cEOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: |server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f - æ–¹æ¡ˆäºŒï¼šé€šè¿‡api-serveræä¾›çš„ä»£ç†åœ°å€è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€ export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u003c\u003cEOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: |server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) ä½¿ç”¨NodeExporterç›‘æ§èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ ä¸ºäº†èƒ½å¤Ÿé‡‡é›†é›†ç¾¤ä¸­å„ä¸ªèŠ‚ç‚¹çš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ©grafana-agentå†…ç½®çš„NodeExporterã€‚å…·ä½“çš„æ­¥éª¤å¯ä»¥å‚è€ƒï¼šgrafana-agent node_exporterã€‚\né€šè¿‡kube-apiserveræ¥äº†è§£æ•´ä¸ªK8sé›†ç¾¤çš„è¯¦ç»†è¿è¡ŒçŠ¶æ€ kube-apiserveræ‰®æ¼”äº†æ•´ä¸ªKubernetesé›†ç¾¤ç®¡ç†çš„å…¥å£çš„è§’è‰²ï¼Œè´Ÿè´£å¯¹å¤–æš´éœ²Kubernetes APIã€‚kube-apiserverç»„ä»¶ä¸€èˆ¬æ˜¯ç‹¬ç«‹éƒ¨ç½²åœ¨é›†ç¾¤å¤–çš„ï¼Œä¸ºäº†èƒ½å¤Ÿè®©éƒ¨ç½²åœ¨é›†ç¾¤å†…çš„åº”ç”¨ï¼ˆkubernetesæ’ä»¶æˆ–è€…ç”¨æˆ·åº”ç”¨ï¼‰èƒ½å¤Ÿä¸kube-apiserveräº¤äº’ï¼ŒKubernetesä¼šé»˜è®¤åœ¨å‘½åç©ºé—´ä¸‹åˆ›å»ºä¸€ä¸ªåä¸ºkubernetesçš„æœåŠ¡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n$ kubectl get svc kubernetes -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 166d \u003cnone\u003e è€Œè¯¥kubernetesæœåŠ¡ä»£ç†çš„åç«¯å®é™…åœ°å€é€šè¿‡endpointsè¿›è¡Œç»´æŠ¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n$ kubectl get endpoints kubernetes NAME ENDPOINTS AGE kubernetes 10.0.2.15:8443 166d é€šè¿‡è¿™ç§æ–¹å¼é›†ç¾¤å†…çš„åº”ç”¨æˆ–è€…ç³»ç»Ÿä¸»æœºå°±å¯ä»¥é€šè¿‡é›†ç¾¤å†…éƒ¨çš„DNSåŸŸåkubernetes.default.svcè®¿é—®åˆ°éƒ¨ç½²å¤–éƒ¨çš„kube-apiserverå®ä¾‹ã€‚\nå› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦ç›‘æ§kube-apiserverç›¸å…³çš„æŒ‡æ ‡ï¼Œåªéœ€è¦é€šè¿‡endpointsèµ„æºæ‰¾åˆ°kuberneteså¯¹åº”çš„æ‰€æœ‰åç«¯åœ°å€å³å¯ã€‚\nå¦‚ä¸‹æ‰€ç¤ºï¼Œåˆ›å»ºç›‘æ§ä»»åŠ¡kubernetes-apiserversï¼Œè¿™é‡ŒæŒ‡å®šäº†æœåŠ¡å‘ç°æ¨¡å¼ä¸ºendpointsã€‚grafana-agentä¼šæŸ¥æ‰¾å½“å‰é›†ç¾¤ä¸­æ‰€æœ‰çš„endpointsé…ç½®ï¼Œå¹¶é€šè¿‡relabelè¿›è¡Œåˆ¤æ–­æ˜¯å¦ä¸ºapiserverå¯¹åº”çš„è®¿é—®åœ°å€ï¼š\n- job_name: 'kubernetes-apiservers' kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - target_label: __address__ replacement: kubernetes.default.svc:443 åœ¨relabel_configsé…ç½®ä¸­ç¬¬ä¸€æ­¥ç”¨äºåˆ¤æ–­å½“å‰endpointsæ˜¯å¦ä¸ºkube-apiserverå¯¹ç”¨çš„åœ°å€ã€‚ç¬¬äºŒæ­¥ï¼Œæ›¿æ¢ç›‘æ§é‡‡é›†åœ°å€åˆ°kubernetes.default.svc:443å³å¯ã€‚é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶ï¼Œé‡å»ºgrafana-agentå®ä¾‹ï¼Œç”¨ä»¥ä¸‹promql {service=\"kubernetes\", job=\"apiserver\"}å³å¯åœ¨nightingale dashboardä¸­å¾—åˆ°kube-apiserverç›¸å…³çš„metricsæ•°æ®ã€‚\né€šè¿‡BlackboxExporteräº†è§£å’Œç›‘æ§K8sé›†ç¾¤ä¸­çš„ç½‘ç»œè¿é€šçŠ¶å†µ ä¸ºäº†èƒ½å¤Ÿå¯¹Ingresså’ŒServiceè¿›è¡Œæ¢æµ‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨K8sé›†ç¾¤éƒ¨ç½²Blackbox Exporterå®ä¾‹ã€‚ å¦‚ä¸‹æ‰€ç¤ºï¼Œåˆ›å»ºblackbox-exporter.yamlç”¨äºæè¿°éƒ¨ç½²ç›¸å…³çš„å†…å®¹:\ncat \u003c\u003c EOF | apiVersion: v1 kind: Service metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: ports: - name: blackbox port: 9115 protocol: TCP selector: app: blackbox-exporter type: ClusterIP --- apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: replicas: 1 selector: matchLabels: app: blackbox-exporter template: metadata: labels: app: blackbox-exporter spec: containers: - image: prom/blackbox-exporter imagePullPolicy: IfNotPresent name: blackbox-exporter EOF kubectl apply -f - é€šè¿‡ä»¥ä¸Šå‘½ä»¤ï¼Œå°†åœ¨K8sé›†ç¾¤ä¸­éƒ¨ç½²äº†ä¸€ä¸ªBlackbox Exporterçš„Podå®ä¾‹ï¼ŒåŒæ—¶é€šè¿‡æœåŠ¡blackbox-exporteråœ¨é›†ç¾¤å†…æš´éœ²è®¿é—®åœ°å€blackbox-exporter.default.svc.cluster.localï¼Œå¯¹äºé›†ç¾¤å†…çš„ä»»æ„æœåŠ¡éƒ½å¯ä»¥é€šè¿‡è¯¥å†…éƒ¨DNSåŸŸåè®¿é—®Blackbox Exporterå®ä¾‹ï¼š\n$ kubectl get pods NAME READY STATUS RESTARTS AGE blackbox-exporter-f77fc78b6-72bl5 1/1 Running 0 4s $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE blackbox-exporter ClusterIP 10.109.144.192 \u003cnone\u003e 9115/TCP 3m ä¸ºäº†èƒ½å¤Ÿè®©grafana-agentèƒ½å¤Ÿè‡ªåŠ¨çš„å¯¹Serviceè¿›è¡Œæ¢æµ‹ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡æœåŠ¡å‘ç°è‡ªåŠ¨æ‰¾åˆ°æ‰€æœ‰çš„Serviceä¿¡æ¯ã€‚ å¦‚ä¸‹æ‰€ç¤ºï¼Œåœ¨grafana-agentçš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ åä¸ºkubernetes-servicesçš„ç›‘æ§é‡‡é›†ä»»åŠ¡ï¼š\n- job_name: 'kubernetes-services' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: service relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name åœ¨è¯¥ä»»åŠ¡é…ç½®ä¸­ï¼Œé€šè¿‡æŒ‡å®škubernetes_sd_configçš„roleä¸ºserviceæŒ‡å®šæœåŠ¡å‘ç°æ¨¡å¼ï¼š\nkubernetes_sd_configs: - role: service ä¸ºäº†åŒºåˆ†é›†ç¾¤ä¸­éœ€è¦è¿›è¡Œæ¢æµ‹çš„Serviceå®ä¾‹ï¼Œæˆ‘ä»¬é€šè¿‡æ ‡ç­¾â€˜prometheus.io/probe: trueâ€™è¿›è¡Œåˆ¤æ–­ï¼Œä»è€Œè¿‡æ»¤å‡ºéœ€è¦æ¢æµ‹çš„æ‰€æœ‰Serviceå®ä¾‹ï¼š\n- source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true å¹¶ä¸”å°†é€šè¿‡æœåŠ¡å‘ç°è·å–åˆ°çš„Serviceå®ä¾‹åœ°å€__address__è½¬æ¢ä¸ºè·å–ç›‘æ§æ•°æ®çš„è¯·æ±‚å‚æ•°ã€‚åŒæ—¶å°†__addressæ‰§è¡ŒBlackbox Exporterå®ä¾‹çš„è®¿é—®åœ°å€ï¼Œå¹¶ä¸”é‡å†™äº†æ ‡ç­¾instanceçš„å†…å®¹ï¼š\n- source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance æœ€åï¼Œä¸ºç›‘æ§æ ·æœ¬æ·»åŠ äº†é¢å¤–çš„æ ‡ç­¾ä¿¡æ¯ï¼š\n- action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name å¯¹äºIngressè€Œè¨€ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç›¸å¯¹ç±»ä¼¼çš„è¿‡ç¨‹ï¼Œè¿™é‡Œç»™å‡ºå¯¹Ingressæ¢æµ‹çš„grafana-agentä»»åŠ¡é…ç½®ä½œä¸ºå‚è€ƒï¼š\n- job_name: 'kubernetes-ingresses' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: ingress relabel_configs: - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path] regex: (.+);(.+);(.+) replacement: ${1}://${2}${3} target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_ingress_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_ingress_name] target_label: kubernetes_name é€šè¿‡kube-state-metricsäº†è§£å’Œç›‘æ§K8sé›†ç¾¤è‡ªèº«å’Œåº”ç”¨çš„è¿è¡ŒçŠ¶æ€ kube-state-metricsé‡ç‚¹å›ç­”ä»¥ä¸‹æ–¹é¢çš„é—®é¢˜ï¼š\n æˆ‘è°ƒåº¦äº†å¤šå°‘ä¸ªreplicasï¼Ÿç°åœ¨å¯ç”¨çš„æœ‰å‡ ä¸ªï¼Ÿ å¤šå°‘ä¸ªPodæ˜¯running/stopped/terminatedçŠ¶æ€ï¼Ÿ Podé‡å¯äº†å¤šå°‘æ¬¡ï¼Ÿ æˆ‘æœ‰å¤šå°‘jobåœ¨è¿è¡Œä¸­ï¼Ÿ  kube-state-metricsåŸºäºclient-goå¼€å‘ï¼Œè½®è¯¢Kubernetes APIï¼Œå¹¶å°†Kubernetesçš„ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºmetricsã€‚ä»–æ‰€æ”¯æŒçš„æŒ‡æ ‡åŒ…æ‹¬ï¼š\n CronJob Metrics DaemonSet Metrics Deployment Metrics Job Metrics LimitRange Metrics Node Metrics PersistentVolume Metrics PersistentVolumeClaim Metrics Pod Metrics Pod Disruption Budget Metrics ReplicaSet Metrics ReplicationController Metrics ResourceQuota Metrics Service Metrics StatefulSet Metrics Namespace Metrics Horizontal Pod Autoscaler Metrics Endpoint Metrics Secret Metrics ConfigMap Metrics  ä»¥Podä¸ºä¾‹ï¼š\n kube_pod_info kube_pod_owner kube_pod_status_phase kube_pod_status_ready kube_pod_status_scheduled kube_pod_container_status_waiting kube_pod_container_status_terminated_reason â€¦  éƒ¨ç½²æ¸…å•ï¼š\nâ”œâ”€â”€ cluster-role-binding.yaml â”œâ”€â”€ cluster-role.yaml â”œâ”€â”€ deployment.yaml â”œâ”€â”€ service-account.yaml â”œâ”€â”€ service.yaml ä¸»è¦é•œåƒæœ‰ï¼š\n image: quay.io/coreos/kube-state-metrics:v2.4.2  å¯¹äºpodçš„èµ„æºé™åˆ¶ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼š\n200MiB memory 0.1 cores è¶…è¿‡100èŠ‚ç‚¹çš„é›†ç¾¤ï¼š\n2MiB memory per node 0.001 cores per node å› ä¸ºkube-state-metrics-service.yamlä¸­æœ‰prometheus.io/scrape: 'true'æ ‡è¯†ï¼Œå› æ­¤ä¼šå°†metricæš´éœ²ç»™grafana-agentï¼Œè€Œgrafana-agentä¼šåœ¨kubernetes-service-endpointsè¿™ä¸ªjobä¸‹è‡ªåŠ¨å‘ç°kube-state-metricsï¼Œå¹¶å¼€å§‹æ‹‰å–metricsï¼Œæ— éœ€å…¶ä»–é…ç½®ã€‚\nä½¿ç”¨kube-state-metricsåçš„å¸¸ç”¨åœºæ™¯æœ‰ï¼š\n å­˜åœ¨æ‰§è¡Œå¤±è´¥çš„Job: kube_job_status_failed{job=â€œkubernetes-service-endpointsâ€,k8s_app=â€œkube-state-metricsâ€}==1 é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€é”™è¯¯: kube_node_status_condition{condition=â€œReadyâ€,status!=â€œtrueâ€}==1 é›†ç¾¤ä¸­å­˜åœ¨å¯åŠ¨å¤±è´¥çš„Podï¼škube_pod_status_phase{phase=~â€œFailed|Unknownâ€}==1 æœ€è¿‘30åˆ†é’Ÿå†…æœ‰Podå®¹å™¨é‡å¯: changes(kube_pod_container_status_restarts[30m])\u003e0   å‚è€ƒèµ„æ–™\n  Prometheusä¸æœåŠ¡å‘ç° åŸºäºæ–‡ä»¶çš„æœåŠ¡å‘ç° åŸºäºConsulçš„æœåŠ¡å‘ç° æœåŠ¡å‘ç°ä¸Relabel Kubernetesä¸‹çš„æœåŠ¡å‘ç° ç›‘æ§Kubernetesé›†ç¾¤ kube-state-metrics kube-state-metrics deoplyment   Acknowledgement:æœ¬æ–‡æ¡£åœ¨yunlzheng ç›‘æ§Kubernetesé›†ç¾¤çš„åŸºç¡€ä¸Šä¿®æ”¹å’Œè¡¥å……è€Œæˆï¼Œç›¸å…³æ–‡å­—çš„ç‰ˆæƒå½’å±åŸä½œè€…yunlzhengæ‰€æœ‰ï¼Œå¹¶è‡´ä»¥è°¢æ„ã€‚\n ",
    "description": "",
    "tags": null,
    "title": "ç›‘æ§K8sé›†ç¾¤å’Œåº”ç”¨",
    "uri": "/grafana-agent/how-to-monitoring-k8s/"
  }
]
